<!DOCTYPE html>
<!-- saved from url=(0066)https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html -->
<html class="writer-html5" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>torch_geometric.nn — pytorch_geometric  documentation</title>
      <style type="text/css">:root, :host {
  --fa-font-solid: normal 900 1em/1 "Font Awesome 6 Free";
  --fa-font-regular: normal 400 1em/1 "Font Awesome 6 Free";
  --fa-font-light: normal 300 1em/1 "Font Awesome 6 Pro";
  --fa-font-thin: normal 100 1em/1 "Font Awesome 6 Pro";
  --fa-font-duotone: normal 900 1em/1 "Font Awesome 6 Duotone";
  --fa-font-duotone-regular: normal 400 1em/1 "Font Awesome 6 Duotone";
  --fa-font-duotone-light: normal 300 1em/1 "Font Awesome 6 Duotone";
  --fa-font-duotone-thin: normal 100 1em/1 "Font Awesome 6 Duotone";
  --fa-font-brands: normal 400 1em/1 "Font Awesome 6 Brands";
  --fa-font-sharp-solid: normal 900 1em/1 "Font Awesome 6 Sharp";
  --fa-font-sharp-regular: normal 400 1em/1 "Font Awesome 6 Sharp";
  --fa-font-sharp-light: normal 300 1em/1 "Font Awesome 6 Sharp";
  --fa-font-sharp-thin: normal 100 1em/1 "Font Awesome 6 Sharp";
  --fa-font-sharp-duotone-solid: normal 900 1em/1 "Font Awesome 6 Sharp Duotone";
  --fa-font-sharp-duotone-regular: normal 400 1em/1 "Font Awesome 6 Sharp Duotone";
  --fa-font-sharp-duotone-light: normal 300 1em/1 "Font Awesome 6 Sharp Duotone";
  --fa-font-sharp-duotone-thin: normal 100 1em/1 "Font Awesome 6 Sharp Duotone";
}

svg:not(:root).svg-inline--fa, svg:not(:host).svg-inline--fa {
  overflow: visible;
  box-sizing: content-box;
}

.svg-inline--fa {
  display: var(--fa-display, inline-block);
  height: 1em;
  overflow: visible;
  vertical-align: -0.125em;
}
.svg-inline--fa.fa-2xs {
  vertical-align: 0.1em;
}
.svg-inline--fa.fa-xs {
  vertical-align: 0em;
}
.svg-inline--fa.fa-sm {
  vertical-align: -0.0714285705em;
}
.svg-inline--fa.fa-lg {
  vertical-align: -0.2em;
}
.svg-inline--fa.fa-xl {
  vertical-align: -0.25em;
}
.svg-inline--fa.fa-2xl {
  vertical-align: -0.3125em;
}
.svg-inline--fa.fa-pull-left {
  margin-right: var(--fa-pull-margin, 0.3em);
  width: auto;
}
.svg-inline--fa.fa-pull-right {
  margin-left: var(--fa-pull-margin, 0.3em);
  width: auto;
}
.svg-inline--fa.fa-li {
  width: var(--fa-li-width, 2em);
  top: 0.25em;
}
.svg-inline--fa.fa-fw {
  width: var(--fa-fw-width, 1.25em);
}

.fa-layers svg.svg-inline--fa {
  bottom: 0;
  left: 0;
  margin: auto;
  position: absolute;
  right: 0;
  top: 0;
}

.fa-layers-counter, .fa-layers-text {
  display: inline-block;
  position: absolute;
  text-align: center;
}

.fa-layers {
  display: inline-block;
  height: 1em;
  position: relative;
  text-align: center;
  vertical-align: -0.125em;
  width: 1em;
}
.fa-layers svg.svg-inline--fa {
  transform-origin: center center;
}

.fa-layers-text {
  left: 50%;
  top: 50%;
  transform: translate(-50%, -50%);
  transform-origin: center center;
}

.fa-layers-counter {
  background-color: var(--fa-counter-background-color, #ff253a);
  border-radius: var(--fa-counter-border-radius, 1em);
  box-sizing: border-box;
  color: var(--fa-inverse, #fff);
  line-height: var(--fa-counter-line-height, 1);
  max-width: var(--fa-counter-max-width, 5em);
  min-width: var(--fa-counter-min-width, 1.5em);
  overflow: hidden;
  padding: var(--fa-counter-padding, 0.25em 0.5em);
  right: var(--fa-right, 0);
  text-overflow: ellipsis;
  top: var(--fa-top, 0);
  transform: scale(var(--fa-counter-scale, 0.25));
  transform-origin: top right;
}

.fa-layers-bottom-right {
  bottom: var(--fa-bottom, 0);
  right: var(--fa-right, 0);
  top: auto;
  transform: scale(var(--fa-layers-scale, 0.25));
  transform-origin: bottom right;
}

.fa-layers-bottom-left {
  bottom: var(--fa-bottom, 0);
  left: var(--fa-left, 0);
  right: auto;
  top: auto;
  transform: scale(var(--fa-layers-scale, 0.25));
  transform-origin: bottom left;
}

.fa-layers-top-right {
  top: var(--fa-top, 0);
  right: var(--fa-right, 0);
  transform: scale(var(--fa-layers-scale, 0.25));
  transform-origin: top right;
}

.fa-layers-top-left {
  left: var(--fa-left, 0);
  right: auto;
  top: var(--fa-top, 0);
  transform: scale(var(--fa-layers-scale, 0.25));
  transform-origin: top left;
}

.fa-1x {
  font-size: 1em;
}

.fa-2x {
  font-size: 2em;
}

.fa-3x {
  font-size: 3em;
}

.fa-4x {
  font-size: 4em;
}

.fa-5x {
  font-size: 5em;
}

.fa-6x {
  font-size: 6em;
}

.fa-7x {
  font-size: 7em;
}

.fa-8x {
  font-size: 8em;
}

.fa-9x {
  font-size: 9em;
}

.fa-10x {
  font-size: 10em;
}

.fa-2xs {
  font-size: 0.625em;
  line-height: 0.1em;
  vertical-align: 0.225em;
}

.fa-xs {
  font-size: 0.75em;
  line-height: 0.0833333337em;
  vertical-align: 0.125em;
}

.fa-sm {
  font-size: 0.875em;
  line-height: 0.0714285718em;
  vertical-align: 0.0535714295em;
}

.fa-lg {
  font-size: 1.25em;
  line-height: 0.05em;
  vertical-align: -0.075em;
}

.fa-xl {
  font-size: 1.5em;
  line-height: 0.0416666682em;
  vertical-align: -0.125em;
}

.fa-2xl {
  font-size: 2em;
  line-height: 0.03125em;
  vertical-align: -0.1875em;
}

.fa-fw {
  text-align: center;
  width: 1.25em;
}

.fa-ul {
  list-style-type: none;
  margin-left: var(--fa-li-margin, 2.5em);
  padding-left: 0;
}
.fa-ul > li {
  position: relative;
}

.fa-li {
  left: calc(-1 * var(--fa-li-width, 2em));
  position: absolute;
  text-align: center;
  width: var(--fa-li-width, 2em);
  line-height: inherit;
}

.fa-border {
  border-color: var(--fa-border-color, #eee);
  border-radius: var(--fa-border-radius, 0.1em);
  border-style: var(--fa-border-style, solid);
  border-width: var(--fa-border-width, 0.08em);
  padding: var(--fa-border-padding, 0.2em 0.25em 0.15em);
}

.fa-pull-left {
  float: left;
  margin-right: var(--fa-pull-margin, 0.3em);
}

.fa-pull-right {
  float: right;
  margin-left: var(--fa-pull-margin, 0.3em);
}

.fa-beat {
  animation-name: fa-beat;
  animation-delay: var(--fa-animation-delay, 0s);
  animation-direction: var(--fa-animation-direction, normal);
  animation-duration: var(--fa-animation-duration, 1s);
  animation-iteration-count: var(--fa-animation-iteration-count, infinite);
  animation-timing-function: var(--fa-animation-timing, ease-in-out);
}

.fa-bounce {
  animation-name: fa-bounce;
  animation-delay: var(--fa-animation-delay, 0s);
  animation-direction: var(--fa-animation-direction, normal);
  animation-duration: var(--fa-animation-duration, 1s);
  animation-iteration-count: var(--fa-animation-iteration-count, infinite);
  animation-timing-function: var(--fa-animation-timing, cubic-bezier(0.28, 0.84, 0.42, 1));
}

.fa-fade {
  animation-name: fa-fade;
  animation-delay: var(--fa-animation-delay, 0s);
  animation-direction: var(--fa-animation-direction, normal);
  animation-duration: var(--fa-animation-duration, 1s);
  animation-iteration-count: var(--fa-animation-iteration-count, infinite);
  animation-timing-function: var(--fa-animation-timing, cubic-bezier(0.4, 0, 0.6, 1));
}

.fa-beat-fade {
  animation-name: fa-beat-fade;
  animation-delay: var(--fa-animation-delay, 0s);
  animation-direction: var(--fa-animation-direction, normal);
  animation-duration: var(--fa-animation-duration, 1s);
  animation-iteration-count: var(--fa-animation-iteration-count, infinite);
  animation-timing-function: var(--fa-animation-timing, cubic-bezier(0.4, 0, 0.6, 1));
}

.fa-flip {
  animation-name: fa-flip;
  animation-delay: var(--fa-animation-delay, 0s);
  animation-direction: var(--fa-animation-direction, normal);
  animation-duration: var(--fa-animation-duration, 1s);
  animation-iteration-count: var(--fa-animation-iteration-count, infinite);
  animation-timing-function: var(--fa-animation-timing, ease-in-out);
}

.fa-shake {
  animation-name: fa-shake;
  animation-delay: var(--fa-animation-delay, 0s);
  animation-direction: var(--fa-animation-direction, normal);
  animation-duration: var(--fa-animation-duration, 1s);
  animation-iteration-count: var(--fa-animation-iteration-count, infinite);
  animation-timing-function: var(--fa-animation-timing, linear);
}

.fa-spin {
  animation-name: fa-spin;
  animation-delay: var(--fa-animation-delay, 0s);
  animation-direction: var(--fa-animation-direction, normal);
  animation-duration: var(--fa-animation-duration, 2s);
  animation-iteration-count: var(--fa-animation-iteration-count, infinite);
  animation-timing-function: var(--fa-animation-timing, linear);
}

.fa-spin-reverse {
  --fa-animation-direction: reverse;
}

.fa-pulse,
.fa-spin-pulse {
  animation-name: fa-spin;
  animation-direction: var(--fa-animation-direction, normal);
  animation-duration: var(--fa-animation-duration, 1s);
  animation-iteration-count: var(--fa-animation-iteration-count, infinite);
  animation-timing-function: var(--fa-animation-timing, steps(8));
}

@media (prefers-reduced-motion: reduce) {
  .fa-beat,
.fa-bounce,
.fa-fade,
.fa-beat-fade,
.fa-flip,
.fa-pulse,
.fa-shake,
.fa-spin,
.fa-spin-pulse {
    animation-delay: -1ms;
    animation-duration: 1ms;
    animation-iteration-count: 1;
    transition-delay: 0s;
    transition-duration: 0s;
  }
}
@keyframes fa-beat {
  0%, 90% {
    transform: scale(1);
  }
  45% {
    transform: scale(var(--fa-beat-scale, 1.25));
  }
}
@keyframes fa-bounce {
  0% {
    transform: scale(1, 1) translateY(0);
  }
  10% {
    transform: scale(var(--fa-bounce-start-scale-x, 1.1), var(--fa-bounce-start-scale-y, 0.9)) translateY(0);
  }
  30% {
    transform: scale(var(--fa-bounce-jump-scale-x, 0.9), var(--fa-bounce-jump-scale-y, 1.1)) translateY(var(--fa-bounce-height, -0.5em));
  }
  50% {
    transform: scale(var(--fa-bounce-land-scale-x, 1.05), var(--fa-bounce-land-scale-y, 0.95)) translateY(0);
  }
  57% {
    transform: scale(1, 1) translateY(var(--fa-bounce-rebound, -0.125em));
  }
  64% {
    transform: scale(1, 1) translateY(0);
  }
  100% {
    transform: scale(1, 1) translateY(0);
  }
}
@keyframes fa-fade {
  50% {
    opacity: var(--fa-fade-opacity, 0.4);
  }
}
@keyframes fa-beat-fade {
  0%, 100% {
    opacity: var(--fa-beat-fade-opacity, 0.4);
    transform: scale(1);
  }
  50% {
    opacity: 1;
    transform: scale(var(--fa-beat-fade-scale, 1.125));
  }
}
@keyframes fa-flip {
  50% {
    transform: rotate3d(var(--fa-flip-x, 0), var(--fa-flip-y, 1), var(--fa-flip-z, 0), var(--fa-flip-angle, -180deg));
  }
}
@keyframes fa-shake {
  0% {
    transform: rotate(-15deg);
  }
  4% {
    transform: rotate(15deg);
  }
  8%, 24% {
    transform: rotate(-18deg);
  }
  12%, 28% {
    transform: rotate(18deg);
  }
  16% {
    transform: rotate(-22deg);
  }
  20% {
    transform: rotate(22deg);
  }
  32% {
    transform: rotate(-12deg);
  }
  36% {
    transform: rotate(12deg);
  }
  40%, 100% {
    transform: rotate(0deg);
  }
}
@keyframes fa-spin {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}
.fa-rotate-90 {
  transform: rotate(90deg);
}

.fa-rotate-180 {
  transform: rotate(180deg);
}

.fa-rotate-270 {
  transform: rotate(270deg);
}

.fa-flip-horizontal {
  transform: scale(-1, 1);
}

.fa-flip-vertical {
  transform: scale(1, -1);
}

.fa-flip-both,
.fa-flip-horizontal.fa-flip-vertical {
  transform: scale(-1, -1);
}

.fa-rotate-by {
  transform: rotate(var(--fa-rotate-angle, 0));
}

.fa-stack {
  display: inline-block;
  vertical-align: middle;
  height: 2em;
  position: relative;
  width: 2.5em;
}

.fa-stack-1x,
.fa-stack-2x {
  bottom: 0;
  left: 0;
  margin: auto;
  position: absolute;
  right: 0;
  top: 0;
  z-index: var(--fa-stack-z-index, auto);
}

.svg-inline--fa.fa-stack-1x {
  height: 1em;
  width: 1.25em;
}
.svg-inline--fa.fa-stack-2x {
  height: 2em;
  width: 2.5em;
}

.fa-inverse {
  color: var(--fa-inverse, #fff);
}

.sr-only,
.fa-sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border-width: 0;
}

.sr-only-focusable:not(:focus),
.fa-sr-only-focusable:not(:focus) {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border-width: 0;
}

.svg-inline--fa .fa-primary {
  fill: var(--fa-primary-color, currentColor);
  opacity: var(--fa-primary-opacity, 1);
}

.svg-inline--fa .fa-secondary {
  fill: var(--fa-secondary-color, currentColor);
  opacity: var(--fa-secondary-opacity, 0.4);
}

.svg-inline--fa.fa-swap-opacity .fa-primary {
  opacity: var(--fa-secondary-opacity, 0.4);
}

.svg-inline--fa.fa-swap-opacity .fa-secondary {
  opacity: var(--fa-primary-opacity, 1);
}

.svg-inline--fa mask .fa-primary,
.svg-inline--fa mask .fa-secondary {
  fill: black;
}</style><link rel="stylesheet" type="text/css" href="./torch_geometric.nn — pytorch_geometric documentation_files/pygments.css">
      <link rel="stylesheet" type="text/css" href="./torch_geometric.nn — pytorch_geometric documentation_files/mytheme.css">
      <link rel="stylesheet" type="text/css" href="./torch_geometric.nn — pytorch_geometric documentation_files/copybutton.css">

  
    <link rel="shortcut icon" href="https://raw.githubusercontent.com/pyg-team/pyg_sphinx_theme/master/pyg_sphinx_theme/static/img/favicon.png">
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="./torch_geometric.nn — pytorch_geometric documentation_files/documentation_options.js.download"></script>
        <script src="./torch_geometric.nn — pytorch_geometric documentation_files/jquery.js.download"></script>
        <script src="./torch_geometric.nn — pytorch_geometric documentation_files/underscore.js.download"></script>
        <script src="./torch_geometric.nn — pytorch_geometric documentation_files/_sphinx_javascript_frameworks_compat.js.download"></script>
        <script src="./torch_geometric.nn — pytorch_geometric documentation_files/doctools.js.download"></script>
        <script src="./torch_geometric.nn — pytorch_geometric documentation_files/clipboard.min.js.download"></script>
        <script src="./torch_geometric.nn — pytorch_geometric documentation_files/copybutton.js.download"></script>
        <script src="./torch_geometric.nn — pytorch_geometric documentation_files/on_pyg_load.js.download"></script>
        <script src="./torch_geometric.nn — pytorch_geometric documentation_files/version_alert.js.download"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="./torch_geometric.nn — pytorch_geometric documentation_files/require.min.js.download"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="./torch_geometric.nn — pytorch_geometric documentation_files/tex-mml-chtml.js.download"></script>
    <script src="./torch_geometric.nn — pytorch_geometric documentation_files/theme.js.download"></script>
    <link rel="index" title="Index" href="https://pytorch-geometric.readthedocs.io/en/latest/genindex.html">
    <link rel="search" title="Search" href="https://pytorch-geometric.readthedocs.io/en/latest/search.html">
    <link rel="next" title="torch_geometric.nn.conv.MessagePassing" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html">
    <link rel="prev" title="torch_geometric.EdgeIndex" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.EdgeIndex.html"> 
<script async="" type="text/javascript" src="./torch_geometric.nn — pytorch_geometric documentation_files/readthedocs-addons.js.download"></script><meta name="readthedocs-project-slug" content="pytorch-geometric"><meta name="readthedocs-version-slug" content="latest"><meta name="readthedocs-resolver-filename" content="/modules/nn.html"><meta name="readthedocs-http-status" content="200"><style type="text/css">.CtxtMenu_InfoClose {  top:.2em; right:.2em;}
.CtxtMenu_InfoContent {  overflow:auto; text-align:left; font-size:80%;  padding:.4em .6em; border:1px inset; margin:1em 0px;  max-height:20em; max-width:30em; background-color:#EEEEEE;  white-space:normal;}
.CtxtMenu_Info.CtxtMenu_MousePost {outline:none;}
.CtxtMenu_Info {  position:fixed; left:50%; width:auto; text-align:center;  border:3px outset; padding:1em 2em; background-color:#DDDDDD;  color:black;  cursor:default; font-family:message-box; font-size:120%;  font-style:normal; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 15px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius:15px;               /* Safari and Chrome */  -moz-border-radius:15px;                  /* Firefox */  -khtml-border-radius:15px;                /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */  filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color="gray", Positive="true"); /* IE */}
</style><style type="text/css">.CtxtMenu_MenuClose {  position:absolute;  cursor:pointer;  display:inline-block;  border:2px solid #AAA;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  font-family: "Courier New", Courier;  font-size:24px;  color:#F0F0F0}
.CtxtMenu_MenuClose span {  display:block; background-color:#AAA; border:1.5px solid;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  line-height:0;  padding:8px 0 6px     /* may need to be browser-specific */}
.CtxtMenu_MenuClose:hover {  color:white!important;  border:2px solid #CCC!important}
.CtxtMenu_MenuClose:hover span {  background-color:#CCC!important}
.CtxtMenu_MenuClose:hover:focus {  outline:none}
</style><style type="text/css">.CtxtMenu_Menu {  position:absolute;  background-color:white;  color:black;  width:auto; padding:5px 0px;  border:1px solid #CCCCCC; margin:0; cursor:default;  font: menu; text-align:left; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 5px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius: 5px;             /* Safari and Chrome */  -moz-border-radius: 5px;                /* Firefox */  -khtml-border-radius: 5px;              /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */}
.CtxtMenu_MenuItem {  padding: 1px 2em;  background:transparent;}
.CtxtMenu_MenuArrow {  position:absolute; right:.5em; padding-top:.25em; color:#666666;  font-family: null; font-size: .75em}
.CtxtMenu_MenuActive .CtxtMenu_MenuArrow {color:white}
.CtxtMenu_MenuArrow.CtxtMenu_RTL {left:.5em; right:auto}
.CtxtMenu_MenuCheck {  position:absolute; left:.7em;  font-family: null}
.CtxtMenu_MenuCheck.CtxtMenu_RTL { right:.7em; left:auto }
.CtxtMenu_MenuRadioCheck {  position:absolute; left: .7em;}
.CtxtMenu_MenuRadioCheck.CtxtMenu_RTL {  right: .7em; left:auto}
.CtxtMenu_MenuInputBox {  padding-left: 1em; right:.5em; color:#666666;  font-family: null;}
.CtxtMenu_MenuInputBox.CtxtMenu_RTL {  left: .1em;}
.CtxtMenu_MenuComboBox {  left:.1em; padding-bottom:.5em;}
.CtxtMenu_MenuSlider {  left: .1em;}
.CtxtMenu_SliderValue {  position:absolute; right:.1em; padding-top:.25em; color:#333333;  font-size: .75em}
.CtxtMenu_SliderBar {  outline: none; background: #d3d3d3}
.CtxtMenu_MenuLabel {  padding: 1px 2em 3px 1.33em;  font-style:italic}
.CtxtMenu_MenuRule {  border-top: 1px solid #DDDDDD;  margin: 4px 3px;}
.CtxtMenu_MenuDisabled {  color:GrayText}
.CtxtMenu_MenuActive {  background-color: #606872;  color: white;}
.CtxtMenu_MenuDisabled:focus {  background-color: #E8E8E8}
.CtxtMenu_MenuLabel:focus {  background-color: #E8E8E8}
.CtxtMenu_ContextMenu:focus {  outline:none}
.CtxtMenu_ContextMenu .CtxtMenu_MenuItem:focus {  outline:none}
.CtxtMenu_SelectionMenu {  position:relative; float:left;  border-bottom: none; -webkit-box-shadow:none; -webkit-border-radius:0px; }
.CtxtMenu_SelectionItem {  padding-right: 1em;}
.CtxtMenu_Selection {  right: 40%; width:50%; }
.CtxtMenu_SelectionBox {  padding: 0em; max-height:20em; max-width: none;  background-color:#FFFFFF;}
.CtxtMenu_SelectionDivider {  clear: both; border-top: 2px solid #000000;}
.CtxtMenu_Menu .CtxtMenu_MenuClose {  top:-10px; left:-10px}
</style><style id="MJX-CHTML-styles">
mjx-container[jax="CHTML"] {
  line-height: 0;
}

mjx-container [space="1"] {
  margin-left: .111em;
}

mjx-container [space="2"] {
  margin-left: .167em;
}

mjx-container [space="3"] {
  margin-left: .222em;
}

mjx-container [space="4"] {
  margin-left: .278em;
}

mjx-container [space="5"] {
  margin-left: .333em;
}

mjx-container [rspace="1"] {
  margin-right: .111em;
}

mjx-container [rspace="2"] {
  margin-right: .167em;
}

mjx-container [rspace="3"] {
  margin-right: .222em;
}

mjx-container [rspace="4"] {
  margin-right: .278em;
}

mjx-container [rspace="5"] {
  margin-right: .333em;
}

mjx-container [size="s"] {
  font-size: 70.7%;
}

mjx-container [size="ss"] {
  font-size: 50%;
}

mjx-container [size="Tn"] {
  font-size: 60%;
}

mjx-container [size="sm"] {
  font-size: 85%;
}

mjx-container [size="lg"] {
  font-size: 120%;
}

mjx-container [size="Lg"] {
  font-size: 144%;
}

mjx-container [size="LG"] {
  font-size: 173%;
}

mjx-container [size="hg"] {
  font-size: 207%;
}

mjx-container [size="HG"] {
  font-size: 249%;
}

mjx-container [width="full"] {
  width: 100%;
}

mjx-box {
  display: inline-block;
}

mjx-block {
  display: block;
}

mjx-itable {
  display: inline-table;
}

mjx-row {
  display: table-row;
}

mjx-row > * {
  display: table-cell;
}

mjx-mtext {
  display: inline-block;
}

mjx-mstyle {
  display: inline-block;
}

mjx-merror {
  display: inline-block;
  color: red;
  background-color: yellow;
}

mjx-mphantom {
  visibility: hidden;
}

_::-webkit-full-page-media, _:future, :root mjx-container {
  will-change: opacity;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-math {
  display: inline-block;
  text-align: left;
  line-height: 0;
  text-indent: 0;
  font-style: normal;
  font-weight: normal;
  font-size: 100%;
  font-size-adjust: none;
  letter-spacing: normal;
  border-collapse: collapse;
  word-wrap: normal;
  word-spacing: normal;
  white-space: nowrap;
  direction: ltr;
  padding: 1px 0;
}

mjx-container[jax="CHTML"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="CHTML"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="CHTML"][display="true"] mjx-math {
  padding: 0;
}

mjx-container[jax="CHTML"][justify="left"] {
  text-align: left;
}

mjx-container[jax="CHTML"][justify="right"] {
  text-align: right;
}

mjx-msup {
  display: inline-block;
  text-align: left;
}

mjx-TeXAtom {
  display: inline-block;
  text-align: left;
}

mjx-mi {
  display: inline-block;
  text-align: left;
}

mjx-c {
  display: inline-block;
}

mjx-utext {
  display: inline-block;
  padding: .75em 0 .2em 0;
}

mjx-mo {
  display: inline-block;
  text-align: left;
}

mjx-stretchy-h {
  display: inline-table;
  width: 100%;
}

mjx-stretchy-h > * {
  display: table-cell;
  width: 0;
}

mjx-stretchy-h > * > mjx-c {
  display: inline-block;
  transform: scalex(1.0000001);
}

mjx-stretchy-h > * > mjx-c::before {
  display: inline-block;
  width: initial;
}

mjx-stretchy-h > mjx-ext {
  /* IE */ overflow: hidden;
  /* others */ overflow: clip visible;
  width: 100%;
}

mjx-stretchy-h > mjx-ext > mjx-c::before {
  transform: scalex(500);
}

mjx-stretchy-h > mjx-ext > mjx-c {
  width: 0;
}

mjx-stretchy-h > mjx-beg > mjx-c {
  margin-right: -.1em;
}

mjx-stretchy-h > mjx-end > mjx-c {
  margin-left: -.1em;
}

mjx-stretchy-v {
  display: inline-block;
}

mjx-stretchy-v > * {
  display: block;
}

mjx-stretchy-v > mjx-beg {
  height: 0;
}

mjx-stretchy-v > mjx-end > mjx-c {
  display: block;
}

mjx-stretchy-v > * > mjx-c {
  transform: scaley(1.0000001);
  transform-origin: left center;
  overflow: hidden;
}

mjx-stretchy-v > mjx-ext {
  display: block;
  height: 100%;
  box-sizing: border-box;
  border: 0px solid transparent;
  /* IE */ overflow: hidden;
  /* others */ overflow: visible clip;
}

mjx-stretchy-v > mjx-ext > mjx-c::before {
  width: initial;
  box-sizing: border-box;
}

mjx-stretchy-v > mjx-ext > mjx-c {
  transform: scaleY(500) translateY(.075em);
  overflow: visible;
}

mjx-mark {
  display: inline-block;
  height: 0px;
}

mjx-msub {
  display: inline-block;
  text-align: left;
}

mjx-msubsup {
  display: inline-block;
  text-align: left;
}

mjx-script {
  display: inline-block;
  padding-right: .05em;
  padding-left: .033em;
}

mjx-script > mjx-spacer {
  display: block;
}

mjx-mn {
  display: inline-block;
  text-align: left;
}

mjx-mtable {
  display: inline-block;
  text-align: center;
  vertical-align: .25em;
  position: relative;
  box-sizing: border-box;
  border-spacing: 0;
  border-collapse: collapse;
}

mjx-mstyle[size="s"] mjx-mtable {
  vertical-align: .354em;
}

mjx-labels {
  position: absolute;
  left: 0;
  top: 0;
}

mjx-table {
  display: inline-block;
  vertical-align: -.5ex;
  box-sizing: border-box;
}

mjx-table > mjx-itable {
  vertical-align: middle;
  text-align: left;
  box-sizing: border-box;
}

mjx-labels > mjx-itable {
  position: absolute;
  top: 0;
}

mjx-mtable[justify="left"] {
  text-align: left;
}

mjx-mtable[justify="right"] {
  text-align: right;
}

mjx-mtable[justify="left"][side="left"] {
  padding-right: 0 ! important;
}

mjx-mtable[justify="left"][side="right"] {
  padding-left: 0 ! important;
}

mjx-mtable[justify="right"][side="left"] {
  padding-right: 0 ! important;
}

mjx-mtable[justify="right"][side="right"] {
  padding-left: 0 ! important;
}

mjx-mtable[align] {
  vertical-align: baseline;
}

mjx-mtable[align="top"] > mjx-table {
  vertical-align: top;
}

mjx-mtable[align="bottom"] > mjx-table {
  vertical-align: bottom;
}

mjx-mtable[side="right"] mjx-labels {
  min-width: 100%;
}

mjx-mtr {
  display: table-row;
  text-align: left;
}

mjx-mtr[rowalign="top"] > mjx-mtd {
  vertical-align: top;
}

mjx-mtr[rowalign="center"] > mjx-mtd {
  vertical-align: middle;
}

mjx-mtr[rowalign="bottom"] > mjx-mtd {
  vertical-align: bottom;
}

mjx-mtr[rowalign="baseline"] > mjx-mtd {
  vertical-align: baseline;
}

mjx-mtr[rowalign="axis"] > mjx-mtd {
  vertical-align: .25em;
}

mjx-mtd {
  display: table-cell;
  text-align: center;
  padding: .215em .4em;
}

mjx-mtd:first-child {
  padding-left: 0;
}

mjx-mtd:last-child {
  padding-right: 0;
}

mjx-mtable > * > mjx-itable > *:first-child > mjx-mtd {
  padding-top: 0;
}

mjx-mtable > * > mjx-itable > *:last-child > mjx-mtd {
  padding-bottom: 0;
}

mjx-tstrut {
  display: inline-block;
  height: 1em;
  vertical-align: -.25em;
}

mjx-labels[align="left"] > mjx-mtr > mjx-mtd {
  text-align: left;
}

mjx-labels[align="right"] > mjx-mtr > mjx-mtd {
  text-align: right;
}

mjx-mtd[extra] {
  padding: 0;
}

mjx-mtd[rowalign="top"] {
  vertical-align: top;
}

mjx-mtd[rowalign="center"] {
  vertical-align: middle;
}

mjx-mtd[rowalign="bottom"] {
  vertical-align: bottom;
}

mjx-mtd[rowalign="baseline"] {
  vertical-align: baseline;
}

mjx-mtd[rowalign="axis"] {
  vertical-align: .25em;
}

mjx-mrow {
  display: inline-block;
  text-align: left;
}

mjx-msqrt {
  display: inline-block;
  text-align: left;
}

mjx-root {
  display: inline-block;
  white-space: nowrap;
}

mjx-surd {
  display: inline-block;
  vertical-align: top;
}

mjx-sqrt {
  display: inline-block;
  padding-top: .07em;
}

mjx-sqrt > mjx-box {
  border-top: .07em solid;
}

mjx-sqrt.mjx-tall > mjx-box {
  padding-left: .3em;
  margin-left: -.3em;
}

mjx-munder {
  display: inline-block;
  text-align: left;
}

mjx-over {
  text-align: left;
}

mjx-munder:not([limits="false"]) {
  display: inline-table;
}

mjx-munder > mjx-row {
  text-align: left;
}

mjx-under {
  padding-bottom: .1em;
}

mjx-munderover {
  display: inline-block;
  text-align: left;
}

mjx-munderover:not([limits="false"]) {
  padding-top: .1em;
}

mjx-munderover:not([limits="false"]) > * {
  display: block;
}

mjx-c::before {
  display: block;
  width: 0;
}

.MJX-TEX {
  font-family: MJXZERO, MJXTEX;
}

.TEX-B {
  font-family: MJXZERO, MJXTEX-B;
}

.TEX-I {
  font-family: MJXZERO, MJXTEX-I;
}

.TEX-MI {
  font-family: MJXZERO, MJXTEX-MI;
}

.TEX-BI {
  font-family: MJXZERO, MJXTEX-BI;
}

.TEX-S1 {
  font-family: MJXZERO, MJXTEX-S1;
}

.TEX-S2 {
  font-family: MJXZERO, MJXTEX-S2;
}

.TEX-S3 {
  font-family: MJXZERO, MJXTEX-S3;
}

.TEX-S4 {
  font-family: MJXZERO, MJXTEX-S4;
}

.TEX-A {
  font-family: MJXZERO, MJXTEX-A;
}

.TEX-C {
  font-family: MJXZERO, MJXTEX-C;
}

.TEX-CB {
  font-family: MJXZERO, MJXTEX-CB;
}

.TEX-FR {
  font-family: MJXZERO, MJXTEX-FR;
}

.TEX-FRB {
  font-family: MJXZERO, MJXTEX-FRB;
}

.TEX-SS {
  font-family: MJXZERO, MJXTEX-SS;
}

.TEX-SSB {
  font-family: MJXZERO, MJXTEX-SSB;
}

.TEX-SSI {
  font-family: MJXZERO, MJXTEX-SSI;
}

.TEX-SC {
  font-family: MJXZERO, MJXTEX-SC;
}

.TEX-T {
  font-family: MJXZERO, MJXTEX-T;
}

.TEX-V {
  font-family: MJXZERO, MJXTEX-V;
}

.TEX-VB {
  font-family: MJXZERO, MJXTEX-VB;
}

mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c {
  font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A ! important;
}

@font-face /* 0 */ {
  font-family: MJXZERO;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff");
}

@font-face /* 1 */ {
  font-family: MJXTEX;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff");
}

@font-face /* 2 */ {
  font-family: MJXTEX-B;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff");
}

@font-face /* 3 */ {
  font-family: MJXTEX-I;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff");
}

@font-face /* 4 */ {
  font-family: MJXTEX-MI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff");
}

@font-face /* 5 */ {
  font-family: MJXTEX-BI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff");
}

@font-face /* 6 */ {
  font-family: MJXTEX-S1;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff");
}

@font-face /* 7 */ {
  font-family: MJXTEX-S2;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff");
}

@font-face /* 8 */ {
  font-family: MJXTEX-S3;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff");
}

@font-face /* 9 */ {
  font-family: MJXTEX-S4;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff");
}

@font-face /* 10 */ {
  font-family: MJXTEX-A;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff");
}

@font-face /* 11 */ {
  font-family: MJXTEX-C;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff");
}

@font-face /* 12 */ {
  font-family: MJXTEX-CB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff");
}

@font-face /* 13 */ {
  font-family: MJXTEX-FR;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff");
}

@font-face /* 14 */ {
  font-family: MJXTEX-FRB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff");
}

@font-face /* 15 */ {
  font-family: MJXTEX-SS;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff");
}

@font-face /* 16 */ {
  font-family: MJXTEX-SSB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff");
}

@font-face /* 17 */ {
  font-family: MJXTEX-SSI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff");
}

@font-face /* 18 */ {
  font-family: MJXTEX-SC;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff");
}

@font-face /* 19 */ {
  font-family: MJXTEX-T;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff");
}

@font-face /* 20 */ {
  font-family: MJXTEX-V;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff");
}

@font-face /* 21 */ {
  font-family: MJXTEX-VB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff");
}

mjx-c.mjx-c1D431.TEX-B::before {
  padding: 0.444em 0.607em 0 0;
  content: "x";
}

mjx-c.mjx-c2032::before {
  padding: 0.56em 0.275em 0 0;
  content: "\2032";
}

mjx-c.mjx-c3D::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "=";
}

mjx-c.mjx-c1D416.TEX-B::before {
  padding: 0.686em 1.189em 0.007em 0;
  content: "W";
}

mjx-c.mjx-c22A4::before {
  padding: 0.668em 0.778em 0 0;
  content: "\22A4";
}

mjx-c.mjx-c2B::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "+";
}

mjx-c.mjx-c1D41B.TEX-B::before {
  padding: 0.694em 0.639em 0.006em 0;
  content: "b";
}

mjx-c.mjx-c28::before {
  padding: 0.75em 0.389em 0.25em 0;
  content: "(";
}

mjx-c.mjx-c2217::before {
  padding: 0.465em 0.5em 0 0;
  content: "\2217";
}

mjx-c.mjx-c2C::before {
  padding: 0.121em 0.278em 0.194em 0;
  content: ",";
}

mjx-c.mjx-c1D439.TEX-I::before {
  padding: 0.68em 0.749em 0 0;
  content: "F";
}

mjx-c.mjx-c1D456.TEX-I::before {
  padding: 0.661em 0.345em 0.011em 0;
  content: "i";
}

mjx-c.mjx-c1D45B.TEX-I::before {
  padding: 0.442em 0.6em 0.011em 0;
  content: "n";
}

mjx-c.mjx-c29::before {
  padding: 0.75em 0.389em 0.25em 0;
  content: ")";
}

mjx-c.mjx-c1D45C.TEX-I::before {
  padding: 0.441em 0.485em 0.011em 0;
  content: "o";
}

mjx-c.mjx-c1D462.TEX-I::before {
  padding: 0.442em 0.572em 0.011em 0;
  content: "u";
}

mjx-c.mjx-c1D461.TEX-I::before {
  padding: 0.626em 0.361em 0.011em 0;
  content: "t";
}

mjx-c.mjx-c1D705.TEX-I::before {
  padding: 0.442em 0.576em 0.011em 0;
  content: "\3BA";
}

mjx-c.mjx-c2E::before {
  padding: 0.12em 0.278em 0 0;
  content: ".";
}

mjx-c.mjx-c58.TEX-C::before {
  padding: 0.683em 0.807em 0 0;
  content: "X";
}

mjx-c.mjx-c1D45E.TEX-I::before {
  padding: 0.442em 0.46em 0.194em 0;
  content: "q";
}

mjx-c.mjx-c1D719.TEX-I::before {
  padding: 0.694em 0.596em 0.205em 0;
  content: "\3D5";
}

mjx-c.mjx-c1D6AF.TEX-B::before {
  padding: 0.696em 0.894em 0.01em 0;
  content: "\398";
}

mjx-c.mjx-c1D70C.TEX-I::before {
  padding: 0.442em 0.517em 0.216em 0;
  content: "\3C1";
}

mjx-c.mjx-c4F.TEX-C::before {
  padding: 0.705em 0.796em 0.022em 0;
  content: "O";
}

mjx-c.mjx-c6C::before {
  padding: 0.694em 0.278em 0 0;
  content: "l";
}

mjx-c.mjx-c6F::before {
  padding: 0.448em 0.5em 0.01em 0;
  content: "o";
}

mjx-c.mjx-c67::before {
  padding: 0.453em 0.5em 0.206em 0;
  content: "g";
}

mjx-c.mjx-c2061::before {
  padding: 0 0 0 0;
  content: "";
}

mjx-c.mjx-c7C::before {
  padding: 0.75em 0.278em 0.249em 0;
  content: "|";
}

mjx-c.mjx-c56.TEX-C::before {
  padding: 0.683em 0.658em 0.052em 0;
  content: "V";
}

mjx-c.mjx-c1D458.TEX-I::before {
  padding: 0.694em 0.521em 0.011em 0;
  content: "k";
}

mjx-c.mjx-c1D43F.TEX-I::before {
  padding: 0.683em 0.681em 0 0;
  content: "L";
}

mjx-c.mjx-c32::before {
  padding: 0.666em 0.5em 0 0;
  content: "2";
}

mjx-c.mjx-c74::before {
  padding: 0.615em 0.389em 0.01em 0;
  content: "t";
}

mjx-c.mjx-c70::before {
  padding: 0.442em 0.556em 0.194em 0;
  content: "p";
}

mjx-c.mjx-c45.TEX-C::before {
  padding: 0.705em 0.564em 0.022em 0;
  content: "E";
}

mjx-c.mjx-c52.TEX-C::before {
  padding: 0.682em 0.848em 0.022em 0;
  content: "R";
}

mjx-c.mjx-c43.TEX-C::before {
  padding: 0.705em 0.527em 0.025em 0;
  content: "C";
}

mjx-c.mjx-c1D419.TEX-B::before {
  padding: 0.686em 0.703em 0 0;
  content: "Z";
}

mjx-c.mjx-c1D418.TEX-B::before {
  padding: 0.686em 0.869em 0 0;
  content: "Y";
}

mjx-c.mjx-c1D443.TEX-I::before {
  padding: 0.683em 0.751em 0 0;
  content: "P";
}

mjx-c.mjx-c1D438.TEX-I::before {
  padding: 0.68em 0.764em 0 0;
  content: "E";
}

mjx-c.mjx-c1D465.TEX-I::before {
  padding: 0.442em 0.572em 0.011em 0;
  content: "x";
}

mjx-c.mjx-c22C5::before {
  padding: 0.31em 0.278em 0 0;
  content: "\22C5";
}

mjx-c.mjx-c73::before {
  padding: 0.448em 0.394em 0.011em 0;
  content: "s";
}

mjx-c.mjx-c69::before {
  padding: 0.669em 0.278em 0 0;
  content: "i";
}

mjx-c.mjx-c6E::before {
  padding: 0.442em 0.556em 0 0;
  content: "n";
}

mjx-c.mjx-c2F::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "/";
}

mjx-c.mjx-c31::before {
  padding: 0.666em 0.5em 0 0;
  content: "1";
}

mjx-c.mjx-c30::before {
  padding: 0.666em 0.5em 0.022em 0;
  content: "0";
}

mjx-c.mjx-c1D451.TEX-I::before {
  padding: 0.694em 0.52em 0.01em 0;
  content: "d";
}

mjx-c.mjx-c63::before {
  padding: 0.448em 0.444em 0.011em 0;
  content: "c";
}

mjx-c.mjx-c5B::before {
  padding: 0.75em 0.278em 0.25em 0;
  content: "[";
}

mjx-c.mjx-c2212::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "\2212";
}

mjx-c.mjx-c5D::before {
  padding: 0.75em 0.278em 0.25em 0;
  content: "]";
}

mjx-c.mjx-c1D466.TEX-I::before {
  padding: 0.442em 0.49em 0.205em 0;
  content: "y";
}

mjx-c.mjx-c28.TEX-S3::before {
  padding: 1.45em 0.736em 0.949em 0;
  content: "(";
}

mjx-c.mjx-c221A::before {
  padding: 0.8em 0.853em 0.2em 0;
  content: "\221A";
}

mjx-c.mjx-c29.TEX-S3::before {
  padding: 1.45em 0.736em 0.949em 0;
  content: ")";
}

mjx-c.mjx-c2264::before {
  padding: 0.636em 0.778em 0.138em 0;
  content: "\2264";
}

mjx-c.mjx-c1D453.TEX-I::before {
  padding: 0.705em 0.55em 0.205em 0;
  content: "f";
}

mjx-c.mjx-c2113::before {
  padding: 0.705em 0.417em 0.02em 0;
  content: "\2113";
}

mjx-c.mjx-c1D703.TEX-I::before {
  padding: 0.705em 0.469em 0.01em 0;
  content: "\3B8";
}

mjx-c.mjx-c7B::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "{";
}

mjx-c.mjx-c1D45F.TEX-I::before {
  padding: 0.442em 0.451em 0.011em 0;
  content: "r";
}

mjx-c.mjx-c3A::before {
  padding: 0.43em 0.278em 0 0;
  content: ":";
}

mjx-c.mjx-c2208::before {
  padding: 0.54em 0.667em 0.04em 0;
  content: "\2208";
}

mjx-c.mjx-c7D::before {
  padding: 0.75em 0.5em 0.25em 0;
  content: "}";
}

mjx-c.mjx-c1D421.TEX-B::before {
  padding: 0.694em 0.639em 0 0;
  content: "h";
}

mjx-c.mjx-c1D463.TEX-I::before {
  padding: 0.443em 0.485em 0.011em 0;
  content: "v";
}

mjx-c.mjx-c2A01.TEX-S2::before {
  padding: 0.949em 1.511em 0.449em 0;
  content: "\2A01";
}

mjx-c.mjx-c1D464.TEX-I::before {
  padding: 0.443em 0.716em 0.011em 0;
  content: "w";
}

mjx-c.mjx-c4E.TEX-C::before {
  padding: 0.789em 0.979em 0.05em 0;
  content: "N";
}

mjx-c.mjx-c2A01.TEX-S1::before {
  padding: 0.75em 1.111em 0.25em 0;
  content: "\2A01";
}

mjx-c.mjx-c1D44F.TEX-I::before {
  padding: 0.694em 0.429em 0.011em 0;
  content: "b";
}

mjx-c.mjx-c2026::before {
  padding: 0.12em 1.172em 0 0;
  content: "\2026";
}

mjx-c.mjx-c1D435.TEX-I::before {
  padding: 0.683em 0.759em 0 0;
  content: "B";
}

mjx-c.mjx-c2211.TEX-S2::before {
  padding: 0.95em 1.444em 0.45em 0;
  content: "\2211";
}

mjx-c.mjx-c1D44E.TEX-I::before {
  padding: 0.441em 0.529em 0.01em 0;
  content: "a";
}
</style><script id="ethicaladsjs" type="text/javascript" async="true" src="./torch_geometric.nn — pytorch_geometric documentation_files/ethicalads.min.js.download"></script><style>[data-ea-publisher].loaded,[data-ea-type].loaded{font-size:14px;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;font-weight:normal;font-style:normal;letter-spacing:0px;vertical-align:baseline;line-height:1.3em}[data-ea-publisher].loaded a,[data-ea-type].loaded a{text-decoration:none}[data-ea-publisher].loaded .ea-pixel,[data-ea-type].loaded .ea-pixel{display:none}[data-ea-publisher].loaded .ea-content,[data-ea-type].loaded .ea-content{margin:1em 1em .5em 1em;padding:1em;background:rgba(0,0,0,.03);color:#505050}[data-ea-publisher].loaded .ea-content a:link,[data-ea-type].loaded .ea-content a:link{color:#505050}[data-ea-publisher].loaded .ea-content a:visited,[data-ea-type].loaded .ea-content a:visited{color:#505050}[data-ea-publisher].loaded .ea-content a:hover,[data-ea-type].loaded .ea-content a:hover{color:#373737}[data-ea-publisher].loaded .ea-content a:active,[data-ea-type].loaded .ea-content a:active{color:#373737}[data-ea-publisher].loaded .ea-content a strong,[data-ea-publisher].loaded .ea-content a b,[data-ea-type].loaded .ea-content a strong,[data-ea-type].loaded .ea-content a b{color:#088cdb}[data-ea-publisher].loaded .ea-callout a:link,[data-ea-type].loaded .ea-callout a:link{color:#6a6a6a}[data-ea-publisher].loaded .ea-callout a:visited,[data-ea-type].loaded .ea-callout a:visited{color:#6a6a6a}[data-ea-publisher].loaded .ea-callout a:hover,[data-ea-type].loaded .ea-callout a:hover{color:#505050}[data-ea-publisher].loaded .ea-callout a:active,[data-ea-type].loaded .ea-callout a:active{color:#505050}[data-ea-publisher].loaded .ea-callout a strong,[data-ea-publisher].loaded .ea-callout a b,[data-ea-type].loaded .ea-callout a strong,[data-ea-type].loaded .ea-callout a b{color:#088cdb}[data-ea-publisher].loaded .ea-callout a,[data-ea-type].loaded .ea-callout a{font-size:.8em}[data-ea-publisher].loaded .ea-domain,[data-ea-type].loaded .ea-domain{margin-top:.75em;font-size:.8em;text-align:center;color:#9d9d9d}[data-ea-publisher].loaded.dark .ea-content,[data-ea-type].loaded.dark .ea-content{background:rgba(255,255,255,.05);color:#dcdcdc}[data-ea-publisher].loaded.dark .ea-content a:link,[data-ea-type].loaded.dark .ea-content a:link{color:#dcdcdc}[data-ea-publisher].loaded.dark .ea-content a:visited,[data-ea-type].loaded.dark .ea-content a:visited{color:#dcdcdc}[data-ea-publisher].loaded.dark .ea-content a:hover,[data-ea-type].loaded.dark .ea-content a:hover{color:#f6f6f6}[data-ea-publisher].loaded.dark .ea-content a:active,[data-ea-type].loaded.dark .ea-content a:active{color:#f6f6f6}[data-ea-publisher].loaded.dark .ea-content a strong,[data-ea-publisher].loaded.dark .ea-content a b,[data-ea-type].loaded.dark .ea-content a strong,[data-ea-type].loaded.dark .ea-content a b{color:#50baf9}[data-ea-publisher].loaded.dark .ea-callout a:link,[data-ea-type].loaded.dark .ea-callout a:link{color:#c3c3c3}[data-ea-publisher].loaded.dark .ea-callout a:visited,[data-ea-type].loaded.dark .ea-callout a:visited{color:#c3c3c3}[data-ea-publisher].loaded.dark .ea-callout a:hover,[data-ea-type].loaded.dark .ea-callout a:hover{color:#dcdcdc}[data-ea-publisher].loaded.dark .ea-callout a:active,[data-ea-type].loaded.dark .ea-callout a:active{color:#dcdcdc}[data-ea-publisher].loaded.dark .ea-callout a strong,[data-ea-publisher].loaded.dark .ea-callout a b,[data-ea-type].loaded.dark .ea-callout a strong,[data-ea-type].loaded.dark .ea-callout a b{color:#50baf9}[data-ea-publisher].loaded.dark .ea-domain,[data-ea-type].loaded.dark .ea-domain{color:#909090}@media(prefers-color-scheme: dark){[data-ea-publisher].loaded.adaptive .ea-content,[data-ea-type].loaded.adaptive .ea-content{background:rgba(255,255,255,.05);color:#dcdcdc}[data-ea-publisher].loaded.adaptive .ea-content a:link,[data-ea-type].loaded.adaptive .ea-content a:link{color:#dcdcdc}[data-ea-publisher].loaded.adaptive .ea-content a:visited,[data-ea-type].loaded.adaptive .ea-content a:visited{color:#dcdcdc}[data-ea-publisher].loaded.adaptive .ea-content a:hover,[data-ea-type].loaded.adaptive .ea-content a:hover{color:#f6f6f6}[data-ea-publisher].loaded.adaptive .ea-content a:active,[data-ea-type].loaded.adaptive .ea-content a:active{color:#f6f6f6}[data-ea-publisher].loaded.adaptive .ea-content a strong,[data-ea-publisher].loaded.adaptive .ea-content a b,[data-ea-type].loaded.adaptive .ea-content a strong,[data-ea-type].loaded.adaptive .ea-content a b{color:#50baf9}[data-ea-publisher].loaded.adaptive .ea-callout a:link,[data-ea-type].loaded.adaptive .ea-callout a:link{color:#c3c3c3}[data-ea-publisher].loaded.adaptive .ea-callout a:visited,[data-ea-type].loaded.adaptive .ea-callout a:visited{color:#c3c3c3}[data-ea-publisher].loaded.adaptive .ea-callout a:hover,[data-ea-type].loaded.adaptive .ea-callout a:hover{color:#dcdcdc}[data-ea-publisher].loaded.adaptive .ea-callout a:active,[data-ea-type].loaded.adaptive .ea-callout a:active{color:#dcdcdc}[data-ea-publisher].loaded.adaptive .ea-callout a strong,[data-ea-publisher].loaded.adaptive .ea-callout a b,[data-ea-type].loaded.adaptive .ea-callout a strong,[data-ea-type].loaded.adaptive .ea-callout a b{color:#50baf9}[data-ea-publisher].loaded.adaptive .ea-domain,[data-ea-type].loaded.adaptive .ea-domain{color:#909090}}[data-ea-publisher].loaded .ea-content,[data-ea-type].loaded .ea-content{border:0px;border-radius:3px;box-shadow:0px 2px 3px rgba(0,0,0,.15)}[data-ea-publisher].loaded.raised .ea-content,[data-ea-type].loaded.raised .ea-content{border:0px;border-radius:3px;box-shadow:0px 2px 3px rgba(0,0,0,.15)}[data-ea-publisher].loaded.bordered .ea-content,[data-ea-type].loaded.bordered .ea-content{border:1px solid rgba(0,0,0,.04);border-radius:3px;box-shadow:none}[data-ea-publisher].loaded.bordered.dark .ea-content,[data-ea-type].loaded.bordered.dark .ea-content{border:1px solid rgba(255,255,255,.07)}@media(prefers-color-scheme: dark){[data-ea-publisher].loaded.bordered.adaptive .ea-content,[data-ea-type].loaded.bordered.adaptive .ea-content{border:1px solid rgba(255,255,255,.07)}}[data-ea-publisher].loaded.flat .ea-content,[data-ea-type].loaded.flat .ea-content{border:0px;border-radius:3px;box-shadow:none}[data-ea-type=image].loaded,[data-ea-publisher]:not([data-ea-type]).loaded,.ea-type-image{display:inline-block}[data-ea-type=image].loaded .ea-content,[data-ea-publisher]:not([data-ea-type]).loaded .ea-content,.ea-type-image .ea-content{max-width:180px;overflow:auto;text-align:center}[data-ea-type=image].loaded .ea-content>a>img,[data-ea-publisher]:not([data-ea-type]).loaded .ea-content>a>img,.ea-type-image .ea-content>a>img{width:120px;height:90px;display:inline-block}[data-ea-type=image].loaded .ea-content>.ea-text,[data-ea-publisher]:not([data-ea-type]).loaded .ea-content>.ea-text,.ea-type-image .ea-content>.ea-text{margin-top:1em;font-size:1em;text-align:center}[data-ea-type=image].loaded .ea-callout,[data-ea-publisher]:not([data-ea-type]).loaded .ea-callout,.ea-type-image .ea-callout{max-width:180px;margin:0em 1em 1em 1em;padding-left:1em;padding-right:1em;font-style:italic;text-align:right}[data-ea-type=image].loaded.horizontal .ea-content,[data-ea-publisher]:not([data-ea-type]).loaded.horizontal .ea-content,.ea-type-image.horizontal .ea-content{max-width:320px}[data-ea-type=image].loaded.horizontal .ea-content>a>img,[data-ea-publisher]:not([data-ea-type]).loaded.horizontal .ea-content>a>img,.ea-type-image.horizontal .ea-content>a>img{float:left;margin-right:1em}[data-ea-type=image].loaded.horizontal .ea-content .ea-text,[data-ea-publisher]:not([data-ea-type]).loaded.horizontal .ea-content .ea-text,.ea-type-image.horizontal .ea-content .ea-text{margin-top:0em;text-align:left;overflow:auto}[data-ea-type=image].loaded.horizontal .ea-callout,[data-ea-publisher]:not([data-ea-type]).loaded.horizontal .ea-callout,.ea-type-image.horizontal .ea-callout{max-width:320px;text-align:right}[data-ea-type=text].loaded,.ea-type-text{font-size:14px}[data-ea-type=text].loaded .ea-content,.ea-type-text .ea-content{text-align:left}[data-ea-type=text].loaded .ea-callout,.ea-type-text .ea-callout{margin:.5em 1em 1em 1em;padding-left:1em;padding-right:1em;text-align:right;font-style:italic}[data-ea-style=stickybox].loaded{position:fixed;bottom:20px;right:20px;z-index:100}[data-ea-style=stickybox].loaded .ea-type-image .ea-stickybox-hide{cursor:pointer;position:absolute;top:.75em;right:.75em;background-color:#fefefe;border:1px solid #088cdb;border-radius:50%;color:#088cdb;font-size:1em;text-align:center;height:1.5em;width:1.5em;line-height:1.4}@media(max-width: 1300px){[data-ea-style=stickybox].loaded{position:static;bottom:0;right:0;margin:auto;text-align:center}[data-ea-style=stickybox].loaded .ea-stickybox-hide{display:none}}@media(min-width: 1301px){[data-ea-style=stickybox].loaded .ea-type-image .ea-content{background:#dcdcdc}[data-ea-style=stickybox].loaded.dark .ea-type-image .ea-content{background:#505050}}@media(min-width: 1301px)and (prefers-color-scheme: dark){[data-ea-style=stickybox].loaded.adaptive .ea-type-image .ea-content{background:#505050}}[data-ea-style=fixedfooter].loaded{position:fixed;bottom:0;left:0;z-index:200;width:100%;max-width:100%}[data-ea-style=fixedfooter].loaded .ea-type-text{width:100%;max-width:100%;display:flex;z-index:200;background:#dcdcdc}[data-ea-style=fixedfooter].loaded .ea-type-text .ea-content{border:0px;border-radius:3px;box-shadow:none}[data-ea-style=fixedfooter].loaded .ea-type-text .ea-content{background-color:inherit;max-width:100%;margin:0;padding:1em;flex:auto}[data-ea-style=fixedfooter].loaded .ea-type-text .ea-callout{max-width:100%;margin:0;padding:1em;flex:initial}@media(max-width: 576px){[data-ea-style=fixedfooter].loaded .ea-type-text .ea-callout{display:none}}[data-ea-style=fixedfooter].loaded .ea-type-text .ea-fixedfooter-hide{cursor:pointer;color:#505050;padding:1em;flex:initial;margin:auto 0}[data-ea-style=fixedfooter].loaded .ea-type-text .ea-fixedfooter-hide span{padding:.25em;font-size:.8em;font-weight:bold;border:.15em solid #505050;border-radius:.5em;white-space:nowrap}[data-ea-style=fixedfooter].loaded.dark .ea-type-text{background:#505050}[data-ea-style=fixedfooter].loaded.dark .ea-type-text .ea-fixedfooter-hide span{color:#dcdcdc;border-color:#dcdcdc}@media(prefers-color-scheme: dark){[data-ea-style=fixedfooter].loaded.adaptive .ea-type-text{background:#505050}[data-ea-style=fixedfooter].loaded.adaptive .ea-type-text .ea-fixedfooter-hide span{color:#dcdcdc;border-color:#dcdcdc}}</style></head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">

          
          
          <a href="https://pytorch-geometric.readthedocs.io/en/latest/index.html">
            
              <img src="./torch_geometric.nn — pytorch_geometric documentation_files/pyg_logo.png" class="logo" alt="Logo">
          </a>
              <div class="version">
                2.7.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="https://pytorch-geometric.readthedocs.io/en/latest/search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs">
    <input type="hidden" name="check_keywords" value="yes">
    <input type="hidden" name="area" value="default">
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Install PyG</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html">Introduction by Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/get_started/colabs.html">Colab Notebooks and Video Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/tutorial/gnn_design.html">Design of Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/tutorial/dataset.html">Working with Graph Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/tutorial/application.html">Use-Cases &amp; Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/tutorial/distributed.html">Distributed Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/batching.html">Advanced Mini-Batching</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/sparse_tensor.html">Memory-Efficient Aggregations</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/hgam.html">Hierarchical Neighborhood Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/compile.html">Compiled Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/jit.html">TorchScript Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/remote.html">Scaling Up GNNs via Remote Backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/graphgym.html">Managing Experiments with GraphGym</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/cpu_affinity.html">CPU Affinity for PyG Workloads</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul class="current" aria-expanded="true">
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/root.html">torch_geometric</a></li>
<li class="toctree-l1 current" aria-expanded="true"><a class="reference internal pyg-mono current" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#" aria-expanded="true"><button class="toctree-expand" title="Open/close menu"></button>torch_geometric.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers">Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#aggregation-operators">Aggregation Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#normalization-layers">Normalization Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#pooling-layers">Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#unpooling-layers">Unpooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#kge-models">KGE Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.encoding">Encodings</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#functional">Functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-convolutional-layers">Dense Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-pooling-layers">Dense Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#model-transformations">Model Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.data_parallel">DataParallel Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.model_hub">Model Hub</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.summary">Model Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html">torch_geometric.data</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html">torch_geometric.loader</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/sampler.html">torch_geometric.sampler</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html">torch_geometric.datasets</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html">torch_geometric.transforms</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html">torch_geometric.utils</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/explain.html">torch_geometric.explain</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/metrics.html">torch_geometric.metrics</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/distributed.html">torch_geometric.distributed</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/contrib.html">torch_geometric.contrib</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/graphgym.html">torch_geometric.graphgym</a></li>
<li class="toctree-l1"><a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/profile.html">torch_geometric.profile</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Cheatsheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/cheatsheet/gnn_cheatsheet.html">GNN Cheatsheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/cheatsheet/data_cheatsheet.html">Dataset Cheatsheet</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">External Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/external/resources.html">External Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="https://pytorch-geometric.readthedocs.io/en/latest/index.html">pytorch_geometric</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="https://pytorch-geometric.readthedocs.io/en/latest/index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active pyg-mono">torch_geometric.nn</li>
      <li class="wy-breadcrumbs-aside">
            <a href="https://pytorch-geometric.readthedocs.io/en/latest/_sources/modules/nn.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="torch-geometric-nn">
<h1 class="pyg-mono">torch_geometric.nn<a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch-geometric-nn" title="Permalink to this heading"></a></h1>
<nav class="contents local" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers" id="id42">Convolutional Layers</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#aggregation-operators" id="id43">Aggregation Operators</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#normalization-layers" id="id44">Normalization Layers</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#pooling-layers" id="id45">Pooling Layers</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#unpooling-layers" id="id46">Unpooling Layers</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models" id="id47">Models</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#kge-models" id="id48">KGE Models</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.encoding" id="id49">Encodings</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#functional" id="id50">Functional</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-convolutional-layers" id="id51">Dense Convolutional Layers</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-pooling-layers" id="id52">Dense Pooling Layers</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#model-transformations" id="id53">Model Transformations</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.data_parallel" id="id54">DataParallel Layers</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.model_hub" id="id55">Model Hub</a></p></li>
<li><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.summary" id="id56">Model Summary</a></p></li>
</ul>
</nav>
<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.sequential.Sequential">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Sequential</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">modules</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/sequential.html#Sequential"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.sequential.Sequential" title="Permalink to this definition"></a></dt>
<dd><p>An extension of the <a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code></a> container in order to
define a sequential GNN model.</p>
<p>Since GNN operators take in multiple input arguments,
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.Sequential</span></code> additionally expects both global
input arguments, and function header definitions of individual operators.
If omitted, an intermediate module will operate on the <em>output</em> of its
preceding module:</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell0"><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Linear</span><span class="p">,</span> <span class="n">ReLU</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">GCNConv</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="s1">'x, edge_index'</span><span class="p">,</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">GCNConv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="s1">'x, edge_index -&gt; x'</span><span class="p">),</span>
    <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">(</span><span class="n">GCNConv</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="s1">'x, edge_index -&gt; x'</span><span class="p">),</span>
    <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">),</span>
<span class="p">])</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell0">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>Here, <code class="xref py py-obj docutils literal notranslate"><span class="pre">'x,</span> <span class="pre">edge_index'</span></code> defines the input arguments of <code class="xref py py-obj docutils literal notranslate"><span class="pre">model</span></code>,
and <code class="xref py py-obj docutils literal notranslate"><span class="pre">'x,</span> <span class="pre">edge_index</span> <span class="pre">-&gt;</span> <span class="pre">x'</span></code> defines the function header, <em>i.e.</em> input
arguments <em>and</em> return types of <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html#torch_geometric.nn.conv.GCNConv" title="torch_geometric.nn.conv.GCNConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">GCNConv</span></code></a>.</p>
<p>In particular, this also allows to create more sophisticated models,
such as utilizing <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.JumpingKnowledge.html#torch_geometric.nn.models.JumpingKnowledge" title="torch_geometric.nn.models.JumpingKnowledge"><code class="xref py py-class docutils literal notranslate"><span class="pre">JumpingKnowledge</span></code></a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell1"><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Linear</span><span class="p">,</span> <span class="n">ReLU</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">GCNConv</span><span class="p">,</span> <span class="n">JumpingKnowledge</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">global_mean_pool</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="s1">'x, edge_index, batch'</span><span class="p">,</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span> <span class="s1">'x -&gt; x'</span><span class="p">),</span>
    <span class="p">(</span><span class="n">GCNConv</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="s1">'x, edge_index -&gt; x1'</span><span class="p">),</span>
    <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">(</span><span class="n">GCNConv</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="s1">'x1, edge_index -&gt; x2'</span><span class="p">),</span>
    <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">(</span><span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">:</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">],</span> <span class="s1">'x1, x2 -&gt; xs'</span><span class="p">),</span>
    <span class="p">(</span><span class="n">JumpingKnowledge</span><span class="p">(</span><span class="s2">"cat"</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="s1">'xs -&gt; x'</span><span class="p">),</span>
    <span class="p">(</span><span class="n">global_mean_pool</span><span class="p">,</span> <span class="s1">'x, batch -&gt; x'</span><span class="p">),</span>
    <span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="mi">64</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">),</span>
<span class="p">])</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell1">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_args</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The input arguments of the model.</p></li>
<li><p><strong>modules</strong> (<em>[</em><em>(</em><em>Callable</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>) or </em><em>Callable</em><em>]</em>) – A list of modules (with
optional function header definitions). Alternatively, an
<code class="xref py py-obj docutils literal notranslate"><span class="pre">OrderedDict</span></code> of modules (and function header definitions) can
be passed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.Linear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_initializer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_initializer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#Linear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.Linear" title="Permalink to this definition"></a></dt>
<dd><p>Applies a linear transformation to the incoming data.</p>
<div class="math notranslate nohighlight">
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="0" style="font-size: 114.5%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.413em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D416 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.413em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c22A4"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D41B TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msup><mo>=</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">W</mi></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">⊤</mi></mrow></msup><mo>+</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">b</mi></mrow></math></mjx-assistive-mml></mjx-container></div>
<p>In contrast to <a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code></a>, it supports lazy initialization
and customizable weight and bias initialization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of each input sample. Will be initialized
lazily in case it is given as <code class="xref py py-obj docutils literal notranslate"><span class="pre">-1</span></code>.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>weight_initializer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The initializer for the weight
matrix (<code class="xref py py-obj docutils literal notranslate"><span class="pre">"glorot"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"uniform"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"kaiming_uniform"</span></code>
or <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>).
If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, will match default weight initialization of
<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code></a>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>bias_initializer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The initializer for the bias vector
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">"zeros"</span></code> or <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>).
If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, will match default bias initialization of
<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Linear.html#torch.nn.Linear" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code></a>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><ul class="simple">
<li><p><strong>input:</strong> features <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.106em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mo>∗</mo><mo>,</mo><msub><mi>F</mi><mrow data-mjx-texclass="ORD"><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span></p></li>
<li><p><strong>output:</strong> features <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.106em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mo>∗</mo><mo>,</mo><msub><mi>F</mi><mrow data-mjx-texclass="ORD"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.Linear.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#Linear.reset_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.Linear.reset_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Resets all learnable parameters of the module.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.Linear.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#Linear.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.Linear.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.Tensor</em></a>) – The input features.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.HeteroLinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">HeteroLinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_sorted</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#HeteroLinear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.HeteroLinear" title="Permalink to this definition"></a></dt>
<dd><p>Applies separate linear transformations to the incoming data according
to types.</p>
<p>For type <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="3" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>κ</mi></math></mjx-assistive-mml></mjx-container></span>, it computes</p>
<div class="math notranslate nohighlight">
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="4" style="font-size: 114.5%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.247em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.378em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D416 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.247em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c22A4"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.347em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D41B TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mrow data-mjx-texclass="ORD"><mi>κ</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msubsup><mo>=</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mrow data-mjx-texclass="ORD"><mi>κ</mi></mrow></msub><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">W</mi></mrow><mrow data-mjx-texclass="ORD"><mi>κ</mi></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">⊤</mi></mrow></msubsup><mo>+</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">b</mi></mrow><mrow data-mjx-texclass="ORD"><mi>κ</mi></mrow></msub><mo>.</mo></math></mjx-assistive-mml></mjx-container></div>
<p>It supports lazy initialization and customizable weight and bias
initialization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of each input sample. Will be initialized
lazily in case it is given as <code class="xref py py-obj docutils literal notranslate"><span class="pre">-1</span></code>.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>num_types</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The number of types.</p></li>
<li><p><strong>is_sorted</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, assumes that
<code class="xref py py-obj docutils literal notranslate"><span class="pre">type_vec</span></code> is sorted. This avoids internal re-sorting of the
data and can improve runtime and memory efficiency.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.Linear</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><ul class="simple">
<li><p><strong>input:</strong>
features <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="5" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.106em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mo>∗</mo><mo>,</mo><msub><mi>F</mi><mrow data-mjx-texclass="ORD"><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>,
type vector <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="6" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mo>∗</mo><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span></p></li>
<li><p><strong>output:</strong> features <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="7" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em; margin-left: -0.106em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mo>∗</mo><mo>,</mo><msub><mi>F</mi><mrow data-mjx-texclass="ORD"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.HeteroLinear.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#HeteroLinear.reset_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.HeteroLinear.reset_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Resets all learnable parameters of the module.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.HeteroLinear.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_vec</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#HeteroLinear.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.HeteroLinear.forward" title="Permalink to this definition"></a></dt>
<dd><p>The forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.Tensor</em></a>) – The input features.</p></li>
<li><p><strong>type_vec</strong> (<a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.Tensor</em></a>) – A vector that maps each entry to a type.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.HeteroDictLinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">HeteroDictLinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#HeteroDictLinear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.HeteroDictLinear" title="Permalink to this definition"></a></dt>
<dd><p>Applies separate linear transformations to the incoming data
dictionary.</p>
<p>For key <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="8" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>κ</mi></math></mjx-assistive-mml></mjx-container></span>, it computes</p>
<div class="math notranslate nohighlight">
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="9" style="font-size: 114.5%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.247em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-var"><mjx-c class="mjx-c2032"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.378em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D431 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D416 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.247em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c22A4"></mjx-c></mjx-mi></mjx-texatom><mjx-spacer style="margin-top: 0.347em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D41B TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mrow data-mjx-texclass="ORD"><mi>κ</mi></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-alternate="1">′</mi></mrow></msubsup><mo>=</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mrow data-mjx-texclass="ORD"><mi>κ</mi></mrow></msub><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">W</mi></mrow><mrow data-mjx-texclass="ORD"><mi>κ</mi></mrow><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">⊤</mi></mrow></msubsup><mo>+</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">b</mi></mrow><mrow data-mjx-texclass="ORD"><mi>κ</mi></mrow></msub><mo>.</mo></math></mjx-assistive-mml></mjx-container></div>
<p>It supports lazy initialization and customizable weight and bias
initialization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>Dict</em><em>[</em><em>Any</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – Size of each input sample. If
passed an integer, <a class="reference external" href="https://docs.python.org/3/library/types.html#module-types" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">types</span></code></a> will be a mandatory argument.
initialized lazily in case it is given as <code class="xref py py-obj docutils literal notranslate"><span class="pre">-1</span></code>.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>types</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>optional</em>) – The keys of the input dictionary.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.Linear</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.HeteroDictLinear.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#HeteroDictLinear.reset_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.HeteroDictLinear.reset_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Resets all learnable parameters of the module.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.dense.HeteroDictLinear.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/linear.html#HeteroDictLinear.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.dense.HeteroDictLinear.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x_dict</strong> (<em>Dict</em><em>[</em><em>Any</em><em>, </em><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.Tensor</em></a><em>]</em>) – A dictionary holding input
features for each individual type.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="convolutional-layers">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id42" role="doc-backlink">Convolutional Layers</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html#torch_geometric.nn.conv.MessagePassing" title="torch_geometric.nn.conv.MessagePassing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MessagePassing</span></code></a></p></td>
<td><p>Base class for creating message passing layers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SimpleConv.html#torch_geometric.nn.conv.SimpleConv" title="torch_geometric.nn.conv.SimpleConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SimpleConv</span></code></a></p></td>
<td><p>A simple message passing operator that performs (non-trainable) propagation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html#torch_geometric.nn.conv.GCNConv" title="torch_geometric.nn.conv.GCNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GCNConv</span></code></a></p></td>
<td><p>The graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1609.02907">"Semi-supervised Classification with Graph Convolutional Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ChebConv.html#torch_geometric.nn.conv.ChebConv" title="torch_geometric.nn.conv.ChebConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ChebConv</span></code></a></p></td>
<td><p>The chebyshev spectral graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1606.09375">"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html#torch_geometric.nn.conv.SAGEConv" title="torch_geometric.nn.conv.SAGEConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SAGEConv</span></code></a></p></td>
<td><p>The GraphSAGE operator from the <a class="reference external" href="https://arxiv.org/abs/1706.02216">"Inductive Representation Learning on Large Graphs"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.CuGraphSAGEConv.html#torch_geometric.nn.conv.CuGraphSAGEConv" title="torch_geometric.nn.conv.CuGraphSAGEConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CuGraphSAGEConv</span></code></a></p></td>
<td><p></p><p>The GraphSAGE operator from the <a class="reference external" href="https://arxiv.org/abs/1706.02216">"Inductive Representation Learning on Large Graphs"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GraphConv.html#torch_geometric.nn.conv.GraphConv" title="torch_geometric.nn.conv.GraphConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GraphConv</span></code></a></p></td>
<td><p>The graph neural network operator from the <a class="reference external" href="https://arxiv.org/abs/1810.02244">"Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GravNetConv.html#torch_geometric.nn.conv.GravNetConv" title="torch_geometric.nn.conv.GravNetConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GravNetConv</span></code></a></p></td>
<td><p>The GravNet operator from the <a class="reference external" href="https://arxiv.org/abs/1902.07987">"Learning Representations of Irregular Particle-detector Geometry with Distance-weighted Graph Networks"</a> paper, where the graph is dynamically constructed using nearest neighbors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GatedGraphConv.html#torch_geometric.nn.conv.GatedGraphConv" title="torch_geometric.nn.conv.GatedGraphConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GatedGraphConv</span></code></a></p></td>
<td><p>The gated graph convolution operator from the <a class="reference external" href="https://arxiv.org/abs/1511.05493">"Gated Graph Sequence Neural Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ResGatedGraphConv.html#torch_geometric.nn.conv.ResGatedGraphConv" title="torch_geometric.nn.conv.ResGatedGraphConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ResGatedGraphConv</span></code></a></p></td>
<td><p>The residual gated graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1711.07553">"Residual Gated Graph ConvNets"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATConv.html#torch_geometric.nn.conv.GATConv" title="torch_geometric.nn.conv.GATConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GATConv</span></code></a></p></td>
<td><p>The graph attentional operator from the <a class="reference external" href="https://arxiv.org/abs/1710.10903">"Graph Attention Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.CuGraphGATConv.html#torch_geometric.nn.conv.CuGraphGATConv" title="torch_geometric.nn.conv.CuGraphGATConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CuGraphGATConv</span></code></a></p></td>
<td><p></p><p>The graph attentional operator from the <a class="reference external" href="https://arxiv.org/abs/1710.10903">"Graph Attention Networks"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FusedGATConv.html#torch_geometric.nn.conv.FusedGATConv" title="torch_geometric.nn.conv.FusedGATConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FusedGATConv</span></code></a></p></td>
<td><p>The fused graph attention operator from the <a class="reference external" href="https://proceedings.mlsys.org/paper/2022/file/9a1158154dfa42caddbd0694a4e9bdc8-Paper.pdf">"Understanding GNN Computational Graph: A Coordinated Computation, IO, and Memory Perspective"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATv2Conv.html#torch_geometric.nn.conv.GATv2Conv" title="torch_geometric.nn.conv.GATv2Conv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GATv2Conv</span></code></a></p></td>
<td><p>The GATv2 operator from the <a class="reference external" href="https://arxiv.org/abs/2105.14491">"How Attentive are Graph Attention Networks?"</a> paper, which fixes the static attention problem of the standard <code class="xref py py-class docutils literal notranslate"><span class="pre">GATConv</span></code> layer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.TransformerConv.html#torch_geometric.nn.conv.TransformerConv" title="torch_geometric.nn.conv.TransformerConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TransformerConv</span></code></a></p></td>
<td><p>The graph transformer operator from the <a class="reference external" href="https://arxiv.org/abs/2009.03509">"Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.AGNNConv.html#torch_geometric.nn.conv.AGNNConv" title="torch_geometric.nn.conv.AGNNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AGNNConv</span></code></a></p></td>
<td><p>The graph attentional propagation layer from the <a class="reference external" href="https://arxiv.org/abs/1803.03735">"Attention-based Graph Neural Network for Semi-Supervised Learning"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.TAGConv.html#torch_geometric.nn.conv.TAGConv" title="torch_geometric.nn.conv.TAGConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TAGConv</span></code></a></p></td>
<td><p>The topology adaptive graph convolutional networks operator from the <a class="reference external" href="https://arxiv.org/abs/1710.10370">"Topology Adaptive Graph Convolutional Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINConv.html#torch_geometric.nn.conv.GINConv" title="torch_geometric.nn.conv.GINConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GINConv</span></code></a></p></td>
<td><p>The graph isomorphism operator from the <a class="reference external" href="https://arxiv.org/abs/1810.00826">"How Powerful are Graph Neural Networks?"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINEConv.html#torch_geometric.nn.conv.GINEConv" title="torch_geometric.nn.conv.GINEConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GINEConv</span></code></a></p></td>
<td><p>The modified <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINConv.html#torch_geometric.nn.conv.GINConv" title="torch_geometric.nn.conv.GINConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">GINConv</span></code></a> operator from the <a class="reference external" href="https://arxiv.org/abs/1905.12265">"Strategies for Pre-training Graph Neural Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ARMAConv.html#torch_geometric.nn.conv.ARMAConv" title="torch_geometric.nn.conv.ARMAConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ARMAConv</span></code></a></p></td>
<td><p>The ARMA graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1901.01343">"Graph Neural Networks with Convolutional ARMA Filters"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SGConv.html#torch_geometric.nn.conv.SGConv" title="torch_geometric.nn.conv.SGConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SGConv</span></code></a></p></td>
<td><p>The simple graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1902.07153">"Simplifying Graph Convolutional Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SSGConv.html#torch_geometric.nn.conv.SSGConv" title="torch_geometric.nn.conv.SSGConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SSGConv</span></code></a></p></td>
<td><p>The simple spectral graph convolutional operator from the <a class="reference external" href="https://openreview.net/forum?id=CYO5T-YjWZV">"Simple Spectral Graph Convolution"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.APPNP.html#torch_geometric.nn.conv.APPNP" title="torch_geometric.nn.conv.APPNP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">APPNP</span></code></a></p></td>
<td><p>The approximate personalized propagation of neural predictions layer from the <a class="reference external" href="https://arxiv.org/abs/1810.05997">"Predict then Propagate: Graph Neural Networks meet Personalized PageRank"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MFConv.html#torch_geometric.nn.conv.MFConv" title="torch_geometric.nn.conv.MFConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MFConv</span></code></a></p></td>
<td><p>The graph neural network operator from the <a class="reference external" href="https://arxiv.org/abs/1509.09292">"Convolutional Networks on Graphs for Learning Molecular Fingerprints"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.RGCNConv.html#torch_geometric.nn.conv.RGCNConv" title="torch_geometric.nn.conv.RGCNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RGCNConv</span></code></a></p></td>
<td><p>The relational graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1703.06103">"Modeling Relational Data with Graph Convolutional Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FastRGCNConv.html#torch_geometric.nn.conv.FastRGCNConv" title="torch_geometric.nn.conv.FastRGCNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FastRGCNConv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.RGCNConv.html#torch_geometric.nn.conv.RGCNConv" title="torch_geometric.nn.conv.RGCNConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">RGCNConv</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.CuGraphRGCNConv.html#torch_geometric.nn.conv.CuGraphRGCNConv" title="torch_geometric.nn.conv.CuGraphRGCNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CuGraphRGCNConv</span></code></a></p></td>
<td><p></p><p>The relational graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1703.06103">"Modeling Relational Data with Graph Convolutional Networks"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.RGATConv.html#torch_geometric.nn.conv.RGATConv" title="torch_geometric.nn.conv.RGATConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RGATConv</span></code></a></p></td>
<td><p>The relational graph attentional operator from the <a class="reference external" href="https://arxiv.org/abs/1904.05811">"Relational Graph Attention Networks"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SignedConv.html#torch_geometric.nn.conv.SignedConv" title="torch_geometric.nn.conv.SignedConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SignedConv</span></code></a></p></td>
<td><p>The signed graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1808.06354">"Signed Graph Convolutional Network"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.DNAConv.html#torch_geometric.nn.conv.DNAConv" title="torch_geometric.nn.conv.DNAConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DNAConv</span></code></a></p></td>
<td><p>The dynamic neighborhood aggregation operator from the <a class="reference external" href="https://arxiv.org/abs/1904.04849">"Just Jump: Towards Dynamic Neighborhood Aggregation in Graph Neural Networks"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PointNetConv.html#torch_geometric.nn.conv.PointNetConv" title="torch_geometric.nn.conv.PointNetConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PointNetConv</span></code></a></p></td>
<td><p>The PointNet set layer from the <a class="reference external" href="https://arxiv.org/abs/1612.00593">"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"</a> and <a class="reference external" href="https://arxiv.org/abs/1706.02413">"PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"</a> papers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GMMConv.html#torch_geometric.nn.conv.GMMConv" title="torch_geometric.nn.conv.GMMConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GMMConv</span></code></a></p></td>
<td><p>The gaussian mixture model convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1611.08402">"Geometric Deep Learning on Graphs and Manifolds using Mixture Model CNNs"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SplineConv.html#torch_geometric.nn.conv.SplineConv" title="torch_geometric.nn.conv.SplineConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplineConv</span></code></a></p></td>
<td><p>The spline-based convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1711.08920">"SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.NNConv.html#torch_geometric.nn.conv.NNConv" title="torch_geometric.nn.conv.NNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NNConv</span></code></a></p></td>
<td><p>The continuous kernel-based convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1704.01212">"Neural Message Passing for Quantum Chemistry"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.CGConv.html#torch_geometric.nn.conv.CGConv" title="torch_geometric.nn.conv.CGConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CGConv</span></code></a></p></td>
<td><p>The crystal graph convolutional operator from the <a class="reference external" href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.145301">"Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.EdgeConv.html#torch_geometric.nn.conv.EdgeConv" title="torch_geometric.nn.conv.EdgeConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EdgeConv</span></code></a></p></td>
<td><p>The edge convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1801.07829">"Dynamic Graph CNN for Learning on Point Clouds"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.DynamicEdgeConv.html#torch_geometric.nn.conv.DynamicEdgeConv" title="torch_geometric.nn.conv.DynamicEdgeConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DynamicEdgeConv</span></code></a></p></td>
<td><p></p><p>The dynamic edge convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1801.07829">"Dynamic Graph CNN for Learning on Point Clouds"</a> paper (see <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.EdgeConv.html#torch_geometric.nn.conv.EdgeConv" title="torch_geometric.nn.conv.EdgeConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.EdgeConv</span></code></a>), where the graph is dynamically constructed using nearest neighbors in the feature space.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.XConv.html#torch_geometric.nn.conv.XConv" title="torch_geometric.nn.conv.XConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">XConv</span></code></a></p></td>
<td><p>The convolutional operator on <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="10" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow></math></mjx-assistive-mml></mjx-container></span>-transformed points from the <a class="reference external" href="https://arxiv.org/abs/1801.07791">"PointCNN: Convolution On X-Transformed Points"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PPFConv.html#torch_geometric.nn.conv.PPFConv" title="torch_geometric.nn.conv.PPFConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PPFConv</span></code></a></p></td>
<td><p>The PPFNet operator from the <a class="reference external" href="https://arxiv.org/abs/1802.02669">"PPFNet: Global Context Aware Local Features for Robust 3D Point Matching"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FeaStConv.html#torch_geometric.nn.conv.FeaStConv" title="torch_geometric.nn.conv.FeaStConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FeaStConv</span></code></a></p></td>
<td><p>The (translation-invariant) feature-steered convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1706.05206">"FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PointTransformerConv.html#torch_geometric.nn.conv.PointTransformerConv" title="torch_geometric.nn.conv.PointTransformerConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PointTransformerConv</span></code></a></p></td>
<td><p>The Point Transformer layer from the <a class="reference external" href="https://arxiv.org/abs/2012.09164">"Point Transformer"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HypergraphConv.html#torch_geometric.nn.conv.HypergraphConv" title="torch_geometric.nn.conv.HypergraphConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HypergraphConv</span></code></a></p></td>
<td><p>The hypergraph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1901.08150">"Hypergraph Convolution and Hypergraph Attention"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.LEConv.html#torch_geometric.nn.conv.LEConv" title="torch_geometric.nn.conv.LEConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LEConv</span></code></a></p></td>
<td><p>The local extremum graph neural network operator from the <a class="reference external" href="https://arxiv.org/abs/1911.07979">"ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PNAConv.html#torch_geometric.nn.conv.PNAConv" title="torch_geometric.nn.conv.PNAConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PNAConv</span></code></a></p></td>
<td><p>The Principal Neighbourhood Aggregation graph convolution operator from the <a class="reference external" href="https://arxiv.org/abs/2004.05718">"Principal Neighbourhood Aggregation for Graph Nets"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.ClusterGCNConv.html#torch_geometric.nn.conv.ClusterGCNConv" title="torch_geometric.nn.conv.ClusterGCNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ClusterGCNConv</span></code></a></p></td>
<td><p>The ClusterGCN graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1905.07953">"Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GENConv.html#torch_geometric.nn.conv.GENConv" title="torch_geometric.nn.conv.GENConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GENConv</span></code></a></p></td>
<td><p>The GENeralized Graph Convolution (GENConv) from the <a class="reference external" href="https://arxiv.org/abs/2006.07739">"DeeperGCN: All You Need to Train Deeper GCNs"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCN2Conv.html#torch_geometric.nn.conv.GCN2Conv" title="torch_geometric.nn.conv.GCN2Conv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GCN2Conv</span></code></a></p></td>
<td><p>The graph convolutional operator with initial residual connections and identity mapping (GCNII) from the <a class="reference external" href="https://arxiv.org/abs/2007.02133">"Simple and Deep Graph Convolutional Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PANConv.html#torch_geometric.nn.conv.PANConv" title="torch_geometric.nn.conv.PANConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PANConv</span></code></a></p></td>
<td><p>The path integral based convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/2006.16811">"Path Integral Based Convolution and Pooling for Graph Neural Networks"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.WLConv.html#torch_geometric.nn.conv.WLConv" title="torch_geometric.nn.conv.WLConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">WLConv</span></code></a></p></td>
<td><p>The Weisfeiler Lehman (WL) operator from the <a class="reference external" href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf">"A Reduction of a Graph to a Canonical Form and an Algebra Arising During this Reduction"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.WLConvContinuous.html#torch_geometric.nn.conv.WLConvContinuous" title="torch_geometric.nn.conv.WLConvContinuous"><code class="xref py py-obj docutils literal notranslate"><span class="pre">WLConvContinuous</span></code></a></p></td>
<td><p>The Weisfeiler Lehman operator from the <a class="reference external" href="https://arxiv.org/abs/1906.01277">"Wasserstein Weisfeiler-Lehman Graph Kernels"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FiLMConv.html#torch_geometric.nn.conv.FiLMConv" title="torch_geometric.nn.conv.FiLMConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FiLMConv</span></code></a></p></td>
<td><p>The FiLM graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1906.12192">"GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SuperGATConv.html#torch_geometric.nn.conv.SuperGATConv" title="torch_geometric.nn.conv.SuperGATConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SuperGATConv</span></code></a></p></td>
<td><p>The self-supervised graph attentional operator from the <a class="reference external" href="https://openreview.net/forum?id=Wi5KUNlqWty">"How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.FAConv.html#torch_geometric.nn.conv.FAConv" title="torch_geometric.nn.conv.FAConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FAConv</span></code></a></p></td>
<td><p>The Frequency Adaptive Graph Convolution operator from the <a class="reference external" href="https://arxiv.org/abs/2101.00797">"Beyond Low-Frequency Information in Graph Convolutional Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.EGConv.html#torch_geometric.nn.conv.EGConv" title="torch_geometric.nn.conv.EGConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EGConv</span></code></a></p></td>
<td><p>The Efficient Graph Convolution from the <a class="reference external" href="https://arxiv.org/abs/2104.01481">"Adaptive Filters and Aggregator Fusion for Efficient Graph Convolutions"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PDNConv.html#torch_geometric.nn.conv.PDNConv" title="torch_geometric.nn.conv.PDNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PDNConv</span></code></a></p></td>
<td><p>The pathfinder discovery network convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/2010.12878">"Pathfinder Discovery Networks for Neural Message Passing"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GeneralConv.html#torch_geometric.nn.conv.GeneralConv" title="torch_geometric.nn.conv.GeneralConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GeneralConv</span></code></a></p></td>
<td><p>A general GNN layer adapted from the <a class="reference external" href="https://arxiv.org/abs/2011.08843">"Design Space for Graph Neural Networks"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HGTConv.html#torch_geometric.nn.conv.HGTConv" title="torch_geometric.nn.conv.HGTConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HGTConv</span></code></a></p></td>
<td><p>The Heterogeneous Graph Transformer (HGT) operator from the <a class="reference external" href="https://arxiv.org/abs/2003.01332">"Heterogeneous Graph Transformer"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HEATConv.html#torch_geometric.nn.conv.HEATConv" title="torch_geometric.nn.conv.HEATConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HEATConv</span></code></a></p></td>
<td><p>The heterogeneous edge-enhanced graph attentional operator from the <a class="reference external" href="https://arxiv.org/abs/2106.07161">"Heterogeneous Edge-Enhanced Graph Attention Network For Multi-Agent Trajectory Prediction"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HeteroConv.html#torch_geometric.nn.conv.HeteroConv" title="torch_geometric.nn.conv.HeteroConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HeteroConv</span></code></a></p></td>
<td><p>A generic wrapper for computing graph convolution on heterogeneous graphs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HANConv.html#torch_geometric.nn.conv.HANConv" title="torch_geometric.nn.conv.HANConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HANConv</span></code></a></p></td>
<td><p>The Heterogenous Graph Attention Operator from the <a class="reference external" href="https://arxiv.org/abs/1903.07293">"Heterogenous Graph Attention Network"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.LGConv.html#torch_geometric.nn.conv.LGConv" title="torch_geometric.nn.conv.LGConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LGConv</span></code></a></p></td>
<td><p>The Light Graph Convolution (LGC) operator from the <a class="reference external" href="https://arxiv.org/abs/2002.02126">"LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PointGNNConv.html#torch_geometric.nn.conv.PointGNNConv" title="torch_geometric.nn.conv.PointGNNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PointGNNConv</span></code></a></p></td>
<td><p>The PointGNN operator from the <a class="reference external" href="https://arxiv.org/abs/2003.01251">"Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GPSConv.html#torch_geometric.nn.conv.GPSConv" title="torch_geometric.nn.conv.GPSConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GPSConv</span></code></a></p></td>
<td><p>The general, powerful, scalable (GPS) graph transformer layer from the <a class="reference external" href="https://arxiv.org/abs/2205.12454">"Recipe for a General, Powerful, Scalable Graph Transformer"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.AntiSymmetricConv.html#torch_geometric.nn.conv.AntiSymmetricConv" title="torch_geometric.nn.conv.AntiSymmetricConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AntiSymmetricConv</span></code></a></p></td>
<td><p>The anti-symmetric graph convolutional operator from the <a class="reference external" href="https://openreview.net/forum?id=J3Y7cgZOOS">"Anti-Symmetric DGN: a stable architecture for Deep Graph Networks"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.DirGNNConv.html#torch_geometric.nn.conv.DirGNNConv" title="torch_geometric.nn.conv.DirGNNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DirGNNConv</span></code></a></p></td>
<td><p>A generic wrapper for computing graph convolution on directed graphs as described in the <a class="reference external" href="https://arxiv.org/abs/2305.10498">"Edge Directionality Improves Learning on Heterophilic Graphs"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MixHopConv.html#torch_geometric.nn.conv.MixHopConv" title="torch_geometric.nn.conv.MixHopConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MixHopConv</span></code></a></p></td>
<td><p>The Mix-Hop graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1905.00067">"MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing"</a> paper.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="aggregation-operators">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id43" role="doc-backlink">Aggregation Operators</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#aggregation-operators" title="Permalink to this heading"></a></h2>
<p>Aggregation functions play an important role in the message passing framework and the readout functions of Graph Neural Networks.
Specifically, many works in the literature (<a class="reference external" href="https://arxiv.org/abs/1706.02216">Hamilton et al. (2017)</a>, <a class="reference external" href="https://arxiv.org/abs/1810.00826">Xu et al. (2018)</a>, <a class="reference external" href="https://arxiv.org/abs/2004.05718">Corso et al. (2020)</a>, <a class="reference external" href="https://arxiv.org/abs/2006.07739">Li et al. (2020)</a>, <a class="reference external" href="https://arxiv.org/abs/2104.01481">Tailor et al. (2021)</a>) demonstrate that the choice of aggregation functions contributes significantly to the representational power and performance of the model.
For example, <strong>mean aggregation</strong> captures the distribution (or proportions) of elements, <strong>max aggregation</strong> proves to be advantageous to identify representative elements, and <strong>sum aggregation</strong> enables the learning of structural graph properties (<a class="reference external" href="https://arxiv.org/abs/1810.00826">Xu et al. (2018)</a>).
Recent works also show that using <strong>multiple aggregations</strong> (<a class="reference external" href="https://arxiv.org/abs/2004.05718">Corso et al. (2020)</a>, <a class="reference external" href="https://arxiv.org/abs/2104.01481">Tailor et al. (2021)</a>) and <strong>learnable aggregations</strong> (<a class="reference external" href="https://arxiv.org/abs/2006.07739">Li et al. (2020)</a>) can potentially provide substantial improvements.
Another line of research studies optimization-based and implicitly-defined aggregations (<a class="reference external" href="https://arxiv.org/abs/2202.12795">Bartunov et al. (2022)</a>).
Furthermore, an interesting discussion concerns the trade-off between representational power (usually gained through learnable functions implemented as neural networks) and the formal property of permutation invariance (<a class="reference external" href="https://arxiv.org/abs/2211.04952">Buterez et al. (2022)</a>).</p>
<p>To facilitate further experimentation and unify the concepts of aggregation within GNNs across both <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html#torch_geometric.nn.conv.MessagePassing" title="torch_geometric.nn.conv.MessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">MessagePassing</span></code></a> and global readouts, we have made the concept of <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.Aggregation.html#torch_geometric.nn.aggr.Aggregation" title="torch_geometric.nn.aggr.Aggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Aggregation</span></code></a> a first-class principle in <span class="inline-logo pyg">PyG</span>.
As of now, <span class="inline-logo pyg">PyG</span> provides support for various aggregations — from rather simple ones (<em>e.g.</em>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">mean</span></code>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#max" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#sum" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sum</span></code></a>), to advanced ones (<em>e.g.</em>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">median</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">var</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">std</span></code>), learnable ones (<em>e.g.</em>, <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.SoftmaxAggregation.html#torch_geometric.nn.aggr.SoftmaxAggregation" title="torch_geometric.nn.aggr.SoftmaxAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">SoftmaxAggregation</span></code></a>, <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.PowerMeanAggregation.html#torch_geometric.nn.aggr.PowerMeanAggregation" title="torch_geometric.nn.aggr.PowerMeanAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">PowerMeanAggregation</span></code></a>, <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.SetTransformerAggregation.html#torch_geometric.nn.aggr.SetTransformerAggregation" title="torch_geometric.nn.aggr.SetTransformerAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">SetTransformerAggregation</span></code></a>), and exotic ones (<em>e.g.</em>, <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MLPAggregation.html#torch_geometric.nn.aggr.MLPAggregation" title="torch_geometric.nn.aggr.MLPAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">MLPAggregation</span></code></a>, <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.LSTMAggregation.html#torch_geometric.nn.aggr.LSTMAggregation" title="torch_geometric.nn.aggr.LSTMAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSTMAggregation</span></code></a>, <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.SortAggregation.html#torch_geometric.nn.aggr.SortAggregation" title="torch_geometric.nn.aggr.SortAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">SortAggregation</span></code></a>, <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.EquilibriumAggregation.html#torch_geometric.nn.aggr.EquilibriumAggregation" title="torch_geometric.nn.aggr.EquilibriumAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">EquilibriumAggregation</span></code></a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell2"><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">aggr</span>

<span class="c1"># Simple aggregations:</span>
<span class="n">mean_aggr</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">MeanAggregation</span><span class="p">()</span>
<span class="n">max_aggr</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">MaxAggregation</span><span class="p">()</span>

<span class="c1"># Advanced aggregations:</span>
<span class="n">median_aggr</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">MedianAggregation</span><span class="p">()</span>

<span class="c1"># Learnable aggregations:</span>
<span class="n">softmax_aggr</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">SoftmaxAggregation</span><span class="p">(</span><span class="n">learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">powermean_aggr</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">PowerMeanAggregation</span><span class="p">(</span><span class="n">learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Exotic aggregations:</span>
<span class="n">lstm_aggr</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">LSTMAggregation</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=...</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=...</span><span class="p">)</span>
<span class="n">sort_aggr</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">SortAggregation</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell2">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>We can then easily apply these aggregations over a batch of sets of potentially varying size.
For this, an <code class="xref py py-obj docutils literal notranslate"><span class="pre">index</span></code> vector defines the mapping from input elements to their location in the output:</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell3"><span></span><span class="c1"># Feature matrix holding 1000 elements with 64 features each:</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="c1"># Randomly assign elements to 100 sets:</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="p">))</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">mean_aggr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>  <span class="c1">#  Output shape: [100, 64]</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell3">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>Notably, all aggregations share the same set of forward arguments, as described in detail in the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.Aggregation.html#torch_geometric.nn.aggr.Aggregation" title="torch_geometric.nn.aggr.Aggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.aggr.Aggregation</span></code></a> base class.</p>
<p>Each of the provided aggregations can be used within <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html#torch_geometric.nn.conv.MessagePassing" title="torch_geometric.nn.conv.MessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">MessagePassing</span></code></a> as well as for hierachical/global pooling to obtain graph-level representations:</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell4"><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">MessagePassing</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MyConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="c1"># Use a learnable softmax neighborhood aggregation:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="n">aggr</span><span class="o">.</span><span class="n">SoftmaxAggregation</span><span class="p">(</span><span class="n">learn</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

   <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
       <span class="o">....</span>


<span class="k">class</span><span class="w"> </span><span class="nc">MyGNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">MyConv</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="c1"># Use a global sort aggregation:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">SortAggregation</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

     <span class="k">def</span><span class="w"> </span><span class="nf">foward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
         <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
         <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
         <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
         <span class="k">return</span> <span class="n">x</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell4">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>In addition, the aggregation package of <span class="inline-logo pyg">PyG</span> introduces two new concepts:
First, aggregations can be <strong>resolved from pure strings</strong> via a lookup table, following the design principles of the <a class="reference external" href="https://github.com/cthoyt/class-resolver">class-resolver</a> library, <em>e.g.</em>, by simply passing in <code class="xref py py-obj docutils literal notranslate"><span class="pre">"median"</span></code> to the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html#torch_geometric.nn.conv.MessagePassing" title="torch_geometric.nn.conv.MessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">MessagePassing</span></code></a> module.
This will automatically resolve to the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MedianAggregation.html#torch_geometric.nn.aggr.MedianAggregation" title="torch_geometric.nn.aggr.MedianAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MedianAggregation</span></code></a> class:</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell5"><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s2">"median"</span><span class="p">)</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell5">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>Secondly, <strong>multiple aggregations</strong> can be combined and stacked via the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MultiAggregation.html#torch_geometric.nn.aggr.MultiAggregation" title="torch_geometric.nn.aggr.MultiAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAggregation</span></code></a> module in order to enhance the representational power of GNNs (<a class="reference external" href="https://arxiv.org/abs/2004.05718">Corso et al. (2020)</a>, <a class="reference external" href="https://arxiv.org/abs/2104.01481">Tailor et al. (2021)</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell6"><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="c1"># Combines a set of aggregations and concatenates their results,</span>
        <span class="c1"># i.e. its output will be `[num_nodes, 3 * out_channels]` here.</span>
        <span class="c1"># Note that the interface also supports automatic resolution.</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="n">aggr</span><span class="o">.</span><span class="n">MultiAggregation</span><span class="p">(</span>
            <span class="p">[</span><span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="n">aggr</span><span class="o">.</span><span class="n">SoftmaxAggregation</span><span class="p">(</span><span class="n">learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)]))</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell6">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>Importantly, <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MultiAggregation.html#torch_geometric.nn.aggr.MultiAggregation" title="torch_geometric.nn.aggr.MultiAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAggregation</span></code></a> provides various options to combine the outputs of its underlying aggegations (<em>e.g.</em>, using concatenation, summation, attention, …) via its <code class="xref py py-obj docutils literal notranslate"><span class="pre">mode</span></code> argument.
The default <code class="xref py py-obj docutils literal notranslate"><span class="pre">mode</span></code> performs concatenation (<code class="xref py py-obj docutils literal notranslate"><span class="pre">"cat"</span></code>).
For combining via attention, we need to additionally specify the <code class="xref py py-obj docutils literal notranslate"><span class="pre">in_channels</span></code> <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_channels</span></code>, and <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_heads</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell7"><span></span><span class="n">multi_aggr</span> <span class="o">=</span> <span class="n">aggr</span><span class="o">.</span><span class="n">MultiAggregation</span><span class="p">(</span>
    <span class="n">aggrs</span><span class="o">=</span><span class="p">[</span><span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">],</span>
    <span class="n">mode</span><span class="o">=</span><span class="s1">'attn'</span><span class="p">,</span>
    <span class="n">mode_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
<span class="p">)</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell7">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>If aggregations are given as a list, they will be automatically resolved to a <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MultiAggregation.html#torch_geometric.nn.aggr.MultiAggregation" title="torch_geometric.nn.aggr.MultiAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiAggregation</span></code></a>, <em>e.g.</em>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">aggr=['mean',</span> <span class="pre">'std',</span> <span class="pre">'median']</span></code>.</p>
<p>Finally, we added full support for customization of aggregations into the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html#torch_geometric.nn.conv.SAGEConv" title="torch_geometric.nn.conv.SAGEConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">SAGEConv</span></code></a> layer — simply override its <code class="xref py py-obj docutils literal notranslate"><span class="pre">aggr</span></code> argument and <strong>utilize the power of aggregation within your GNN</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can read more about the <code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.aggr</span></code> package in this <a class="reference external" href="https://medium.com/@pytorch_geometric/a-principled-approach-to-aggregations-983c086b10b3">blog post</a>.</p>
</div>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.Aggregation.html#torch_geometric.nn.aggr.Aggregation" title="torch_geometric.nn.aggr.Aggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Aggregation</span></code></a></p></td>
<td><p>An abstract base class for implementing custom aggregations.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MultiAggregation.html#torch_geometric.nn.aggr.MultiAggregation" title="torch_geometric.nn.aggr.MultiAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiAggregation</span></code></a></p></td>
<td><p></p><p>Performs aggregations with one or more aggregators and combines aggregated results, as described in the <a class="reference external" href="https://arxiv.org/abs/2004.05718">"Principal Neighbourhood Aggregation for Graph Nets"</a> and <a class="reference external" href="https://arxiv.org/abs/2104.01481">"Adaptive Filters and Aggregator Fusion for Efficient Graph Convolutions"</a> papers.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.SumAggregation.html#torch_geometric.nn.aggr.SumAggregation" title="torch_geometric.nn.aggr.SumAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SumAggregation</span></code></a></p></td>
<td><p>An aggregation operator that sums up features across a set of elements.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MeanAggregation.html#torch_geometric.nn.aggr.MeanAggregation" title="torch_geometric.nn.aggr.MeanAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MeanAggregation</span></code></a></p></td>
<td><p>An aggregation operator that averages features across a set of elements.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MaxAggregation.html#torch_geometric.nn.aggr.MaxAggregation" title="torch_geometric.nn.aggr.MaxAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MaxAggregation</span></code></a></p></td>
<td><p>An aggregation operator that takes the feature-wise maximum across a set of elements.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MinAggregation.html#torch_geometric.nn.aggr.MinAggregation" title="torch_geometric.nn.aggr.MinAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinAggregation</span></code></a></p></td>
<td><p>An aggregation operator that takes the feature-wise minimum across a set of elements.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MulAggregation.html#torch_geometric.nn.aggr.MulAggregation" title="torch_geometric.nn.aggr.MulAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MulAggregation</span></code></a></p></td>
<td><p>An aggregation operator that multiples features across a set of elements.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.VarAggregation.html#torch_geometric.nn.aggr.VarAggregation" title="torch_geometric.nn.aggr.VarAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VarAggregation</span></code></a></p></td>
<td><p>An aggregation operator that takes the feature-wise variance across a set of elements.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.StdAggregation.html#torch_geometric.nn.aggr.StdAggregation" title="torch_geometric.nn.aggr.StdAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StdAggregation</span></code></a></p></td>
<td><p>An aggregation operator that takes the feature-wise standard deviation across a set of elements.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.SoftmaxAggregation.html#torch_geometric.nn.aggr.SoftmaxAggregation" title="torch_geometric.nn.aggr.SoftmaxAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SoftmaxAggregation</span></code></a></p></td>
<td><p></p><p>The softmax aggregation operator based on a temperature term, as described in the <a class="reference external" href="https://arxiv.org/abs/2006.07739">"DeeperGCN: All You Need to Train Deeper GCNs"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.PowerMeanAggregation.html#torch_geometric.nn.aggr.PowerMeanAggregation" title="torch_geometric.nn.aggr.PowerMeanAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PowerMeanAggregation</span></code></a></p></td>
<td><p></p><p>The powermean aggregation operator based on a power term, as described in the <a class="reference external" href="https://arxiv.org/abs/2006.07739">"DeeperGCN: All You Need to Train Deeper GCNs"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MedianAggregation.html#torch_geometric.nn.aggr.MedianAggregation" title="torch_geometric.nn.aggr.MedianAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MedianAggregation</span></code></a></p></td>
<td><p>An aggregation operator that returns the feature-wise median of a set.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.QuantileAggregation.html#torch_geometric.nn.aggr.QuantileAggregation" title="torch_geometric.nn.aggr.QuantileAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QuantileAggregation</span></code></a></p></td>
<td><p>An aggregation operator that returns the feature-wise <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="11" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></mjx-assistive-mml></mjx-container></span>-th quantile of a set <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="12" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c58 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">X</mi></mrow></math></mjx-assistive-mml></mjx-container></span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.LSTMAggregation.html#torch_geometric.nn.aggr.LSTMAggregation" title="torch_geometric.nn.aggr.LSTMAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LSTMAggregation</span></code></a></p></td>
<td><p></p><p>Performs LSTM-style aggregation in which the elements to aggregate are interpreted as a sequence, as described in the <a class="reference external" href="https://arxiv.org/abs/1706.02216">"Inductive Representation Learning on Large Graphs"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.GRUAggregation.html#torch_geometric.nn.aggr.GRUAggregation" title="torch_geometric.nn.aggr.GRUAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRUAggregation</span></code></a></p></td>
<td><p>Performs GRU aggregation in which the elements to aggregate are interpreted as a sequence, as described in the <a class="reference external" href="https://arxiv.org/abs/2211.04952">"Graph Neural Networks with Adaptive Readouts"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.Set2Set.html#torch_geometric.nn.aggr.Set2Set" title="torch_geometric.nn.aggr.Set2Set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Set2Set</span></code></a></p></td>
<td><p>The Set2Set aggregation operator based on iterative content-based attention, as described in the <a class="reference external" href="https://arxiv.org/abs/1511.06391">"Order Matters: Sequence to sequence for Sets"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.DegreeScalerAggregation.html#torch_geometric.nn.aggr.DegreeScalerAggregation" title="torch_geometric.nn.aggr.DegreeScalerAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DegreeScalerAggregation</span></code></a></p></td>
<td><p></p><p>Combines one or more aggregators and transforms its output with one or more scalers as introduced in the <a class="reference external" href="https://arxiv.org/abs/2004.05718">"Principal Neighbourhood Aggregation for Graph Nets"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.SortAggregation.html#torch_geometric.nn.aggr.SortAggregation" title="torch_geometric.nn.aggr.SortAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SortAggregation</span></code></a></p></td>
<td><p>The pooling operator from the <a class="reference external" href="https://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf">"An End-to-End Deep Learning Architecture for Graph Classification"</a> paper, where node features are sorted in descending order based on their last feature channel.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.GraphMultisetTransformer.html#torch_geometric.nn.aggr.GraphMultisetTransformer" title="torch_geometric.nn.aggr.GraphMultisetTransformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GraphMultisetTransformer</span></code></a></p></td>
<td><p>The Graph Multiset Transformer pooling operator from the <a class="reference external" href="https://arxiv.org/abs/2102.11533">"Accurate Learning of Graph Representations with Graph Multiset Pooling"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.AttentionalAggregation.html#torch_geometric.nn.aggr.AttentionalAggregation" title="torch_geometric.nn.aggr.AttentionalAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AttentionalAggregation</span></code></a></p></td>
<td><p>The soft attention aggregation layer from the <a class="reference external" href="https://arxiv.org/abs/1904.12787">"Graph Matching Networks for Learning the Similarity of Graph Structured Objects"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.EquilibriumAggregation.html#torch_geometric.nn.aggr.EquilibriumAggregation" title="torch_geometric.nn.aggr.EquilibriumAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EquilibriumAggregation</span></code></a></p></td>
<td><p>The equilibrium aggregation layer from the <a class="reference external" href="https://arxiv.org/abs/2202.12795">"Equilibrium Aggregation: Encoding Sets via Optimization"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.MLPAggregation.html#torch_geometric.nn.aggr.MLPAggregation" title="torch_geometric.nn.aggr.MLPAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MLPAggregation</span></code></a></p></td>
<td><p></p><p>Performs MLP aggregation in which the elements to aggregate are flattened into a single vectorial representation, and are then processed by a Multi-Layer Perceptron (MLP), as described in the <a class="reference external" href="https://arxiv.org/abs/2211.04952">"Graph Neural Networks with Adaptive Readouts"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.DeepSetsAggregation.html#torch_geometric.nn.aggr.DeepSetsAggregation" title="torch_geometric.nn.aggr.DeepSetsAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DeepSetsAggregation</span></code></a></p></td>
<td><p></p><p>Performs Deep Sets aggregation in which the elements to aggregate are first transformed by a Multi-Layer Perceptron (MLP) <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="13" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D719 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D6AF TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ϕ</mi><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">Θ</mi></mrow></mrow></msub></math></mjx-assistive-mml></mjx-container></span>, summed, and then transformed by another MLP <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="14" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D70C TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D6AF TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ρ</mi><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">Θ</mi></mrow></mrow></msub></math></mjx-assistive-mml></mjx-container></span>, as suggested in the <a class="reference external" href="https://arxiv.org/abs/2211.04952">"Graph Neural Networks with Adaptive Readouts"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.SetTransformerAggregation.html#torch_geometric.nn.aggr.SetTransformerAggregation" title="torch_geometric.nn.aggr.SetTransformerAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SetTransformerAggregation</span></code></a></p></td>
<td><p></p><p>Performs "Set Transformer" aggregation in which the elements to aggregate are processed by multi-head attention blocks, as described in the <a class="reference external" href="https://arxiv.org/abs/2211.04952">"Graph Neural Networks with Adaptive Readouts"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.LCMAggregation.html#torch_geometric.nn.aggr.LCMAggregation" title="torch_geometric.nn.aggr.LCMAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LCMAggregation</span></code></a></p></td>
<td><p>The Learnable Commutative Monoid aggregation from the <a class="reference external" href="https://arxiv.org/abs/2212.08541">"Learnable Commutative Monoids for Graph Neural Networks"</a> paper, in which the elements are aggregated using a binary tree reduction with <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="15" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c4F TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-n"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-texatom space="2" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c56 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">O</mi></mrow><mo stretchy="false">(</mo><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mrow data-mjx-texclass="ORD"><mo stretchy="false">|</mo></mrow><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">V</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">|</mo></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span> depth.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.VariancePreservingAggregation.html#torch_geometric.nn.aggr.VariancePreservingAggregation" title="torch_geometric.nn.aggr.VariancePreservingAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VariancePreservingAggregation</span></code></a></p></td>
<td><p>Performs the Variance Preserving Aggregation (VPA) from the <a class="reference external" href="https://arxiv.org/abs/2403.04747">"GNN-VPA: A Variance-Preserving Aggregation Strategy for Graph Neural Networks"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.aggr.PatchTransformerAggregation.html#torch_geometric.nn.aggr.PatchTransformerAggregation" title="torch_geometric.nn.aggr.PatchTransformerAggregation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PatchTransformerAggregation</span></code></a></p></td>
<td><p>Performs patch transformer aggregation in which the elements to aggregate are processed by multi-head attention blocks across patches, as described in the <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3583780.3615059">"Simplifying Temporal Heterogeneous Network for Continuous-Time Link Prediction"</a> paper.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="normalization-layers">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id44" role="doc-backlink">Normalization Layers</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#normalization-layers" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.BatchNorm.html#torch_geometric.nn.norm.BatchNorm" title="torch_geometric.nn.norm.BatchNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BatchNorm</span></code></a></p></td>
<td><p>Applies batch normalization over a batch of features as described in the <a class="reference external" href="https://arxiv.org/abs/1502.03167">"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.HeteroBatchNorm.html#torch_geometric.nn.norm.HeteroBatchNorm" title="torch_geometric.nn.norm.HeteroBatchNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HeteroBatchNorm</span></code></a></p></td>
<td><p></p><p>Applies batch normalization over a batch of heterogeneous features as described in the <a class="reference external" href="https://arxiv.org/abs/1502.03167">"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.InstanceNorm.html#torch_geometric.nn.norm.InstanceNorm" title="torch_geometric.nn.norm.InstanceNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">InstanceNorm</span></code></a></p></td>
<td><p>Applies instance normalization over each individual example in a batch of node features as described in the <a class="reference external" href="https://arxiv.org/abs/1607.08022">"Instance Normalization: The Missing Ingredient for Fast Stylization"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.LayerNorm.html#torch_geometric.nn.norm.LayerNorm" title="torch_geometric.nn.norm.LayerNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LayerNorm</span></code></a></p></td>
<td><p>Applies layer normalization over each individual example in a batch of features as described in the <a class="reference external" href="https://arxiv.org/abs/1607.06450">"Layer Normalization"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.HeteroLayerNorm.html#torch_geometric.nn.norm.HeteroLayerNorm" title="torch_geometric.nn.norm.HeteroLayerNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HeteroLayerNorm</span></code></a></p></td>
<td><p></p><p>Applies layer normalization over each individual example in a batch of heterogeneous features as described in the <a class="reference external" href="https://arxiv.org/abs/1607.06450">"Layer Normalization"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.GraphNorm.html#torch_geometric.nn.norm.GraphNorm" title="torch_geometric.nn.norm.GraphNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GraphNorm</span></code></a></p></td>
<td><p>Applies graph normalization over individual graphs as described in the <a class="reference external" href="https://arxiv.org/abs/2009.03294">"GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.GraphSizeNorm.html#torch_geometric.nn.norm.GraphSizeNorm" title="torch_geometric.nn.norm.GraphSizeNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GraphSizeNorm</span></code></a></p></td>
<td><p>Applies Graph Size Normalization over each individual graph in a batch of node features as described in the <a class="reference external" href="https://arxiv.org/abs/2003.00982">"Benchmarking Graph Neural Networks"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.PairNorm.html#torch_geometric.nn.norm.PairNorm" title="torch_geometric.nn.norm.PairNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PairNorm</span></code></a></p></td>
<td><p>Applies pair normalization over node features as described in the <a class="reference external" href="https://arxiv.org/abs/1909.12223">"PairNorm: Tackling Oversmoothing in GNNs"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.MeanSubtractionNorm.html#torch_geometric.nn.norm.MeanSubtractionNorm" title="torch_geometric.nn.norm.MeanSubtractionNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MeanSubtractionNorm</span></code></a></p></td>
<td><p>Applies layer normalization by subtracting the mean from the inputs as described in the  <a class="reference external" href="https://arxiv.org/abs/2003.13663">"Revisiting 'Over-smoothing' in Deep GCNs"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.MessageNorm.html#torch_geometric.nn.norm.MessageNorm" title="torch_geometric.nn.norm.MessageNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MessageNorm</span></code></a></p></td>
<td><p>Applies message normalization over the aggregated messages as described in the <a class="reference external" href="https://arxiv.org/abs/2006.07739">"DeeperGCNs: All You Need to Train Deeper GCNs"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.DiffGroupNorm.html#torch_geometric.nn.norm.DiffGroupNorm" title="torch_geometric.nn.norm.DiffGroupNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DiffGroupNorm</span></code></a></p></td>
<td><p>The differentiable group normalization layer from the <a class="reference external" href="https://arxiv.org/abs/2006.06972">"Towards Deeper Graph Neural Networks with Differentiable Group Normalization"</a> paper, which normalizes node features group-wise via a learnable soft cluster assignment.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="pooling-layers">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id45" role="doc-backlink">Pooling Layers</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#pooling-layers" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.global_add_pool.html#torch_geometric.nn.pool.global_add_pool" title="torch_geometric.nn.pool.global_add_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_add_pool</span></code></a></p></td>
<td><p>Returns batch-wise graph-level-outputs by adding node features across the node dimension.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.global_mean_pool.html#torch_geometric.nn.pool.global_mean_pool" title="torch_geometric.nn.pool.global_mean_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_mean_pool</span></code></a></p></td>
<td><p>Returns batch-wise graph-level-outputs by averaging node features across the node dimension.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.global_max_pool.html#torch_geometric.nn.pool.global_max_pool" title="torch_geometric.nn.pool.global_max_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">global_max_pool</span></code></a></p></td>
<td><p>Returns batch-wise graph-level-outputs by taking the channel-wise maximum across the node dimension.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.KNNIndex.html#torch_geometric.nn.pool.KNNIndex" title="torch_geometric.nn.pool.KNNIndex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KNNIndex</span></code></a></p></td>
<td><p>A base class to perform fast <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="16" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-nearest neighbor search (<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="17" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-NN) via the <code class="xref py py-obj docutils literal notranslate"><span class="pre">faiss</span></code> library.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.L2KNNIndex.html#torch_geometric.nn.pool.L2KNNIndex" title="torch_geometric.nn.pool.L2KNNIndex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">L2KNNIndex</span></code></a></p></td>
<td><p>Performs fast <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="18" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-nearest neighbor search (<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="19" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-NN) based on the <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="20" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container></span> metric via the <code class="xref py py-obj docutils literal notranslate"><span class="pre">faiss</span></code> library.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.MIPSKNNIndex.html#torch_geometric.nn.pool.MIPSKNNIndex" title="torch_geometric.nn.pool.MIPSKNNIndex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MIPSKNNIndex</span></code></a></p></td>
<td><p>Performs fast <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="21" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-nearest neighbor search (<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="22" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-NN) based on the maximum inner product via the <code class="xref py py-obj docutils literal notranslate"><span class="pre">faiss</span></code> library.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.ApproxL2KNNIndex.html#torch_geometric.nn.pool.ApproxL2KNNIndex" title="torch_geometric.nn.pool.ApproxL2KNNIndex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ApproxL2KNNIndex</span></code></a></p></td>
<td><p>Performs fast approximate <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="23" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-nearest neighbor search (<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="24" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-NN) based on the the <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="25" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container></span> metric via the <code class="xref py py-obj docutils literal notranslate"><span class="pre">faiss</span></code> library.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.ApproxMIPSKNNIndex.html#torch_geometric.nn.pool.ApproxMIPSKNNIndex" title="torch_geometric.nn.pool.ApproxMIPSKNNIndex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ApproxMIPSKNNIndex</span></code></a></p></td>
<td><p>Performs fast approximate <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="26" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-nearest neighbor search (<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="27" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container></span>-NN) based on the maximum inner product via the <code class="xref py py-obj docutils literal notranslate"><span class="pre">faiss</span></code> library.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.TopKPooling.html#torch_geometric.nn.pool.TopKPooling" title="torch_geometric.nn.pool.TopKPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopKPooling</span></code></a></p></td>
<td><p><span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="28" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c70"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.229em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">top</mi></mrow><mi>k</mi></msub></math></mjx-assistive-mml></mjx-container></span> pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1905.05178">"Graph U-Nets"</a>, <a class="reference external" href="https://arxiv.org/abs/1811.01287">"Towards Sparse Hierarchical Graph Classifiers"</a> and <a class="reference external" href="https://arxiv.org/abs/1905.02850">"Understanding Attention and Generalization in Graph Neural Networks"</a> papers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.SAGPooling.html#torch_geometric.nn.pool.SAGPooling" title="torch_geometric.nn.pool.SAGPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SAGPooling</span></code></a></p></td>
<td><p></p><p>The self-attention pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1904.08082">"Self-Attention Graph Pooling"</a> and <a class="reference external" href="https://arxiv.org/abs/1905.02850">"Understanding Attention and Generalization in Graph Neural Networks"</a> papers.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.EdgePooling.html#torch_geometric.nn.pool.EdgePooling" title="torch_geometric.nn.pool.EdgePooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EdgePooling</span></code></a></p></td>
<td><p>The edge pooling operator from the <a class="reference external" href="https://graphreason.github.io/papers/17.pdf">"Towards Graph Pooling by Edge Contraction"</a> and <a class="reference external" href="https://arxiv.org/abs/1905.10990">"Edge Contraction Pooling for Graph Neural Networks"</a> papers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.ClusterPooling.html#torch_geometric.nn.pool.ClusterPooling" title="torch_geometric.nn.pool.ClusterPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ClusterPooling</span></code></a></p></td>
<td><p>The cluster pooling operator from the <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/paperurl">"Edge-Based Graph Component Pooling"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.ASAPooling.html#torch_geometric.nn.pool.ASAPooling" title="torch_geometric.nn.pool.ASAPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ASAPooling</span></code></a></p></td>
<td><p></p><p>The Adaptive Structure Aware Pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1911.07979">"ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.PANPooling.html#torch_geometric.nn.pool.PANPooling" title="torch_geometric.nn.pool.PANPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PANPooling</span></code></a></p></td>
<td><p></p><p>The path integral based pooling operator from the <a class="reference external" href="https://arxiv.org/abs/2006.16811">"Path Integral Based Convolution and Pooling for Graph Neural Networks"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.MemPooling.html#torch_geometric.nn.pool.MemPooling" title="torch_geometric.nn.pool.MemPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MemPooling</span></code></a></p></td>
<td><p>Memory based pooling layer from <a class="reference external" href="https://arxiv.org/abs/2002.09518">"Memory-Based Graph Networks"</a> paper, which learns a coarsened graph representation based on soft cluster assignments.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.max_pool.html#torch_geometric.nn.pool.max_pool" title="torch_geometric.nn.pool.max_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_pool</span></code></a></p></td>
<td><p>Pools and coarsens a graph given by the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> object according to the clustering defined in <code class="xref py py-attr docutils literal notranslate"><span class="pre">cluster</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.avg_pool.html#torch_geometric.nn.pool.avg_pool" title="torch_geometric.nn.pool.avg_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">avg_pool</span></code></a></p></td>
<td><p>Pools and coarsens a graph given by the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> object according to the clustering defined in <code class="xref py py-attr docutils literal notranslate"><span class="pre">cluster</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.max_pool_x.html#torch_geometric.nn.pool.max_pool_x" title="torch_geometric.nn.pool.max_pool_x"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_pool_x</span></code></a></p></td>
<td><p>Max-Pools node features according to the clustering defined in <code class="xref py py-attr docutils literal notranslate"><span class="pre">cluster</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.max_pool_neighbor_x.html#torch_geometric.nn.pool.max_pool_neighbor_x" title="torch_geometric.nn.pool.max_pool_neighbor_x"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_pool_neighbor_x</span></code></a></p></td>
<td><p>Max pools neighboring node features, where each feature in <code class="xref py py-obj docutils literal notranslate"><span class="pre">data.x</span></code> is replaced by the feature value with the maximum value from the central node and its neighbors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.avg_pool_x.html#torch_geometric.nn.pool.avg_pool_x" title="torch_geometric.nn.pool.avg_pool_x"><code class="xref py py-obj docutils literal notranslate"><span class="pre">avg_pool_x</span></code></a></p></td>
<td><p>Average pools node features according to the clustering defined in <code class="xref py py-attr docutils literal notranslate"><span class="pre">cluster</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.avg_pool_neighbor_x.html#torch_geometric.nn.pool.avg_pool_neighbor_x" title="torch_geometric.nn.pool.avg_pool_neighbor_x"><code class="xref py py-obj docutils literal notranslate"><span class="pre">avg_pool_neighbor_x</span></code></a></p></td>
<td><p>Average pools neighboring node features, where each feature in <code class="xref py py-obj docutils literal notranslate"><span class="pre">data.x</span></code> is replaced by the average feature values from the central node and its neighbors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.graclus.html#torch_geometric.nn.pool.graclus" title="torch_geometric.nn.pool.graclus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">graclus</span></code></a></p></td>
<td><p>A greedy clustering algorithm from the <a class="reference external" href="http://www.cs.utexas.edu/users/inderjit/public_papers/multilevel_pami.pdf">"Weighted Graph Cuts without Eigenvectors: A Multilevel Approach"</a> paper of picking an unmarked vertex and matching it with one of its unmarked neighbors (that maximizes its edge weight).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.voxel_grid.html#torch_geometric.nn.pool.voxel_grid" title="torch_geometric.nn.pool.voxel_grid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">voxel_grid</span></code></a></p></td>
<td><p>Voxel grid pooling from the, <em>e.g.</em>, <a class="reference external" href="https://arxiv.org/abs/1704.02901">Dynamic Edge-Conditioned Filters in Convolutional Networks on Graphs</a> paper, which overlays a regular grid of user-defined size over a point cloud and clusters all points within the same voxel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.fps.html#torch_geometric.nn.pool.fps" title="torch_geometric.nn.pool.fps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fps</span></code></a></p></td>
<td><p></p><p>A sampling algorithm from the <a class="reference external" href="https://arxiv.org/abs/1706.02413">"PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"</a> paper, which iteratively samples the most distant point with regard to the rest points.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.knn.html#torch_geometric.nn.pool.knn" title="torch_geometric.nn.pool.knn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">knn</span></code></a></p></td>
<td><p>Finds for each element in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code> the <code class="xref py py-obj docutils literal notranslate"><span class="pre">k</span></code> nearest points in <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.knn_graph.html#torch_geometric.nn.pool.knn_graph" title="torch_geometric.nn.pool.knn_graph"><code class="xref py py-obj docutils literal notranslate"><span class="pre">knn_graph</span></code></a></p></td>
<td><p>Computes graph edges to the nearest <code class="xref py py-obj docutils literal notranslate"><span class="pre">k</span></code> points.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.approx_knn.html#torch_geometric.nn.pool.approx_knn" title="torch_geometric.nn.pool.approx_knn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">approx_knn</span></code></a></p></td>
<td><p>Finds for each element in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code> the <code class="xref py py-obj docutils literal notranslate"><span class="pre">k</span></code> approximated nearest points in <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.approx_knn_graph.html#torch_geometric.nn.pool.approx_knn_graph" title="torch_geometric.nn.pool.approx_knn_graph"><code class="xref py py-obj docutils literal notranslate"><span class="pre">approx_knn_graph</span></code></a></p></td>
<td><p>Computes graph edges to the nearest approximated <code class="xref py py-obj docutils literal notranslate"><span class="pre">k</span></code> points.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.radius.html#torch_geometric.nn.pool.radius" title="torch_geometric.nn.pool.radius"><code class="xref py py-obj docutils literal notranslate"><span class="pre">radius</span></code></a></p></td>
<td><p>Finds for each element in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code> all points in <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> within distance <code class="xref py py-obj docutils literal notranslate"><span class="pre">r</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.radius_graph.html#torch_geometric.nn.pool.radius_graph" title="torch_geometric.nn.pool.radius_graph"><code class="xref py py-obj docutils literal notranslate"><span class="pre">radius_graph</span></code></a></p></td>
<td><p>Computes graph edges to all points within a given distance.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.nearest.html#torch_geometric.nn.pool.nearest" title="torch_geometric.nn.pool.nearest"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nearest</span></code></a></p></td>
<td><p>Finds for each element in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code> the <code class="xref py py-obj docutils literal notranslate"><span class="pre">k</span></code> nearest point in <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code>.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="unpooling-layers">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id46" role="doc-backlink">Unpooling Layers</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#unpooling-layers" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.unpool.knn_interpolate.html#torch_geometric.nn.unpool.knn_interpolate" title="torch_geometric.nn.unpool.knn_interpolate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">knn_interpolate</span></code></a></p></td>
<td><p></p><p>The k-NN interpolation from the <a class="reference external" href="https://arxiv.org/abs/1706.02413">"PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"</a> paper.</p>
<p></p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="models">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id47" role="doc-backlink">Models</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MLP.html#torch_geometric.nn.models.MLP" title="torch_geometric.nn.models.MLP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MLP</span></code></a></p></td>
<td><p>A Multi-Layer Perception (MLP) model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html#torch_geometric.nn.models.GCN" title="torch_geometric.nn.models.GCN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GCN</span></code></a></p></td>
<td><p></p><p>The Graph Neural Network from the <a class="reference external" href="https://arxiv.org/abs/1609.02907">"Semi-supervised Classification with Graph Convolutional Networks"</a> paper, using the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html#torch_geometric.nn.conv.GCNConv" title="torch_geometric.nn.conv.GCNConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">GCNConv</span></code></a> operator for message passing.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GraphSAGE.html#torch_geometric.nn.models.GraphSAGE" title="torch_geometric.nn.models.GraphSAGE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GraphSAGE</span></code></a></p></td>
<td><p></p><p>The Graph Neural Network from the <a class="reference external" href="https://arxiv.org/abs/1706.02216">"Inductive Representation Learning on Large Graphs"</a> paper, using the <code class="xref py py-class docutils literal notranslate"><span class="pre">SAGEConv</span></code> operator for message passing.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GIN.html#torch_geometric.nn.models.GIN" title="torch_geometric.nn.models.GIN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GIN</span></code></a></p></td>
<td><p></p><p>The Graph Neural Network from the <a class="reference external" href="https://arxiv.org/abs/1810.00826">"How Powerful are Graph Neural Networks?"</a> paper, using the <code class="xref py py-class docutils literal notranslate"><span class="pre">GINConv</span></code> operator for message passing.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GAT.html#torch_geometric.nn.models.GAT" title="torch_geometric.nn.models.GAT"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GAT</span></code></a></p></td>
<td><p></p><p>The Graph Neural Network from <a class="reference external" href="https://arxiv.org/abs/1710.10903">"Graph Attention Networks"</a> or <a class="reference external" href="https://arxiv.org/abs/2105.14491">"How Attentive are Graph Attention Networks?"</a> papers, using the <code class="xref py py-class docutils literal notranslate"><span class="pre">GATConv</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">GATv2Conv</span></code> operator for message passing, respectively.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.PNA.html#torch_geometric.nn.models.PNA" title="torch_geometric.nn.models.PNA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PNA</span></code></a></p></td>
<td><p></p><p>The Graph Neural Network from the <a class="reference external" href="https://arxiv.org/abs/2004.05718">"Principal Neighbourhood Aggregation for Graph Nets"</a> paper, using the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PNAConv.html#torch_geometric.nn.conv.PNAConv" title="torch_geometric.nn.conv.PNAConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">PNAConv</span></code></a> operator for message passing.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.EdgeCNN.html#torch_geometric.nn.models.EdgeCNN" title="torch_geometric.nn.models.EdgeCNN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EdgeCNN</span></code></a></p></td>
<td><p></p><p>The Graph Neural Network from the <a class="reference external" href="https://arxiv.org/abs/1801.07829">"Dynamic Graph CNN for Learning on Point Clouds"</a> paper, using the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.EdgeConv.html#torch_geometric.nn.conv.EdgeConv" title="torch_geometric.nn.conv.EdgeConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">EdgeConv</span></code></a> operator for message passing.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.JumpingKnowledge.html#torch_geometric.nn.models.JumpingKnowledge" title="torch_geometric.nn.models.JumpingKnowledge"><code class="xref py py-obj docutils literal notranslate"><span class="pre">JumpingKnowledge</span></code></a></p></td>
<td><p>The Jumping Knowledge layer aggregation module from the <a class="reference external" href="https://arxiv.org/abs/1806.03536">"Representation Learning on Graphs with Jumping Knowledge Networks"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.HeteroJumpingKnowledge.html#torch_geometric.nn.models.HeteroJumpingKnowledge" title="torch_geometric.nn.models.HeteroJumpingKnowledge"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HeteroJumpingKnowledge</span></code></a></p></td>
<td><p>A heterogeneous version of the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.JumpingKnowledge.html#torch_geometric.nn.models.JumpingKnowledge" title="torch_geometric.nn.models.JumpingKnowledge"><code class="xref py py-class docutils literal notranslate"><span class="pre">JumpingKnowledge</span></code></a> module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MetaLayer.html#torch_geometric.nn.models.MetaLayer" title="torch_geometric.nn.models.MetaLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MetaLayer</span></code></a></p></td>
<td><p>A meta layer for building any kind of graph network, inspired by the <a class="reference external" href="https://arxiv.org/abs/1806.01261">"Relational Inductive Biases, Deep Learning, and Graph Networks"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.Node2Vec.html#torch_geometric.nn.models.Node2Vec" title="torch_geometric.nn.models.Node2Vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Node2Vec</span></code></a></p></td>
<td><p>The Node2Vec model from the <a class="reference external" href="https://arxiv.org/abs/1607.00653">"node2vec: Scalable Feature Learning for Networks"</a> paper where random walks of length <code class="xref py py-obj docutils literal notranslate"><span class="pre">walk_length</span></code> are sampled in a given graph, and node embeddings are learned via negative sampling optimization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.DeepGraphInfomax.html#torch_geometric.nn.models.DeepGraphInfomax" title="torch_geometric.nn.models.DeepGraphInfomax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DeepGraphInfomax</span></code></a></p></td>
<td><p>The Deep Graph Infomax model from the <a class="reference external" href="https://arxiv.org/abs/1809.10341">"Deep Graph Infomax"</a> paper based on user-defined encoder and summary model <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="29" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c45 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">E</mi></mrow></math></mjx-assistive-mml></mjx-container></span> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="30" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container></span> respectively, and a corruption function <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="31" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c43 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">C</mi></mrow></math></mjx-assistive-mml></mjx-container></span>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.InnerProductDecoder.html#torch_geometric.nn.models.InnerProductDecoder" title="torch_geometric.nn.models.InnerProductDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">InnerProductDecoder</span></code></a></p></td>
<td><p>The inner product decoder from the <a class="reference external" href="https://arxiv.org/abs/1611.07308">"Variational Graph Auto-Encoders"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GAE.html#torch_geometric.nn.models.GAE" title="torch_geometric.nn.models.GAE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GAE</span></code></a></p></td>
<td><p></p><p>The Graph Auto-Encoder model from the <a class="reference external" href="https://arxiv.org/abs/1611.07308">"Variational Graph Auto-Encoders"</a> paper based on user-defined encoder and decoder models.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.VGAE.html#torch_geometric.nn.models.VGAE" title="torch_geometric.nn.models.VGAE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VGAE</span></code></a></p></td>
<td><p></p><p>The Variational Graph Auto-Encoder model from the <a class="reference external" href="https://arxiv.org/abs/1611.07308">"Variational Graph Auto-Encoders"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.ARGA.html#torch_geometric.nn.models.ARGA" title="torch_geometric.nn.models.ARGA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ARGA</span></code></a></p></td>
<td><p>The Adversarially Regularized Graph Auto-Encoder model from the <a class="reference external" href="https://arxiv.org/abs/1802.04407">"Adversarially Regularized Graph Autoencoder for Graph Embedding"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.ARGVA.html#torch_geometric.nn.models.ARGVA" title="torch_geometric.nn.models.ARGVA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ARGVA</span></code></a></p></td>
<td><p></p><p>The Adversarially Regularized Variational Graph Auto-Encoder model from the <a class="reference external" href="https://arxiv.org/abs/1802.04407">"Adversarially Regularized Graph Autoencoder for Graph Embedding"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.SignedGCN.html#torch_geometric.nn.models.SignedGCN" title="torch_geometric.nn.models.SignedGCN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SignedGCN</span></code></a></p></td>
<td><p></p><p>The signed graph convolutional network model from the <a class="reference external" href="https://arxiv.org/abs/1808.06354">"Signed Graph Convolutional Network"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.RENet.html#torch_geometric.nn.models.RENet" title="torch_geometric.nn.models.RENet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RENet</span></code></a></p></td>
<td><p>The Recurrent Event Network model from the <a class="reference external" href="https://arxiv.org/abs/1904.05530">"Recurrent Event Network for Reasoning over Temporal Knowledge Graphs"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GraphUNet.html#torch_geometric.nn.models.GraphUNet" title="torch_geometric.nn.models.GraphUNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GraphUNet</span></code></a></p></td>
<td><p></p><p>The Graph U-Net model from the <a class="reference external" href="https://arxiv.org/abs/1905.05178">"Graph U-Nets"</a> paper which implements a U-Net like architecture with graph pooling and unpooling operations.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.SchNet.html#torch_geometric.nn.models.SchNet" title="torch_geometric.nn.models.SchNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SchNet</span></code></a></p></td>
<td><p>The continuous-filter convolutional neural network SchNet from the <a class="reference external" href="https://arxiv.org/abs/1706.08566">"SchNet: A Continuous-filter Convolutional Neural Network for Modeling Quantum Interactions"</a> paper that uses the interactions blocks of the form.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.DimeNet.html#torch_geometric.nn.models.DimeNet" title="torch_geometric.nn.models.DimeNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DimeNet</span></code></a></p></td>
<td><p>The directional message passing neural network (DimeNet) from the <a class="reference external" href="https://arxiv.org/abs/2003.03123">"Directional Message Passing for Molecular Graphs"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.DimeNetPlusPlus.html#torch_geometric.nn.models.DimeNetPlusPlus" title="torch_geometric.nn.models.DimeNetPlusPlus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DimeNetPlusPlus</span></code></a></p></td>
<td><p>The DimeNet++ from the <a class="reference external" href="https://arxiv.org/abs/2011.14115">"Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.to_captum_model.html#torch_geometric.nn.models.to_captum_model" title="torch_geometric.nn.models.to_captum_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_captum_model</span></code></a></p></td>
<td><p>Converts a model to a model that can be used for <a class="reference external" href="https://captum.ai/">Captum</a> attribution methods.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.to_captum_input.html#torch_geometric.nn.models.to_captum_input" title="torch_geometric.nn.models.to_captum_input"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_captum_input</span></code></a></p></td>
<td><p></p><p>Given <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">mask_type</span></code>, converts it to a format to use in <a class="reference external" href="https://captum.ai/">Captum</a> attribution methods.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.captum_output_to_dicts.html#torch_geometric.nn.models.captum_output_to_dicts" title="torch_geometric.nn.models.captum_output_to_dicts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">captum_output_to_dicts</span></code></a></p></td>
<td><p></p><p>Convert the output of <a class="reference external" href="https://captum.ai/">Captum</a> attribution methods which is a tuple of attributions to two dictionaries with node and edge attribution tensors.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MetaPath2Vec.html#torch_geometric.nn.models.MetaPath2Vec" title="torch_geometric.nn.models.MetaPath2Vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MetaPath2Vec</span></code></a></p></td>
<td><p>The MetaPath2Vec model from the <a class="reference external" href="https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf">"metapath2vec: Scalable Representation Learning for Heterogeneous Networks"</a> paper where random walks based on a given <code class="xref py py-obj docutils literal notranslate"><span class="pre">metapath</span></code> are sampled in a heterogeneous graph, and node embeddings are learned via negative sampling optimization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.DeepGCNLayer.html#torch_geometric.nn.models.DeepGCNLayer" title="torch_geometric.nn.models.DeepGCNLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DeepGCNLayer</span></code></a></p></td>
<td><p>The skip connection operations from the <a class="reference external" href="https://arxiv.org/abs/1904.03751">"DeepGCNs: Can GCNs Go as Deep as CNNs?"</a> and <a class="reference external" href="https://arxiv.org/abs/2006.07739">"All You Need to Train Deeper GCNs"</a> papers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.TGNMemory.html#torch_geometric.nn.models.TGNMemory" title="torch_geometric.nn.models.TGNMemory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TGNMemory</span></code></a></p></td>
<td><p>The Temporal Graph Network (TGN) memory model from the <a class="reference external" href="https://arxiv.org/abs/2006.10637">"Temporal Graph Networks for Deep Learning on Dynamic Graphs"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.LabelPropagation.html#torch_geometric.nn.models.LabelPropagation" title="torch_geometric.nn.models.LabelPropagation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LabelPropagation</span></code></a></p></td>
<td><p>The label propagation operator, firstly introduced in the <a class="reference external" href="http://mlg.eng.cam.ac.uk/zoubin/papers/CMU-CALD-02-107.pdf">"Learning from Labeled and Unlabeled Data with Label Propagation"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.CorrectAndSmooth.html#torch_geometric.nn.models.CorrectAndSmooth" title="torch_geometric.nn.models.CorrectAndSmooth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CorrectAndSmooth</span></code></a></p></td>
<td><p>The correct and smooth (C&amp;S) post-processing model from the <a class="reference external" href="https://arxiv.org/abs/2010.13993">"Combining Label Propagation And Simple Models Out-performs Graph Neural Networks"</a> paper, where soft predictions <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="32" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D419 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">Z</mi></mrow></math></mjx-assistive-mml></mjx-container></span> (obtained from a simple base predictor) are first corrected based on ground-truth training label information <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="33" style="font-size: 114.4%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D418 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">Y</mi></mrow></math></mjx-assistive-mml></mjx-container></span> and residual propagation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.AttentiveFP.html#torch_geometric.nn.models.AttentiveFP" title="torch_geometric.nn.models.AttentiveFP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AttentiveFP</span></code></a></p></td>
<td><p>The Attentive FP model for molecular representation learning from the <a class="reference external" href="https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959">"Pushing the Boundaries of Molecular Representation for Drug Discovery with the Graph Attention Mechanism"</a> paper, based on graph attention mechanisms.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.RECT_L.html#torch_geometric.nn.models.RECT_L" title="torch_geometric.nn.models.RECT_L"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RECT_L</span></code></a></p></td>
<td><p>The RECT model, <em>i.e.</em> its supervised RECT-L part, from the <a class="reference external" href="https://arxiv.org/abs/2007.03545">"Network Embedding with Completely-imbalanced Labels"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.LINKX.html#torch_geometric.nn.models.LINKX" title="torch_geometric.nn.models.LINKX"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LINKX</span></code></a></p></td>
<td><p>The LINKX model from the <a class="reference external" href="https://arxiv.org/abs/2110.14446">"Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.LightGCN.html#torch_geometric.nn.models.LightGCN" title="torch_geometric.nn.models.LightGCN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LightGCN</span></code></a></p></td>
<td><p></p><p>The LightGCN model from the <a class="reference external" href="https://arxiv.org/abs/2002.02126">"LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MaskLabel.html#torch_geometric.nn.models.MaskLabel" title="torch_geometric.nn.models.MaskLabel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MaskLabel</span></code></a></p></td>
<td><p></p><p>The label embedding and masking layer from the <a class="reference external" href="https://arxiv.org/abs/2009.03509">"Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification"</a> paper.</p>
<p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GroupAddRev.html#torch_geometric.nn.models.GroupAddRev" title="torch_geometric.nn.models.GroupAddRev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GroupAddRev</span></code></a></p></td>
<td><p>The Grouped Reversible GNN module from the <a class="reference external" href="https://arxiv.org/abs/2106.07476">"Graph Neural Networks with 1000 Layers"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GNNFF.html#torch_geometric.nn.models.GNNFF" title="torch_geometric.nn.models.GNNFF"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GNNFF</span></code></a></p></td>
<td><p>The Graph Neural Network Force Field (GNNFF) from the <a class="reference external" href="https://www.nature.com/articles/s41524-021-00543-3">"Accurate and scalable graph neural network force field and molecular dynamics with direct force architecture"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.PMLP.html#torch_geometric.nn.models.PMLP" title="torch_geometric.nn.models.PMLP"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PMLP</span></code></a></p></td>
<td><p>The P(ropagational)MLP model from the <a class="reference external" href="https://arxiv.org/abs/2212.09034">"Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.NeuralFingerprint.html#torch_geometric.nn.models.NeuralFingerprint" title="torch_geometric.nn.models.NeuralFingerprint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NeuralFingerprint</span></code></a></p></td>
<td><p>The Neural Fingerprint model from the <a class="reference external" href="https://arxiv.org/abs/1509.09292">"Convolutional Networks on Graphs for Learning Molecular Fingerprints"</a> paper to generate fingerprints of molecules.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.ViSNet.html#torch_geometric.nn.models.ViSNet" title="torch_geometric.nn.models.ViSNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ViSNet</span></code></a></p></td>
<td><p>A <span class="inline-logo pytorch">PyTorch</span> module that implements the equivariant vector-scalar interactive graph neural network (ViSNet) from the <a class="reference external" href="https://arxiv.org/abs/2210.16518">"Enhancing Geometric Representations for Molecules with Equivariant Vector-Scalar Interactive Message Passing"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GRetriever.html#torch_geometric.nn.models.GRetriever" title="torch_geometric.nn.models.GRetriever"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRetriever</span></code></a></p></td>
<td><p>The G-Retriever model from the <a class="reference external" href="https://arxiv.org/abs/2402.07630">"G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GITMol.html#torch_geometric.nn.models.GITMol" title="torch_geometric.nn.models.GITMol"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GITMol</span></code></a></p></td>
<td><p>The GITMol model from the <a class="reference external" href="https://arxiv.org/pdf/2308.06911">"GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MoleculeGPT.html#torch_geometric.nn.models.MoleculeGPT" title="torch_geometric.nn.models.MoleculeGPT"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MoleculeGPT</span></code></a></p></td>
<td><p>The MoleculeGPT model from the <a class="reference external" href="https://ai4d3.github.io/papers/34.pdf">"MoleculeGPT: Instruction Following Large Language Models for Molecular Property Prediction"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GLEM.html#torch_geometric.nn.models.GLEM" title="torch_geometric.nn.models.GLEM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GLEM</span></code></a></p></td>
<td><p>This GNN+LM co-training model is based on GLEM from the <a class="reference external" href="https://arxiv.org/abs/2210.14709">"Learning on Large-scale Text-attributed Graphs via Variational Inference"</a> paper.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="kge-models">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id48" role="doc-backlink">KGE Models</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#kge-models" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.KGEModel.html#torch_geometric.nn.kge.KGEModel" title="torch_geometric.nn.kge.KGEModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KGEModel</span></code></a></p></td>
<td><p>An abstract base class for implementing custom KGE models.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.TransE.html#torch_geometric.nn.kge.TransE" title="torch_geometric.nn.kge.TransE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TransE</span></code></a></p></td>
<td><p>The TransE model from the <a class="reference external" href="https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf">"Translating Embeddings for Modeling Multi-Relational Data"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.ComplEx.html#torch_geometric.nn.kge.ComplEx" title="torch_geometric.nn.kge.ComplEx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ComplEx</span></code></a></p></td>
<td><p>The ComplEx model from the <a class="reference external" href="https://arxiv.org/abs/1606.06357">"Complex Embeddings for Simple Link Prediction"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.DistMult.html#torch_geometric.nn.kge.DistMult" title="torch_geometric.nn.kge.DistMult"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DistMult</span></code></a></p></td>
<td><p>The DistMult model from the <a class="reference external" href="https://arxiv.org/abs/1412.6575">"Embedding Entities and Relations for Learning and Inference in Knowledge Bases"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.kge.RotatE.html#torch_geometric.nn.kge.RotatE" title="torch_geometric.nn.kge.RotatE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RotatE</span></code></a></p></td>
<td><p>The RotatE model from the <a class="reference external" href="https://arxiv.org/abs/1902.10197">"RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space"</a> paper.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-torch_geometric.nn.encoding">
<span id="encodings"></span><h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id49" role="doc-backlink">Encodings</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.encoding" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.encoding.PositionalEncoding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">PositionalEncoding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_freq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">granularity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/encoding.html#PositionalEncoding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.encoding.PositionalEncoding" title="Permalink to this definition"></a></dt>
<dd><p>The positional encoding scheme from the <a class="reference external" href="https://arxiv.org/abs/1706.03762">“Attention Is All You Need”</a> paper.</p>
<div class="math notranslate nohighlight">
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="34" style="font-size: 114.5%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtable style="min-width: 13.266em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd style="text-align: right;"><mjx-mtable justify="right" style="min-width: 13.266em;"><mjx-table><mjx-itable><mjx-mtr><mjx-mtd style="text-align: right; padding-right: 0px; padding-bottom: 0.15em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-tstrut></mjx-tstrut></mjx-mtd><mjx-mtd style="text-align: left; padding-left: 0px; padding-bottom: 0.15em;"><mjx-mi class="mjx-n"></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="4"><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.413em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr><mjx-mtr><mjx-mtd style="text-align: right; padding-right: 0px; padding-top: 0.15em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-tstrut></mjx-tstrut></mjx-mtd><mjx-mtd style="text-align: left; padding-left: 0px; padding-top: 0.15em;"><mjx-mi class="mjx-n"></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="4"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.413em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable><mjx-tstrut></mjx-tstrut></mjx-mtd></mjx-mtr></mjx-itable></mjx-table></mjx-mtable></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt"><mtr><mtd><mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt"><mtr><mtd><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mo stretchy="false">)</mo><mrow data-mjx-texclass="ORD"><mn>2</mn><mo>⋅</mo><mi>i</mi></mrow></msub></mtd><mtd><mi></mi><mo>=</mo><mi>sin</mi><mo data-mjx-texclass="NONE">⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><msup><mn>10000</mn><mrow data-mjx-texclass="ORD"><mn>2</mn><mo>⋅</mo><mi>i</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mo stretchy="false">)</mo><mrow data-mjx-texclass="ORD"><mn>2</mn><mo>⋅</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd><mi></mi><mo>=</mo><mi>cos</mi><mo data-mjx-texclass="NONE">⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><msup><mn>10000</mn><mrow data-mjx-texclass="ORD"><mn>2</mn><mo>⋅</mo><mi>i</mi><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math></mjx-assistive-mml></mjx-container></div>
<p>where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="35" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container></span> is the position and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="36" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></mjx-assistive-mml></mjx-container></span> is the dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="37" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></mjx-assistive-mml></mjx-container></span> of each output sample.</p></li>
<li><p><strong>base_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – The base frequency of sinusoidal
functions. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1e-4</span></code>)</p></li>
<li><p><strong>granularity</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – The granularity of the positions. If
set to smaller value, the encoder will capture more fine-grained
changes in positions. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1.0</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.encoding.PositionalEncoding.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/encoding.html#PositionalEncoding.reset_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.encoding.PositionalEncoding.reset_parameters" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.encoding.PositionalEncoding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/encoding.html#PositionalEncoding.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.encoding.PositionalEncoding.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.encoding.TemporalEncoding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">TemporalEncoding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/encoding.html#TemporalEncoding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.encoding.TemporalEncoding" title="Permalink to this definition"></a></dt>
<dd><p>The time-encoding function from the <a class="reference external" href="https://openreview.net/forum?id=ayPPc0SyLv1">“Do We Really Need Complicated
Model Architectures for Temporal Networks?”</a> paper.</p>
<p>It first maps each entry to a vector with exponentially decreasing values,
and then uses the cosine function to project all values to range
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="38" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></mjx-assistive-mml></mjx-container></span>.</p>
<div class="math notranslate nohighlight">
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="39" style="font-size: 114.5%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="4"><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mrow space="2"><mjx-mo class="mjx-s3"><mjx-c class="mjx-c28 TEX-S3"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.203em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-script style="vertical-align: 0.744em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.156em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-s3"><mjx-c class="mjx-c29 TEX-S3"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>y</mi><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo>=</mo><mi>cos</mi><mo data-mjx-texclass="NONE">⁡</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>x</mi><mo>⋅</mo><msup><msqrt><mi>d</mi></msqrt><mrow data-mjx-texclass="ORD"><mo>−</mo><mo stretchy="false">(</mo><mi>i</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><msqrt><mi>d</mi></msqrt></mrow></msup><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container></div>
<p>where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="40" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></mjx-assistive-mml></mjx-container></span> defines the output feature dimension, and
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="41" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2264"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2264"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>d</mi></math></mjx-assistive-mml></mjx-container></span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="42" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></mjx-assistive-mml></mjx-container></span> of each output sample.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.encoding.TemporalEncoding.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/encoding.html#TemporalEncoding.reset_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.encoding.TemporalEncoding.reset_parameters" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.encoding.TemporalEncoding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/encoding.html#TemporalEncoding.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.encoding.TemporalEncoding.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/main/tensors.html#torch.Tensor" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="functional">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id50" role="doc-backlink">Functional</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#functional" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.functional.bro.html#torch_geometric.nn.functional.bro" title="torch_geometric.nn.functional.bro"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bro</span></code></a></p></td>
<td><p>The Batch Representation Orthogonality penalty from the <a class="reference external" href="https://arxiv.org/abs/2105.04854">"Improving Molecular Graph Neural Network Explainability with Orthonormalization and Induced Sparsity"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.functional.gini.html#torch_geometric.nn.functional.gini" title="torch_geometric.nn.functional.gini"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gini</span></code></a></p></td>
<td><p></p><p>The Gini coefficient from the <a class="reference external" href="https://arxiv.org/abs/2105.04854">"Improving Molecular Graph Neural Network Explainability with Orthonormalization and Induced Sparsity"</a> paper.</p>
<p></p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="dense-convolutional-layers">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id51" role="doc-backlink">Dense Convolutional Layers</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-convolutional-layers" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.DenseGCNConv.html#torch_geometric.nn.dense.DenseGCNConv" title="torch_geometric.nn.dense.DenseGCNConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseGCNConv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html#torch_geometric.nn.conv.GCNConv" title="torch_geometric.nn.conv.GCNConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GCNConv</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.DenseGINConv.html#torch_geometric.nn.dense.DenseGINConv" title="torch_geometric.nn.dense.DenseGINConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseGINConv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINConv.html#torch_geometric.nn.conv.GINConv" title="torch_geometric.nn.conv.GINConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GINConv</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.DenseGraphConv.html#torch_geometric.nn.dense.DenseGraphConv" title="torch_geometric.nn.dense.DenseGraphConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseGraphConv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GraphConv.html#torch_geometric.nn.conv.GraphConv" title="torch_geometric.nn.conv.GraphConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GraphConv</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.DenseSAGEConv.html#torch_geometric.nn.dense.DenseSAGEConv" title="torch_geometric.nn.dense.DenseSAGEConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseSAGEConv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html#torch_geometric.nn.conv.SAGEConv" title="torch_geometric.nn.conv.SAGEConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.SAGEConv</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.DenseGATConv.html#torch_geometric.nn.dense.DenseGATConv" title="torch_geometric.nn.dense.DenseGATConv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseGATConv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATConv.html#torch_geometric.nn.conv.GATConv" title="torch_geometric.nn.conv.GATConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GATConv</span></code></a>.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="dense-pooling-layers">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id52" role="doc-backlink">Dense Pooling Layers</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#dense-pooling-layers" title="Permalink to this heading"></a></h2>
<div class="wy-table-responsive"><table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dense_diff_pool.html#torch_geometric.nn.dense.dense_diff_pool" title="torch_geometric.nn.dense.dense_diff_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dense_diff_pool</span></code></a></p></td>
<td><p>The differentiable pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1806.08804">"Hierarchical Graph Representation Learning with Differentiable Pooling"</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.dense_mincut_pool.html#torch_geometric.nn.dense.dense_mincut_pool" title="torch_geometric.nn.dense.dense_mincut_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dense_mincut_pool</span></code></a></p></td>
<td><p>The MinCut pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1907.00481">"Spectral Clustering in Graph Neural Networks for Graph Pooling"</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.dense.DMoNPooling.html#torch_geometric.nn.dense.DMoNPooling" title="torch_geometric.nn.dense.DMoNPooling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DMoNPooling</span></code></a></p></td>
<td><p>The spectral modularity pooling operator from the <a class="reference external" href="https://arxiv.org/abs/2006.16904">"Graph Clustering with Graph Neural Networks"</a> paper.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="model-transformations">
<h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id53" role="doc-backlink">Model Transformations</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#model-transformations" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Transformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer" title="Permalink to this definition"></a></dt>
<dd><p>A <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer" title="torch_geometric.nn.fx.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code></a> executes an FX graph node-by-node, applies
transformations to each node, and produces a new <a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a>.
It exposes a <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.transform" title="torch_geometric.nn.fx.Transformer.transform"><code class="xref py py-func docutils literal notranslate"><span class="pre">transform()</span></code></a> method that returns the transformed
<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>.
<a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer" title="torch_geometric.nn.fx.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code></a> works entirely symbolically.</p>
<p>Methods in the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer" title="torch_geometric.nn.fx.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code></a> class can be overridden to customize
the behavior of transformation.</p>
<div class="highlight-none notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell8"><span></span>transform()
    +-- Iterate over each node in the graph
        +-- placeholder()
        +-- get_attr()
        +-- call_function()
        +-- call_method()
        +-- call_module()
        +-- call_message_passing_module()
        +-- call_global_pooling_module()
        +-- output()
    +-- Erase unused nodes in the graph
    +-- Iterate over each children module
        +-- init_submodule()
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell8">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>In contrast to the <a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Transformer" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.fx.Transformer</span></code></a> class, the
<a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer" title="torch_geometric.nn.fx.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code></a> exposes additional functionality:</p>
<ol class="arabic simple">
<li><p>It subdivides <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_module" title="torch_geometric.nn.fx.Transformer.call_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">call_module()</span></code></a> into nodes that call a regular
<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a> (<a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_module" title="torch_geometric.nn.fx.Transformer.call_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">call_module()</span></code></a>), a
<code class="xref py py-class docutils literal notranslate"><span class="pre">MessagePassing</span></code> module (<a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_message_passing_module" title="torch_geometric.nn.fx.Transformer.call_message_passing_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">call_message_passing_module()</span></code></a>),
or a <code class="xref py py-class docutils literal notranslate"><span class="pre">GlobalPooling</span></code> module (<a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_global_pooling_module" title="torch_geometric.nn.fx.Transformer.call_global_pooling_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">call_global_pooling_module()</span></code></a>).</p></li>
<li><p>It allows to customize or initialize new children modules via
<a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.init_submodule" title="torch_geometric.nn.fx.Transformer.init_submodule"><code class="xref py py-func docutils literal notranslate"><span class="pre">init_submodule()</span></code></a></p></li>
<li><p>It allows to infer whether a node returns node-level or edge-level
information via <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.is_edge_level" title="torch_geometric.nn.fx.Transformer.is_edge_level"><code class="xref py py-meth docutils literal notranslate"><span class="pre">is_edge_level()</span></code></a>.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.nn.Module</em></a>) – The module to be transformed.</p></li>
<li><p><strong>input_map</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – A dictionary holding information
about the type of input arguments of <code class="xref py py-obj docutils literal notranslate"><span class="pre">module.forward</span></code>.
For example, in case <code class="xref py py-obj docutils literal notranslate"><span class="pre">arg</span></code> is a node-level argument, then
<code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map['arg']</span> <span class="pre">=</span> <span class="pre">'node'</span></code>, and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map['arg']</span> <span class="pre">=</span> <span class="pre">'edge'</span></code> otherwise.
In case <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map</span></code> is not further specified, will try to
automatically determine the correct type of input arguments.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>debug</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, will perform
transformation in debug mode. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.placeholder">
<span class="sig-name descname"><span class="pre">placeholder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.placeholder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.placeholder" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.get_attr">
<span class="sig-name descname"><span class="pre">get_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.get_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.get_attr" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.call_message_passing_module">
<span class="sig-name descname"><span class="pre">call_message_passing_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.call_message_passing_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_message_passing_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.call_global_pooling_module">
<span class="sig-name descname"><span class="pre">call_global_pooling_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.call_global_pooling_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_global_pooling_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.call_module">
<span class="sig-name descname"><span class="pre">call_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.call_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.call_method">
<span class="sig-name descname"><span class="pre">call_method</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.call_method"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_method" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.call_function">
<span class="sig-name descname"><span class="pre">call_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.call_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.call_function" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.output">
<span class="sig-name descname"><span class="pre">output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.output" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.init_submodule">
<span class="sig-name descname"><span class="pre">init_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Module</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.init_submodule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.init_submodule" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.GraphModule" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">GraphModule</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.transform" title="Permalink to this definition"></a></dt>
<dd><p>Transforms <code class="xref py py-obj docutils literal notranslate"><span class="pre">self.module</span></code> and returns a transformed
<a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.GraphModule" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.fx.GraphModule</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.GraphModule" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphModule</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.is_node_level">
<span class="sig-name descname"><span class="pre">is_node_level</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.is_node_level"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.is_node_level" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.is_edge_level">
<span class="sig-name descname"><span class="pre">is_edge_level</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.is_edge_level"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.is_edge_level" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.is_graph_level">
<span class="sig-name descname"><span class="pre">is_graph_level</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.is_graph_level"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.is_graph_level" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.has_node_level_arg">
<span class="sig-name descname"><span class="pre">has_node_level_arg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.has_node_level_arg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.has_node_level_arg" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.has_edge_level_arg">
<span class="sig-name descname"><span class="pre">has_edge_level_arg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.has_edge_level_arg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.has_edge_level_arg" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.has_graph_level_arg">
<span class="sig-name descname"><span class="pre">has_graph_level_arg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.has_graph_level_arg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.has_graph_level_arg" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.fx.Transformer.replace_all_uses_with">
<span class="sig-name descname"><span class="pre">replace_all_uses_with</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_replace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace_with</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.Node" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Node</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/fx.html#Transformer.replace_all_uses_with"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.fx.Transformer.replace_all_uses_with" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torch_geometric.nn.to_hetero_transformer.to_hetero">
<span class="sig-name descname"><span class="pre">to_hetero</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.GraphModule" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">GraphModule</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/to_hetero_transformer.html#to_hetero"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_transformer.to_hetero" title="Permalink to this definition"></a></dt>
<dd><p>Converts a homogeneous GNN model into its heterogeneous equivalent in
which node representations are learned for each node type in
<code class="xref py py-obj docutils literal notranslate"><span class="pre">metadata[0]</span></code>, and messages are exchanged between each edge type in
<code class="xref py py-obj docutils literal notranslate"><span class="pre">metadata[1]</span></code>, as denoted in the <a class="reference external" href="https://arxiv.org/abs/1703.06103">“Modeling Relational Data with Graph
Convolutional Networks”</a> paper.</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell9"><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">SAGEConv</span><span class="p">,</span> <span class="n">to_hetero</span>

<span class="k">class</span><span class="w"> </span><span class="nc">GNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">SAGEConv</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">SAGEConv</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GNN</span><span class="p">()</span>

<span class="n">node_types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'paper'</span><span class="p">,</span> <span class="s1">'author'</span><span class="p">]</span>
<span class="n">edge_types</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">'paper'</span><span class="p">,</span> <span class="s1">'cites'</span><span class="p">,</span> <span class="s1">'paper'</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">'paper'</span><span class="p">,</span> <span class="s1">'written_by'</span><span class="p">,</span> <span class="s1">'author'</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">'author'</span><span class="p">,</span> <span class="s1">'writes'</span><span class="p">,</span> <span class="s1">'paper'</span><span class="p">),</span>
<span class="p">]</span>
<span class="n">metadata</span> <span class="o">=</span> <span class="p">(</span><span class="n">node_types</span><span class="p">,</span> <span class="n">edge_types</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">to_hetero</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">x_dict</span><span class="p">,</span> <span class="n">edge_index_dict</span><span class="p">)</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell9">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>where <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_dict</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index_dict</span></code> denote dictionaries that
hold node features and edge connectivity information for each node type and
edge type, respectively.</p>
<p>The below illustration shows the original computation graph of the
homogeneous model on the left, and the newly obtained computation graph of
the heterogeneous model on the right:</p>
<figure class="align-center" id="id40">
<a class="reference internal image-reference" href="./torch_geometric.nn — pytorch_geometric documentation_files/to_hetero.svg"><img alt="../_images/to_hetero.svg" src="./torch_geometric.nn — pytorch_geometric documentation_files/to_hetero.svg" width="90%"></a>
<figcaption>
<p><span class="caption-text">Transforming a model via <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_transformer.to_hetero" title="torch_geometric.nn.to_hetero_transformer.to_hetero"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_hetero()</span></code></a>.</span><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id40" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Here, each <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html#torch_geometric.nn.conv.MessagePassing" title="torch_geometric.nn.conv.MessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">MessagePassing</span></code></a> instance
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="43" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.325em; margin-left: -0.06em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.16em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D703 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>θ</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo stretchy="false">)</mo></mrow></msubsup></math></mjx-assistive-mml></mjx-container></span> is duplicated and stored in a set
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="44" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msubsup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.325em; margin-left: -0.06em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.16em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D703 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo fence="false" stretchy="false">{</mo><msubsup><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>θ</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo>,</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>:</mo><mi>r</mi><mo>∈</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow><mo fence="false" stretchy="false">}</mo></math></mjx-assistive-mml></mjx-container></span> (one instance for
each relation in <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="45" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container></span>), and message passing in layer
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="46" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ℓ</mi></math></mjx-assistive-mml></mjx-container></span> is performed via</p>
<div class="math notranslate nohighlight">
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="47" style="font-size: 114.5%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D421 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.14em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-munder space="4"><mjx-row><mjx-base><mjx-mo class="mjx-lop"><mjx-c class="mjx-c2A01 TEX-S2"></mjx-c></mjx-mo></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em; padding-left: 0.06em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-under></mjx-row></mjx-munder><mjx-msubsup space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.325em; margin-left: -0.06em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.16em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D703 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D421 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.14em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D421 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.14em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D464 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D464 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c4E TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.413em; margin-left: 0.058em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">h</mi></mrow><mi>v</mi><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><munder><mo data-mjx-texclass="OP">⨁</mo><mrow data-mjx-texclass="ORD"><mi>r</mi><mo>∈</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></mrow></munder><msubsup><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>θ</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo>,</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">h</mi></mrow><mi>v</mi><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>,</mo><mo fence="false" stretchy="false">{</mo><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">h</mi></mrow><mi>w</mi><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>:</mo><mi>w</mi><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">N</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo fence="false" stretchy="false">}</mo><mo stretchy="false">)</mo><mo>,</mo></math></mjx-assistive-mml></mjx-container></div>
<p>where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="48" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c4E TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.058em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">N</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span> denotes the neighborhood of <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="49" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c56 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi><mo>∈</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">V</mi></mrow></math></mjx-assistive-mml></mjx-container></span> under relation <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="50" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>r</mi><mo>∈</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container></span>, and
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="51" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2A01 TEX-S1"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo data-mjx-texclass="OP">⨁</mo></math></mjx-assistive-mml></mjx-container></span> denotes the aggregation scheme <code class="xref py py-attr docutils literal notranslate"><span class="pre">aggr</span></code> to use for
grouping node embeddings generated by different relations
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">"sum"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"mean"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"min"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"max"</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">"mul"</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.nn.Module</em></a>) – The homogeneous model to transform.</p></li>
<li><p><strong>metadata</strong> (<em>Tuple</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em><em>]</em>) – The metadata
of the heterogeneous graph, <em>i.e.</em> its node and edge types given
by a list of strings and a list of string triplets, respectively.
See <a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.HeteroData.html#torch_geometric.data.HeteroData.metadata" title="torch_geometric.data.HeteroData.metadata"><code class="xref py py-meth docutils literal notranslate">HeteroData.metadata()</code></a> for more
information.</p></li>
<li><p><strong>aggr</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The aggregation scheme to use for grouping node
embeddings generated by different relations
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">"sum"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"mean"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"min"</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">"max"</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">"mul"</span></code>). (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">"sum"</span></code>)</p></li>
<li><p><strong>input_map</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – A dictionary holding information
about the type of input arguments of <code class="xref py py-obj docutils literal notranslate"><span class="pre">module.forward</span></code>.
For example, in case <code class="xref py py-obj docutils literal notranslate"><span class="pre">arg</span></code> is a node-level argument, then
<code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map['arg']</span> <span class="pre">=</span> <span class="pre">'node'</span></code>, and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map['arg']</span> <span class="pre">=</span> <span class="pre">'edge'</span></code> otherwise.
In case <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map</span></code> is not further specified, will try to
automatically determine the correct type of input arguments.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>debug</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, will perform
transformation in debug mode. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.GraphModule" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphModule</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torch_geometric.nn.to_hetero_with_bases_transformer.to_hetero_with_bases">
<span class="sig-name descname"><span class="pre">to_hetero_with_bases</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_bases</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.GraphModule" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">GraphModule</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/to_hetero_with_bases_transformer.html#to_hetero_with_bases"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_with_bases_transformer.to_hetero_with_bases" title="Permalink to this definition"></a></dt>
<dd><p>Converts a homogeneous GNN model into its heterogeneous equivalent
via the basis-decomposition technique introduced in the
<a class="reference external" href="https://arxiv.org/abs/1703.06103">“Modeling Relational Data with Graph Convolutional Networks”</a> paper.</p>
<p>For this, the heterogeneous graph is mapped to a typed homogeneous graph,
in which its feature representations are aligned and grouped to a single
representation.
All GNN layers inside the model will then perform message passing via
basis-decomposition regularization.
This transformation is especially useful in highly multi-relational data,
such that the number of parameters no longer depend on the number of
relations of the input graph:</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell10"><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">SAGEConv</span><span class="p">,</span> <span class="n">to_hetero_with_bases</span>

<span class="k">class</span><span class="w"> </span><span class="nc">GNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">SAGEConv</span><span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">SAGEConv</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GNN</span><span class="p">()</span>

<span class="n">node_types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'paper'</span><span class="p">,</span> <span class="s1">'author'</span><span class="p">]</span>
<span class="n">edge_types</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">'paper'</span><span class="p">,</span> <span class="s1">'cites'</span><span class="p">,</span> <span class="s1">'paper'</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">'paper'</span><span class="p">,</span> <span class="s1">'written_by'</span><span class="p">,</span> <span class="s1">'author'</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">'author'</span><span class="p">,</span> <span class="s1">'writes'</span><span class="p">,</span> <span class="s1">'paper'</span><span class="p">),</span>
<span class="p">]</span>
<span class="n">metadata</span> <span class="o">=</span> <span class="p">(</span><span class="n">node_types</span><span class="p">,</span> <span class="n">edge_types</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">to_hetero_with_bases</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">num_bases</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                             <span class="n">in_channels</span><span class="o">=</span><span class="p">{</span><span class="s1">'x'</span><span class="p">:</span> <span class="mi">16</span><span class="p">})</span>
<span class="n">model</span><span class="p">(</span><span class="n">x_dict</span><span class="p">,</span> <span class="n">edge_index_dict</span><span class="p">)</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell10">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<p>where <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_dict</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index_dict</span></code> denote dictionaries that
hold node features and edge connectivity information for each node type and
edge type, respectively.
In case <code class="xref py py-obj docutils literal notranslate"><span class="pre">in_channels</span></code> is given for a specific input argument, its
heterogeneous feature information is first aligned to the given
dimensionality.</p>
<p>The below illustration shows the original computation graph of the
homogeneous model on the left, and the newly obtained computation graph of
the regularized heterogeneous model on the right:</p>
<figure class="align-center" id="id41">
<a class="reference internal image-reference" href="./torch_geometric.nn — pytorch_geometric documentation_files/to_hetero_with_bases.svg"><img alt="../_images/to_hetero_with_bases.svg" src="./torch_geometric.nn — pytorch_geometric documentation_files/to_hetero_with_bases.svg" width="90%"></a>
<figcaption>
<p><span class="caption-text">Transforming a model via <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_with_bases_transformer.to_hetero_with_bases" title="torch_geometric.nn.to_hetero_with_bases_transformer.to_hetero_with_bases"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_hetero_with_bases()</span></code></a>.</span><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id41" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Here, each <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html#torch_geometric.nn.conv.MessagePassing" title="torch_geometric.nn.conv.MessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">MessagePassing</span></code></a> instance
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="52" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.325em; margin-left: -0.06em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.16em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D703 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>θ</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo stretchy="false">)</mo></mrow></msubsup></math></mjx-assistive-mml></mjx-container></span> is duplicated <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_bases</span></code> times and
stored in a set <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="53" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msubsup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.325em; margin-left: -0.06em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.16em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D703 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo fence="false" stretchy="false">{</mo><msubsup><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>θ</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo>,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>:</mo><mi>b</mi><mo>∈</mo><mo fence="false" stretchy="false">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>B</mi><mo fence="false" stretchy="false">}</mo><mo fence="false" stretchy="false">}</mo></math></mjx-assistive-mml></mjx-container></span> (one instance for each basis in
<code class="xref py py-obj docutils literal notranslate"><span class="pre">num_bases</span></code>), and message passing in layer <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="54" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ℓ</mi></math></mjx-assistive-mml></mjx-container></span> is performed
via</p>
<div class="math notranslate nohighlight">
<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="55" style="font-size: 114.5%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D421 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.14em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-munder space="4"><mjx-row><mjx-base><mjx-mo class="mjx-lop"><mjx-c class="mjx-c2211 TEX-S2"></mjx-c></mjx-mo></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em; padding-left: 0.027em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-under></mjx-row></mjx-munder><mjx-munderover space="2"><mjx-over style="padding-bottom: 0.2em; padding-left: 0.454em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-over><mjx-box><mjx-munder><mjx-row><mjx-base><mjx-mo class="mjx-lop"><mjx-c class="mjx-c2211 TEX-S2"></mjx-c></mjx-mo></mjx-base></mjx-row><mjx-row><mjx-under style="padding-top: 0.167em; padding-left: 0.118em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-under></mjx-row></mjx-munder></mjx-box></mjx-munderover><mjx-msubsup space="2"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.325em; margin-left: -0.06em;"><mjx-texatom size="s" texclass="ORD" style="margin-left: 0.16em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D703 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msubsup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D421 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.14em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-msubsup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.317em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-msubsup space="3"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D421 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.14em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D464 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D464 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c4E TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.413em; margin-left: 0.058em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">h</mi></mrow><mi>v</mi><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><munder><mo data-mjx-texclass="OP">∑</mo><mrow data-mjx-texclass="ORD"><mi>r</mi><mo>∈</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></mrow></munder><munderover><mo data-mjx-texclass="OP">∑</mo><mrow data-mjx-texclass="ORD"><mi>b</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><msubsup><mi>f</mi><mrow data-mjx-texclass="ORD"><mi>θ</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo>,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">h</mi></mrow><mi>v</mi><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>,</mo><mo fence="false" stretchy="false">{</mo><msubsup><mi>a</mi><mrow data-mjx-texclass="ORD"><mi>r</mi><mo>,</mo><mi>b</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>⋅</mo><msubsup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">h</mi></mrow><mi>w</mi><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>:</mo><mi>w</mi><mo>∈</mo><msup><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">N</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo fence="false" stretchy="false">}</mo><mo stretchy="false">)</mo><mo>,</mo></math></mjx-assistive-mml></mjx-container></div>
<p>where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="56" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c4E TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em; margin-left: 0.058em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">N</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span> denotes the neighborhood of <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="57" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c56 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi><mo>∈</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">V</mi></mrow></math></mjx-assistive-mml></mjx-container></span> under relation <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="58" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>r</mi><mo>∈</mo><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container></span>.
Notably, only the trainable basis coefficients <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="59" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msubsup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.317em; margin-left: 0px;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msubsup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>a</mi><mrow data-mjx-texclass="ORD"><mi>r</mi><mo>,</mo><mi>b</mi></mrow><mrow data-mjx-texclass="ORD"><mo stretchy="false">(</mo><mi>ℓ</mi><mo stretchy="false">)</mo></mrow></msubsup></math></mjx-assistive-mml></mjx-container></span>
depend on the relations in <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="60" style="font-size: 114.5%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c52 TEX-C"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">R</mi></mrow></math></mjx-assistive-mml></mjx-container></span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.nn.Module</em></a>) – The homogeneous model to transform.</p></li>
<li><p><strong>metadata</strong> (<em>Tuple</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em><em>]</em>) – The metadata
of the heterogeneous graph, <em>i.e.</em> its node and edge types given
by a list of strings and a list of string triplets, respectively.
See <a class="reference internal pyg-mono" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.HeteroData.html#torch_geometric.data.HeteroData.metadata" title="torch_geometric.data.HeteroData.metadata"><code class="xref py py-meth docutils literal notranslate">HeteroData.metadata()</code></a> for more
information.</p></li>
<li><p><strong>num_bases</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The number of bases to use.</p></li>
<li><p><strong>in_channels</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – A dictionary holding
information about the desired input feature dimensionality of
input arguments of <code class="xref py py-obj docutils literal notranslate"><span class="pre">module.forward</span></code>.
In case <code class="xref py py-obj docutils literal notranslate"><span class="pre">in_channels</span></code> is given for a specific input argument,
its heterogeneous feature information is first aligned to the given
dimensionality.
This allows handling of node and edge features with varying feature
dimensionality across different types. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>input_map</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – A dictionary holding information
about the type of input arguments of <code class="xref py py-obj docutils literal notranslate"><span class="pre">module.forward</span></code>.
For example, in case <code class="xref py py-obj docutils literal notranslate"><span class="pre">arg</span></code> is a node-level argument, then
<code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map['arg']</span> <span class="pre">=</span> <span class="pre">'node'</span></code>, and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map['arg']</span> <span class="pre">=</span> <span class="pre">'edge'</span></code> otherwise.
In case <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_map</span></code> is not further specified, will try to
automatically determine the correct type of input arguments.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>debug</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, will perform
transformation in debug mode. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/main/fx.html#torch.fx.GraphModule" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphModule</span></code></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-torch_geometric.nn.data_parallel">
<span id="dataparallel-layers"></span><h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id54" role="doc-backlink">DataParallel Layers</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.data_parallel" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.data_parallel.DataParallel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">DataParallel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">follow_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/data_parallel.html#DataParallel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.data_parallel.DataParallel" title="Permalink to this definition"></a></dt>
<dd><p>Implements data parallelism at the module level.</p>
<p>This container parallelizes the application of the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> by
splitting a list of <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> objects and copying
them as <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Batch.html#torch_geometric.data.Batch" title="torch_geometric.data.Batch"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Batch</span></code></a> objects to each device.
In the forward pass, the module is replicated on each device, and each
replica handles a portion of the input.
During the backwards pass, gradients from each replica are summed into the
original module.</p>
<p>The batch size should be larger than the number of GPUs used.</p>
<p>The parallelized <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> must have its parameters and buffers on
<code class="xref py py-obj docutils literal notranslate"><span class="pre">device_ids[0]</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You need to use the <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.DataListLoader" title="torch_geometric.loader.DataListLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.loader.DataListLoader</span></code></a> for
this module.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is recommended to use
<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.parallel.DistributedDataParallel</span></code></a> instead of
<a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.data_parallel.DataParallel" title="torch_geometric.nn.data_parallel.DataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataParallel</span></code></a> for multi-GPU training.
<a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.data_parallel.DataParallel" title="torch_geometric.nn.data_parallel.DataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataParallel</span></code></a> is usually much slower than
<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code></a> even on a single
machine.
Take a look <a class="reference external" href="https://github.com/pyg-team/pytorch_geometric/blob/master/examples/multi_gpu/distributed_batching.py">here</a> for an example on
how to use <span class="inline-logo pyg">PyG</span> in combination with
<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code></a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – Module to be parallelized.</p></li>
<li><p><strong>device_ids</strong> (<em>list of int</em><em> or </em><a class="reference external" href="https://pytorch.org/docs/main/tensor_attributes.html#torch.device" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.device</em></a>) – CUDA devices.
(default: all devices)</p></li>
<li><p><strong>output_device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://pytorch.org/docs/main/tensor_attributes.html#torch.device" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.device</em></a>) – Device location of output.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">device_ids[0]</span></code>)</p></li>
<li><p><strong>follow_batch</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – Creates assignment batch
vectors for each key in the list. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>exclude_keys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – Will exclude each key in the
list. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-torch_geometric.nn.model_hub">
<span id="model-hub"></span><h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id55" role="doc-backlink">Model Hub</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.model_hub" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="torch_geometric.nn.model_hub.PyGModelHubMixin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">PyGModelHubMixin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/model_hub.html#PyGModelHubMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.model_hub.PyGModelHubMixin" title="Permalink to this definition"></a></dt>
<dd><p>A mixin for saving and loading models to the
<a class="reference external" href="https://huggingface.co/docs/hub/index">Huggingface Model Hub</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell11"><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">Planetoid</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Node2Vec</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn.model_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">PyGModelHubMixin</span>

<span class="c1"># Define your class with the mixin:</span>
<span class="k">class</span><span class="w"> </span><span class="nc">N2V</span><span class="p">(</span><span class="n">Node2Vec</span><span class="p">,</span> <span class="n">PyGModelHubMixin</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">model_name</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">):</span>
        <span class="n">Node2Vec</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
        <span class="n">PyGModelHubMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span>
            <span class="n">dataset_name</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">)</span>

<span class="c1"># Instantiate your model:</span>
<span class="n">n2v</span> <span class="o">=</span> <span class="n">N2V</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">'node2vec'</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="s1">'Cora'</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="n">edge_index</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">walk_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">context_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">walks_per_node</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">num_negative_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="c1"># Train the model:</span>
<span class="o">...</span>

<span class="c1"># Push to the HuggingFace hub:</span>
<span class="n">repo_id</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># your repo id</span>
<span class="n">n2v</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>
    <span class="n">local_file_path</span><span class="p">,</span>
    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span>
 <span class="p">)</span>

<span class="c1"># Load the model for inference:</span>
<span class="c1"># The required arguments are the repo id/local folder, and any model</span>
<span class="c1"># initialisation arguments that are not native python types (e.g</span>
<span class="c1"># Node2Vec requires the edge_index argument which is not stored in the</span>
<span class="c1"># model hub).</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">N2V</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">repo_id</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">'node2vec'</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="s1">'Cora'</span><span class="p">,</span>
    <span class="n">edge_index</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">,</span>
<span class="p">)</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell11">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the model.</p></li>
<li><p><strong>dataset_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – Name of the dataset the model was trained against.</p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) – The arguments to initialise the model.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.model_hub.PyGModelHubMixin.save_pretrained">
<span class="sig-name descname"><span class="pre">save_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(in Python v3.13)"><span class="pre">Path</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">push_to_hub</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repo_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/model_hub.html#PyGModelHubMixin.save_pretrained"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.model_hub.PyGModelHubMixin.save_pretrained" title="Permalink to this definition"></a></dt>
<dd><p>Save a trained model to a local directory or to the HuggingFace
model hub.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_directory</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The directory where weights are saved.</p></li>
<li><p><strong>push_to_hub</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, push the model to the
HuggingFace model hub. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>repo_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The repository name in the hub.
If not provided will default to the name of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">save_directory</span></code> in your namespace. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments passed to
<code class="xref py py-meth docutils literal notranslate"><span class="pre">huggingface_hub.ModelHubMixin.save_pretrained()</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_geometric.nn.model_hub.PyGModelHubMixin.from_pretrained">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained_model_name_or_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_download</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resume_download</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proxies</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_files_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/model_hub.html#PyGModelHubMixin.from_pretrained"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.model_hub.PyGModelHubMixin.from_pretrained" title="Permalink to this definition"></a></dt>
<dd><p>Downloads and instantiates a model from the HuggingFace hub.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained_model_name_or_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – </p><p>Can be either:</p>
<ul>
<li><p>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">model_id</span></code> of a pretrained model hosted inside the
HuggingFace hub.</p></li>
<li><p>You can add a <code class="xref py py-obj docutils literal notranslate"><span class="pre">revision</span></code> by appending <code class="xref py py-obj docutils literal notranslate"><span class="pre">@</span></code> at the
end of <code class="xref py py-obj docutils literal notranslate"><span class="pre">model_id</span></code> to load a specific model version.</p></li>
<li><p>A path to a directory containing the saved model weights.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a> if you are both providing the configuration
<code class="xref py py-obj docutils literal notranslate"><span class="pre">config</span></code> and state dictionary <code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code>.</p></li>
</ul>
<p></p></li>
<li><p><strong>force_download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to force the
(re-)download of the model weights and configuration files,
overriding the cached versions if they exist.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>resume_download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to delete incompletely
received files. Will attempt to resume the download if such a
file exists. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>proxies</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – A dictionary of proxy servers
to use by protocol or endpoint, <em>e.g.</em>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">{'http':</span> <span class="pre">'foo.bar:3128',</span> <span class="pre">'http://host':</span> <span class="pre">'foo.bar:4012'}</span></code>.
The proxies are used on each request. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>token</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – The token to use as HTTP bearer
authorization for remote files. If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, will use
the token generated when running <code class="xref py py-obj docutils literal notranslate"><span class="pre">transformers-cli</span> <span class="pre">login</span></code>
(stored in <code class="xref py py-obj docutils literal notranslate"><span class="pre">huggingface</span></code>). It is <strong>required</strong> if you
want to use a private model. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>cache_dir</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The path to a directory in which a
downloaded model configuration should be cached if the
standard cache should not be used. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>local_files_only</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to only look at local
files, <em>i.e.</em> do not try to download the model.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>**model_kwargs</strong> – Additional keyword arguments passed to the
model during initialization.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-torch_geometric.nn.summary">
<span id="model-summary"></span><h2><a class="toc-backref" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#id56" role="doc-backlink">Model Summary</a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#module-torch_geometric.nn.summary" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="torch_geometric.nn.summary.summary">
<span class="sig-name descname"><span class="pre">summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Module</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><span class="pre">Module</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'MessagePassing'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></span><a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/summary.html#summary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.summary.summary" title="Permalink to this definition"></a></dt>
<dd><p>Summarizes a given <a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a>.
The summarized information includes (1) layer names, (2) input and output
shapes, and (3) the number of parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell12"><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">GCN</span><span class="p">,</span> <span class="n">summary</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GCN</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">edge_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">))</span>
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell12">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><div class="mac-header"><span class="dot red"></span><span class="dot yellow"></span><span class="dot green"></span></div><pre id="codecell13"><span></span>+---------------------+---------------------+--------------+--------+
| Layer               | Input Shape         | Output Shape | #Param |
|---------------------+---------------------+--------------+--------|
| GCN                 | [100, 128], [2, 20] | [100, 32]    | 10,336 |
| ├─(act)ReLU         | [100, 64]           | [100, 64]    | --     |
| ├─(convs)ModuleList | --                  | --           | 10,336 |
| │    └─(0)GCNConv   | [100, 128], [2, 20] | [100, 64]    | 8,256  |
| │    └─(1)GCNConv   | [100, 64], [2, 20]  | [100, 32]    | 2,080  |
+---------------------+---------------------+--------------+--------+
</pre><button class="copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#codecell13">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copy" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#000000" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <title>Copy to clipboard</title>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
  <rect x="8" y="8" width="12" height="12" rx="2"></rect>
  <path d="M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2"></path>
</svg>
    </button></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.nn.Module</em></a>) – The model to summarize.</p></li>
<li><p><strong>*args</strong> – The arguments of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">model</span></code>.</p></li>
<li><p><strong>max_depth</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – The depth of nested layers to display.
Any layers deeper than this depth will not be displayed in the
summary. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">3</span></code>)</p></li>
<li><p><strong>leaf_module</strong> (<a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.nn.Module</em></a><em> or </em><em>[</em><a class="reference external" href="https://pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.7.0a0+gitbc57635 ))"><em>torch.nn.Module</em></a><em>]</em><em>, </em><em>optional</em>) – The
modules to be treated as leaf modules, whose submodules are
excluded from the summary.
(default: <a class="reference internal" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html#torch_geometric.nn.conv.MessagePassing" title="torch_geometric.nn.conv.MessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">MessagePassing</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">model</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.EdgeIndex.html" class="btn btn-neutral float-left" title="torch_geometric.EdgeIndex" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.MessagePassing.html" class="btn btn-neutral float-right" title="torch_geometric.nn.conv.MessagePassing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr>

  <div role="contentinfo">
    <p>© Copyright 2025, PyG Team.</p>
  </div></footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 


<readthedocs-flyout><template shadowrootmode="open"><!---->
      <div class=" floating container bottom-right ">
        <!--?lit$085975880$-->
      <header>
        <img class="logo" alt="Read the Docs" src="data:image/svg+xml;base64,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">
        <!--?lit$085975880$--> <!--?lit$085975880$--><span><!--?lit$085975880$--><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="code-branch" class="svg-inline--fa fa-code-branch icon" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M80 104a24 24 0 1 0 0-48 24 24 0 1 0 0 48zm80-24c0 32.8-19.7 61-48 73.3l0 87.8c18.8-10.9 40.7-17.1 64-17.1l96 0c35.3 0 64-28.7 64-64l0-6.7C307.7 141 288 112.8 288 80c0-44.2 35.8-80 80-80s80 35.8 80 80c0 32.8-19.7 61-48 73.3l0 6.7c0 70.7-57.3 128-128 128l-96 0c-35.3 0-64 28.7-64 64l0 6.7c28.3 12.3 48 40.5 48 73.3c0 44.2-35.8 80-80 80s-80-35.8-80-80c0-32.8 19.7-61 48-73.3l0-6.7 0-198.7C19.7 141 0 112.8 0 80C0 35.8 35.8 0 80 0s80 35.8 80 80zm232 0a24 24 0 1 0 -48 0 24 24 0 1 0 48 0zM80 456a24 24 0 1 0 0-48 24 24 0 1 0 0 48z"></path></svg> <!--?lit$085975880$-->latest</span>
      </header>
    
        <main class=" closed ">
          <!--?lit$085975880$--> <!--?lit$085975880$-->
      <dl class="versions">
        <dt>Versions</dt>
        <!--?lit$085975880$--><!----><dd><!--?lit$085975880$--><strong><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html"><!--?lit$085975880$-->latest</a></strong></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/stable/modules/nn.html"><!--?lit$085975880$-->stable</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.6.1/modules/nn.html"><!--?lit$085975880$-->2.6.1</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.6.0/modules/nn.html"><!--?lit$085975880$-->2.6.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.5.3/modules/nn.html"><!--?lit$085975880$-->2.5.3</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.5.2/modules/nn.html"><!--?lit$085975880$-->2.5.2</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.5.1/modules/nn.html"><!--?lit$085975880$-->2.5.1</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.5.0/modules/nn.html"><!--?lit$085975880$-->2.5.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.4.0/modules/nn.html"><!--?lit$085975880$-->2.4.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.3.1/modules/nn.html"><!--?lit$085975880$-->2.3.1</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.3.0/modules/nn.html"><!--?lit$085975880$-->2.3.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.2.0/modules/nn.html"><!--?lit$085975880$-->2.2.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.1.0/modules/nn.html"><!--?lit$085975880$-->2.1.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.0.4/modules/nn.html"><!--?lit$085975880$-->2.0.4</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.0.3/modules/nn.html"><!--?lit$085975880$-->2.0.3</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.0.2/modules/nn.html"><!--?lit$085975880$-->2.0.2</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.0.1/modules/nn.html"><!--?lit$085975880$-->2.0.1</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/2.0.0/modules/nn.html"><!--?lit$085975880$-->2.0.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.7.2/modules/nn.html"><!--?lit$085975880$-->1.7.2</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.7.1/modules/nn.html"><!--?lit$085975880$-->1.7.1</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.7.0/modules/nn.html"><!--?lit$085975880$-->1.7.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.6.3/modules/nn.html"><!--?lit$085975880$-->1.6.3</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.6.1/modules/nn.html"><!--?lit$085975880$-->1.6.1</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.6.0/modules/nn.html"><!--?lit$085975880$-->1.6.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.5.0/modules/nn.html"><!--?lit$085975880$-->1.5.0</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.4.3/modules/nn.html"><!--?lit$085975880$-->1.4.3</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.4.2/modules/nn.html"><!--?lit$085975880$-->1.4.2</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.4.1/modules/nn.html"><!--?lit$085975880$-->1.4.1</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.3.2/modules/nn.html"><!--?lit$085975880$-->1.3.2</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.3.1/modules/nn.html"><!--?lit$085975880$-->1.3.1</a></dd><!----><!----><dd><!--?lit$085975880$--><a href="https://pytorch-geometric.readthedocs.io/en/1.3.0/modules/nn.html"><!--?lit$085975880$-->1.3.0</a></dd><!---->
      </dl>
    
          <!--?lit$085975880$--> <!--?lit$085975880$-->
      <dl>
        <dt>On Read the Docs</dt>
        <dd>
          <a href="https://app.readthedocs.org/projects/pytorch-geometric/?utm_source=pytorch-geometric&amp;utm_content=flyout">Project Home</a>
        </dd>
        <dd>
          <a href="https://app.readthedocs.org/projects/pytorch-geometric/builds/?utm_source=pytorch-geometric&amp;utm_content=flyout">Builds</a>
        </dd>
      </dl>
    
          <!--?lit$085975880$--> <!--?lit$085975880$-->
        <dl>
          <dt>Search</dt>
          <dd>
            <form id="flyout-search-form">
              <input type="text" name="q" aria-label="Search docs" placeholder="Search docs">
            </form>
          </dd>
        </dl>
      
          <hr>
          <!--?lit$085975880$-->
      <small>
        <span>
          <a href="https://docs.readthedocs.io/page/addons.html?utm_source=pytorch-geometric&amp;utm_content=flyout">Addons documentation</a></span>
        <span> ― </span>
        <span>Hosted by
          <a href="https://about.readthedocs.com/?utm_source=pytorch-geometric&amp;utm_content=flyout">Read the Docs</a></span>
      </small>
    
        </main>
      </div>
    </template></readthedocs-flyout><readthedocs-notification class="raised toast"><template shadowrootmode="open"><!----></template></readthedocs-notification><readthedocs-search class="raised floating"><template shadowrootmode="open"><!---->
      <div role="search" hidden="">
        <div class="background"></div>
        <div class="content">
          <form class="  ">
            <label><!--?lit$085975880$--><svg aria-labelledby="svg-inline--fa-title-FKWybZGp93ym" data-prefix="fas" data-icon="magnifying-glass" class="svg-inline--fa fa-magnifying-glass" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><title id="svg-inline--fa-title-FKWybZGp93ym">Search docs</title><path fill="currentColor" d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352a144 144 0 1 0 0-288 144 144 0 1 0 0 288z"></path></svg></label>
            <input placeholder="Search docs" type="search" autocomplete="off">
          </form>
          <!--?lit$085975880$-->
          <div class="results">
            <!--?lit$085975880$--><p>No recent searches</p>
          </div>
          <div class="footer">
            <ul class="help">
              <li><code>Enter</code> to select</li>
              <li><code>Up</code>/<code>Down</code> to navigate</li>
              <li><code>Esc</code> to close</li>
            </ul>
            <div class="credits">
              Search powered by
              <a href="https://about.readthedocs.com/?utm_source=pytorch-geometric&amp;utm_content=search">
                <img alt="Read the Docs" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8"?>
<svg version="1.1" id="svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="694 197 2000 400">
<g id="logo" transform="matrix(0.55753644,0,0,0.55753644,68.308135,1050.1262)">
	<path style="fill:#32322A" d="M1408.1-1181.7c-7.5,1-12.7,7.8-11.7,15.3   c0.7,5.4,4.6,9.9,9.9,11.3c0,0,33.2,11,89.7,15.6c45.4,3.7,96.9-3.2,96.9-3.2c7.5-0.2,13.5-6.5,13.2-14s-6.5-13.5-14-13.2   c-0.9,0-1.8,0.1-2.6,0.3c0,0-50.4,6.2-91.3,2.9c-54-4.4-83.4-14.3-83.4-14.3C1412.6-1181.7,1410.3-1182,1408.1-1181.7z    M1408.1-1249.3c-7.5,1-12.7,7.8-11.7,15.3c0.7,5.4,4.6,9.9,9.9,11.3c0,0,33.2,11,89.7,15.6c45.4,3.7,96.9-3.2,96.9-3.2   c7.5-0.2,13.5-6.5,13.2-14s-6.5-13.5-14-13.2c-0.9,0-1.8,0.1-2.6,0.3c0,0-50.4,6.2-91.3,2.9c-54-4.4-83.4-14.3-83.4-14.3   C1412.6-1249.3,1410.3-1249.6,1408.1-1249.3z M1408.1-1316.9c-7.5,1-12.7,7.8-11.7,15.3c0.7,5.4,4.6,9.9,9.9,11.3   c0,0,33.2,11,89.7,15.6c45.4,3.7,96.9-3.2,96.9-3.2c7.5-0.2,13.5-6.5,13.2-14s-6.5-13.5-14-13.2c-0.9,0-1.8,0.1-2.6,0.3   c0,0-50.4,6.2-91.3,2.9c-54-4.4-83.4-14.3-83.4-14.3C1412.6-1316.9,1410.3-1317.2,1408.1-1316.9z M1408.1-1384.4   c-7.5,1-12.7,7.8-11.7,15.3c0.7,5.4,4.6,9.9,9.9,11.3c0,0,33.2,11,89.7,15.6c45.4,3.7,96.9-3.2,96.9-3.2c7.5-0.2,13.5-6.5,13.2-14   s-6.5-13.5-14-13.2c-0.9,0-1.8,0.1-2.6,0.3c0,0-50.4,6.2-91.3,2.9c-54-4.4-83.4-14.3-83.4-14.3   C1412.6-1384.5,1410.3-1384.7,1408.1-1384.4z M1313.4-1455.7c-71,0.5-97.5,22.3-97.5,22.3v530.3c0,0,25.8-22.3,109-18.9   c83.2,3.4,100.3,32.6,202.5,34.6c102.2,2.1,127.9-15.7,127.9-15.7l1.5-540.6c0,0-46,13-135.5,13.7s-111-22.8-193.2-25.5   C1323-1455.6,1318.1-1455.7,1313.4-1455.7z M1372.8-1421.1c0,0,43,14.2,122.5,18.2c67.2,3.3,134.5-6.6,134.5-6.6v480.5   c0,0-34.1,17.9-119.3,11.8c-66-4.7-138.7-29.7-138.7-29.7L1372.8-1421.1z M1331.3-1408.6c7.6,0,13.7,6.2,13.7,13.7   s-6.2,13.7-13.7,13.7c0,0-22.3,0.1-35.8,1.5c-22.8,2.3-38.3,10.6-38.3,10.6c-6.7,3.5-15,1-18.5-5.7s-1-15,5.7-18.5c0,0,0,0,0,0   c0,0,20.2-10.7,48.4-13.5C1309.1-1408.5,1331.3-1408.6,1331.3-1408.6z M1318.1-1340.8c7.6-0.2,13.3,0,13.3,0   c7.5,0.9,12.9,7.8,12,15.3c-0.8,6.3-5.7,11.2-12,12c0,0-22.3,0.1-35.8,1.5c-22.8,2.3-38.3,10.6-38.3,10.6c-6.7,3.5-15,0.9-18.5-5.8   c-3.5-6.7-0.9-15,5.8-18.5c0,0,20.2-10.7,48.4-13.5C1300.9-1340.1,1310.5-1340.6,1318.1-1340.8z M1331.3-1273.3   c7.6,0,13.7,6.2,13.7,13.7c0,7.6-6.2,13.7-13.7,13.7c0,0-22.3-0.1-35.8,1.2c-22.8,2.3-38.3,10.6-38.3,10.6   c-6.7,3.5-15,0.9-18.5-5.8c-3.5-6.7-0.9-15,5.8-18.5c0,0,20.2-10.7,48.4-13.5C1309.1-1273.4,1331.3-1273.3,1331.3-1273.3z"/>
</g>
<g id="text">
	<path style="fill:#32322A" d="M1128.6,491.9V470l8.9-0.8c5.2-0.5,7.8-3.1,7.8-7.6V336l-15.4-0.8v-23h73.8   c20.9,0,36.9,3.9,48.1,11.6c11.2,7.7,16.8,20.5,16.8,38.1c0,12.3-3.2,22.3-9.7,30.3c-6.3,7.9-13.9,13.7-22.7,17.3   c6.5,2.3,11.6,7.8,15.4,16.5l19.5,42.4l15.4,0.5v23h-66.8V470l7.8-0.8c4.1-0.5,6.2-2.2,6.2-4.9c0-1.1-0.4-2.3-1.1-3.8l-12.7-27   c-2-4.5-4.2-7.7-6.8-9.5c-2.3-2-5.8-3-10.3-3h-24.6v47l17.6,0.8v23L1128.6,491.9 M1178.3,395.4h23.5c22.2,0,33.2-9.9,33.2-29.7   c0-11.4-3-18.7-8.9-22.2c-5.8-3.4-15.1-5.1-28.1-5.1h-19.7V395.4"/>
	<path style="fill:#32322A" d="M1356,351.9c13.5,0,24.2,3.3,32.2,10c7.9,6.5,11.9,15.7,11.9,27.6c0,7.9-1.7,15-5.1,21.1   c-3.4,5.9-7.7,10.6-12.7,14.1c-5,3.4-11.2,6.2-18.4,8.4c-12.1,3.6-25.7,5.4-40.8,5.4c0.5,9.5,3.5,17.3,8.9,23.2   c5.4,5.8,13.7,8.6,24.9,8.6c11.2,0,22.3-4,33.5-11.9l10.3,21.9c-3.6,3.2-9.7,6.6-18.4,10c-8.5,3.4-18.2,5.1-29.2,5.1   c-22,0-38.1-6-48.4-18.1c-10.3-12.3-15.4-29-15.4-50.3c0-21.3,5.9-39.1,17.6-53.5C1318.5,359.1,1334.9,351.9,1356,351.9    M1343.6,413.8c6.7-1.3,12.8-3.9,18.4-7.8c5.6-4.1,8.4-9,8.4-14.6c0-11-5.4-16.5-16.2-16.5c-10.1,0-17.8,4.1-23.2,12.2   c-5.4,7.9-8.4,17.5-8.9,28.6C1329.9,415.5,1337.1,414.9,1343.6,413.8"/>
	<path style="fill:#32322A" d="M1529.6,361.4v100.5c0,2.9,0.5,4.9,1.4,5.9c1.1,1.1,2.9,1.7,5.4,1.9l8.6,0.5v21.6h-43v-15.7   l-0.8-0.3c-9,13-21.4,19.5-37,19.5c-18.4,0-32-5.9-40.8-17.6c-8.8-11.7-13.2-27.7-13.2-48.1c0-24.5,5.9-43.6,17.8-57.3   c11.9-13.7,29.7-20.5,53.5-20.5C1496.8,351.9,1512.9,355.1,1529.6,361.4 M1498.3,448.9v-70c-5-2.3-12-3.5-20.8-3.5   c-12.1,0-20.8,4.9-26.2,14.6c-5.4,9.7-8.1,22.6-8.1,38.7c0,29.2,9.4,43.8,28.1,43.8c7.9,0,14.4-2.3,19.5-7   C1495.7,460.6,1498.3,455.1,1498.3,448.9"/>
	<path style="fill:#32322A" d="M1616.3,351.9c7.7,0,15.1,1.1,22.2,3.2v-27.3c0-4-2.3-6.1-7-6.5l-11.6-0.8v-21.4h50.3v164.3   c0.2,4.1,2.4,6.2,6.8,6.2l9.5,0.5v21.6h-43.8V476l-0.8-0.3c-8.1,13.2-20.4,19.7-36.8,19.7c-20.5,0-35-6.8-43.2-20.5   c-7.6-12.4-11.4-27.7-11.4-45.7c0-23.4,5.8-42.2,17.3-56.2C1579.3,358.9,1595.5,351.9,1616.3,351.9 M1638.4,449.8v-70   c-6.5-2.9-13.3-4.3-20.5-4.3c-11.9,0-20.6,4.8-26.2,14.3c-5.4,9.6-8.1,21.7-8.1,36.5c0,30.3,9.7,45.4,29.2,45.4   c7.4,0,13.5-2.1,18.4-6.2C1636,461.1,1638.4,455.9,1638.4,449.8"/>
	<path style="fill:#32322A" d="M1791.7,470.6c0,0-12.5,4.7-19.2,4.7s-9.2-3.3-9.2-11.8c0-3.8,0.5-8.8,1.4-14.9l10.2-63.1h32.6   l2.8-17.7h-32.6l5.7-34.5L1760,338l-4.7,29.8l-23.6,2.4l-2.6,15.4h23.4L1742,451c-0.9,5.4-1.4,10.6-1.4,15.1   c0,18.7,7.8,28.1,23.9,28.1c13.2,0,31-10.9,31-10.9L1791.7,470.6"/>
	<path style="fill:#32322A" d="M1865,309.8l-43.3,1.2l-2.1,13l19.9,4.7l-26,163.2h22.5l7.8-42.6c0,0,18.7-65,49.4-65   c9.5,0,12.3,6.9,12.3,15.6c0,3.3-0.5,6.9-0.9,10.4l-13.5,81.6l43.3-2.4l2.1-13l-19.9-3.5l10.6-66.2c0.7-5,1.2-9.7,1.2-14   c0-17-6.9-28.6-25.8-28.6c-35.9,0-54.9,45.6-55.8,48.2L1865,309.8"/>
	<path style="fill:#32322A" d="M2035,464.7c0,0-21.5,10.6-38.8,10.6c-17.7,0-26-7.8-26-24.6c0-3.1,0.2-6.6,0.7-10.2   c49,0,83-18.4,83-45.6c0-18.7-15.1-30.7-39-30.7c-37.6,0-68.3,38.5-68.3,87.5c0,26,16.6,42.6,42.6,42.6c27.9,0,53-17.5,53-17.5   L2035,464.7 M1973,424c6.1-24.8,23.4-42.1,40.7-42.1c12.1,0,17.7,5,17.7,15.4C2031.5,412.9,2006.6,424,1973,424"/>
	<path style="fill:#32322A" d="M2093.7,491.9V470l8.9-0.8c5.2-0.5,7.8-3.1,7.8-7.6V336l-15.4-0.8v-23h74.1   c26.5,0,47.1,7,61.9,21.1c15,14.1,22.4,34.9,22.4,62.4c0,17.1-2.3,32.1-6.8,44.9c-4.5,12.6-10.6,22.5-18.4,29.7   c-15.5,14.4-34.8,21.6-57.8,21.6L2093.7,491.9 M2143.4,338.4V466h27.6c15.5,0,27.6-5.6,36.2-16.8c8.6-11.2,13-27.4,13-48.7   c0-41.4-17.6-62.2-52.7-62.2H2143.4"/>
	<path style="fill:#32322A" d="M2330,472.2c19.6,0,29.5-15.9,29.5-47.6c0-16-2.3-28.2-6.8-36.5c-4.3-8.3-11.7-12.4-22.2-12.4   c-10.3,0-17.8,4-22.7,11.9c-4.9,7.9-7.3,18.7-7.3,32.4c0,25.4,4.7,41.4,14.1,47.8C2318.8,470.7,2323.9,472.2,2330,472.2    M2267.9,423.8c0-13.3,2-24.9,5.9-34.6c4-9.9,9.3-17.5,15.9-22.7c12.8-9.7,26.9-14.6,42.4-14.6c10.8,0,19.9,1.8,27.3,5.4   c7.6,3.4,13.4,7.5,17.6,12.2c4.3,4.5,7.9,11.2,10.8,20c3.1,8.6,4.6,18.9,4.6,30.8c0,24.9-6,43.7-18.1,56.5   c-12.1,12.8-27.6,19.2-46.5,19.2c-18.7,0-33.4-6-44.1-18.1C2273.2,465.6,2267.9,447.6,2267.9,423.8"/>
	<path style="fill:#32322A" d="M2438.2,422.5c0,15.3,2.9,27.2,8.6,35.7c5.8,8.5,14.1,12.7,24.9,12.7c11,0,21.8-3.9,32.4-11.6   l11.6,20.8c-12.8,10.5-28.8,15.7-48.1,15.7c-19.3,0-34.5-6-45.7-18.1c-11-12.3-16.5-30.3-16.5-54.1s6.3-41.6,18.9-53.5   c12.8-12.1,27.1-18.1,43-18.1c16,0,30.9,3.7,44.6,11.1v35.1l-24.9,1.9v-13c0-4.9-1.8-7.8-5.4-8.9c-3.4-1.3-7-1.9-10.8-1.9   C2449.1,376.2,2438.2,391.6,2438.2,422.5"/>
	<path style="fill:#32322A" d="M2592.9,376.5c-4.3-1.6-9.6-2.4-15.7-2.4c-6.1,0-11.1,1.4-14.9,4.3c-3.6,2.7-5.4,6.1-5.4,10.3   c0,4,0.6,7.1,1.9,9.5c1.4,2.2,3.6,4.1,6.5,5.7c4.5,2.3,9.9,4.4,16.2,6.2c6.3,1.6,11,3,14.1,4.1c3.1,0.9,6.8,2.5,11.4,4.9   c4.7,2.3,8.2,4.9,10.5,7.6c6.3,6.7,9.5,15.2,9.5,25.7c0,13.5-5,24.1-14.9,31.9c-9.7,7.6-22.2,11.4-37.3,11.4   c-22,0-38.6-2.8-49.7-8.4v-37.6l24.3-1.9v13c0,7.9,7.6,11.9,22.7,11.9s22.7-5.5,22.7-16.5c0-4-1.4-7.2-4.1-9.7   c-2.5-2.5-5-4.2-7.6-5.1c-2.5-0.9-5.6-1.8-9.2-2.7c-3.4-0.9-6.8-1.8-10.3-2.7c-3.2-0.9-6.8-2.1-10.8-3.5c-3.8-1.6-8-3.9-12.7-6.8   c-9.2-5.9-13.8-15.9-13.8-29.7c0-14.1,5-24.9,14.9-32.4c9.9-7.6,22.3-11.4,37.3-11.4c15.1,0,30.1,3.6,44.9,10.8v32.4l-24.3,1.9   v-11.4C2599.1,381.2,2597,378.1,2592.9,376.5"/>
</g>
<div xmlns="" id="saka-gui-root"><div><div><style/></div></div></div></svg>">
              </a>
            </div>
          </div>
        </div>
      </div>
    </template></readthedocs-search><readthedocs-hotkeys><template shadowrootmode="open"><!----></template></readthedocs-hotkeys></body></html>